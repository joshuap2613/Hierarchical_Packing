{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, Tuple\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.ndimage.measurements import label\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import copy\n",
    "class PackEnv2(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, board_shape = (5, 5), input_shapes=[],max_moves=100, replacement=True):\n",
    "        self.counter = 0\n",
    "        self.max_moves = max_moves\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.board_shape = board_shape\n",
    "        self.observation_space = np.zeros((board_shape[0], board_shape[1]*2))\n",
    "        self.action_space = Discrete(board_shape[0]*board_shape[1]+1)\n",
    "        self.state = [np.zeros(board_shape),np.zeros(board_shape)]\n",
    "        self.return_state = np.concatenate((self.state[0], self.state[1]), axis=1)\n",
    "        self.replace = replacement\n",
    "\n",
    "        self.num_possible_moves = board_shape[0]*board_shape[1]\n",
    "\n",
    "        if len(input_shapes) == 0:\n",
    "            mat = np.zeros(board_shape)\n",
    "            mat[0][0] = 1\n",
    "            self.shapes = [mat]\n",
    "        else:\n",
    "            self.shapes = []\n",
    "            for shape in input_shapes:\n",
    "                base_mat = np.zeros(board_shape)\n",
    "                for i in range(len(shape)):\n",
    "                    for j in range(len(shape[0])):\n",
    "                        base_mat[i][j] = shape[i][j]\n",
    "                self.shapes.append(base_mat)\n",
    "        self.remaining_shapes = copy.deepcopy(self.shapes)\n",
    "        val = random.choice(range(len(self.shapes)))\n",
    "        self.state[1] = self.shapes[val]\n",
    "        if not self.replace:\n",
    "            self.remaining_shapes.pop(val)\n",
    "\n",
    "    def reset(self):\n",
    "        val = random.choice(range(len(self.shapes)))\n",
    "        random_shape = self.shapes[val]\n",
    "        self.counter = 0\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.state = [np.zeros(self.board_shape), random_shape]\n",
    "        self.return_state = np.concatenate((self.state[0], self.state[1]), axis=1)\n",
    "        self.remaining_shapes = copy.deepcopy(self.shapes)\n",
    "        if not self.replace:\n",
    "            self.remaining_shapes.pop(val)\n",
    "        return self.return_state\n",
    "\n",
    "\n",
    "    def valid_move(self, target):\n",
    "        state = self.state\n",
    "        board = state[0]\n",
    "        piece = state[1]\n",
    "        h = self.board_shape[0]\n",
    "        w = self.board_shape[1]\n",
    "\n",
    "        #do nothing\n",
    "        if target == h * w:\n",
    "            return True\n",
    "\n",
    "        if target > h*w or target < 0:\n",
    "            return False\n",
    "\n",
    "        h_offset = int(target / h)\n",
    "        w_offset = target % w\n",
    "\n",
    "        for H in range(len(piece)):\n",
    "            for W in range(len(piece[0])):\n",
    "                if piece[H][W] == 1:\n",
    "                    if (h_offset + H >= h) or (w_offset + W  >= w):\n",
    "                        return False\n",
    "                    if board[H+h_offset][W+w_offset] == 1:\n",
    "                        return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def calculate_reward(self, target, divisor=20):\n",
    "        state = self.state\n",
    "        board = state[0]\n",
    "        h = self.board_shape[0]\n",
    "        w = self.board_shape[1]\n",
    "        if target == self.num_possible_moves:\n",
    "            return -.5\n",
    "        \n",
    "        \n",
    "\n",
    "        #connection structure\n",
    "        #structure = np.ones((3, 3), dtype=np.int)\n",
    "        structure = np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "        labeled, ncomponents = label(board, structure)\n",
    "        component_num = labeled[int(target/h)][target % w]\n",
    "        if component_num == 0:\n",
    "            #invalid\n",
    "            return -1\n",
    "        indices = np.indices(board.shape).T[:,:,[1, 0]]\n",
    "        component = indices[labeled == component_num]\n",
    "\n",
    "        size = len(component)\n",
    "        max_h = max([pair[0] for pair in component])\n",
    "        min_h = min([pair[0] for pair in component])\n",
    "        max_w = max([pair[1] for pair in component])\n",
    "        min_w = min([pair[1] for pair in component])\n",
    "        block_size = abs(max_h-min_h + 1)*abs(max_w-min_w + 1)\n",
    "        return size**2/block_size/divisor\n",
    "\n",
    "    def merge(self, target):\n",
    "        state = self.state\n",
    "        board = state[0]\n",
    "        piece = state[1]\n",
    "        h = self.board_shape[0]\n",
    "        w = self.board_shape[1]\n",
    "\n",
    "        #do nothing\n",
    "        if target == h * w:\n",
    "            return state[0]\n",
    "\n",
    "        h_offset = int(target / h)\n",
    "        w_offset = target % w\n",
    "\n",
    "        for H in range(len(piece)):\n",
    "            for W in range(len(piece[0])):\n",
    "                if piece[H][W] == 1:\n",
    "                    #print(\"HIIIIIII\")\n",
    "                    board[H+h_offset][W+w_offset] = 1\n",
    "        return board\n",
    "\n",
    "    def final_reward(self):\n",
    "        h = self.board_shape[0]\n",
    "        w = self.board_shape[1]\n",
    "        state = self.state\n",
    "        board = state[0]\n",
    "        if np.sum(board) == h*w:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "\n",
    "    def step(self, target):\n",
    "        h = self.board_shape[0]\n",
    "        w = self.board_shape[1]\n",
    "        if self.done == True:\n",
    "            self.reward = self.final_reward()\n",
    "            print(\"It's over\")\n",
    "            return [self.return_state, self.reward, self.done, {}]\n",
    "        elif target > self.num_possible_moves:\n",
    "            print(\"Impossible. Invalid position\")\n",
    "            return [self.return_state, self.reward, self.done, {}]\n",
    "        else:\n",
    "            self.counter+=1\n",
    "            #print(\"counter\", self.counter)\n",
    "            if (self.counter == self.max_moves):\n",
    "                self.done = True\n",
    "                self.reward = self.final_reward()                \n",
    "                return [self.return_state, self.reward, self.done, {}]\n",
    "            #self.state[0][int(target/h)][target%k] = 1\n",
    "            if not self.valid_move(target):\n",
    "                self.reward = -1\n",
    "                return [self.return_state, self.reward, self.done, {}]\n",
    "\n",
    "            updated_board = self.merge(target)\n",
    "            self.reward = self.calculate_reward(target)\n",
    "            self.state[0] = updated_board\n",
    "            \n",
    "            #do nothing so same state\n",
    "            if (target == h*w):\n",
    "                return [self.return_state, self.reward, self.done, {}]\n",
    "            #no pieces left so we're done\n",
    "            if len(self.remaining_shapes) == 0:\n",
    "                print(\"hi\")\n",
    "                self.state[1] = np.zeros(self.board_shape)\n",
    "                self.return_state = np.concatenate((self.state[0], self.state[1]), axis=1)\n",
    "                self.done = True\n",
    "                self.reward = self.final_reward()\n",
    "                return [self.return_state, self.reward, self.done, {}]\n",
    "            else:\n",
    "                val = random.choice(range(len(self.remaining_shapes)))\n",
    "                self.state[1] = self.remaining_shapes[val]\n",
    "                if not self.replace:\n",
    "                    self.remaining_shapes.pop(val)\n",
    "                self.return_state = np.concatenate((self.state[0], self.state[1]), axis=1)\n",
    "                return [self.return_state, self.reward, self.done, {}]\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        fig, ax = plt.subplots()\n",
    "        # define the colors\n",
    "        cmap = mpl.colors.ListedColormap(['w', 'k'])\n",
    "\n",
    "        # create a normalize object the describes the limits of\n",
    "        # each color\n",
    "        bounds = [0., 0.5, 1.]\n",
    "        norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        # plot it\n",
    "        ax.imshow(self.state[0], interpolation='none', cmap=cmap, norm=norm)\n",
    "    def render_piece(self, mode='human'):\n",
    "        fig, ax = plt.subplots()\n",
    "        # define the colors\n",
    "        cmap = mpl.colors.ListedColormap(['w', 'k'])\n",
    "\n",
    "        # create a normalize object the describes the limits of\n",
    "        # each color\n",
    "        bounds = [0., 0.5, 1.]\n",
    "        norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        # plot it\n",
    "        ax.imshow(self.state[1], interpolation='none', cmap=cmap, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import gym\n",
    "#import gym_pack\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers, models\n",
    "\n",
    "from rl.agents.cem import CEMAgent\n",
    "from rl.memory import EpisodeParameterMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrupeQN:\n",
    "    def __init__(self, env):\n",
    "        self.env     = env\n",
    "        self.memory  = deque(maxlen=10000)\n",
    "        self.step = (1,1)\n",
    "        self.subgrid_shape = (2,2)\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.learning_rate = 0.01\n",
    "        self.tau = .08\n",
    "        self.min_tau = .02\n",
    "        self.tau_decay = .999\n",
    "\n",
    "        self.model        = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    #some env methods copied\n",
    "    \n",
    "    def valid_move(self,state, target):\n",
    "        h = self.env.board_shape[0]\n",
    "        w = self.env.board_shape[1]\n",
    "        state = (state[:,:w], state[:, w:])\n",
    "        board = state[0]\n",
    "        piece = state[1]\n",
    "        \n",
    "\n",
    "        #do nothing\n",
    "        if target == h * w:\n",
    "            return True\n",
    "\n",
    "        if target > h*w or target < 0:\n",
    "            return False\n",
    "\n",
    "        h_offset = int(target / h)\n",
    "        w_offset = target % w\n",
    "\n",
    "        for H in range(len(piece)):\n",
    "            for W in range(len(piece[0])):\n",
    "                if piece[H][W] == 1:\n",
    "                    if (h_offset + H >= h) or (w_offset + W  >= w):\n",
    "                        return False\n",
    "                    if board[H+h_offset][W+w_offset] == 1:\n",
    "                        return False\n",
    "        return True\n",
    "    def merge(self, state, target):\n",
    "        h = self.env.board_shape[0]\n",
    "        w = self.env.board_shape[1]\n",
    "        state = (state[:,:w], state[:, w:])\n",
    "        board = state[0]\n",
    "        piece = state[1]\n",
    "        \n",
    "\n",
    "        #do nothing\n",
    "        if target == h * w:\n",
    "            return state[0]\n",
    "\n",
    "        h_offset = int(target / h)\n",
    "        w_offset = target % w\n",
    "\n",
    "        for H in range(len(piece)):\n",
    "            for W in range(len(piece[0])):\n",
    "                if piece[H][W] == 1:\n",
    "                    #print(\"HIIIIIII\")\n",
    "                    board[H+h_offset][W+w_offset] += 1\n",
    "        return board\n",
    "    \n",
    "    \n",
    "    def grid_preprocess(self, board):\n",
    "        return\n",
    "    #input should be a binary array describing which action we are taking\n",
    "    #along with the current state space which is made smaller by solving \n",
    "    #using subproblems and then put through several convolutional layers\n",
    "    #then this is put through several fully connected layers and finally\n",
    "    #output through a single node\n",
    "    def create_model(self):\n",
    "        h, w = self.env.board_shape\n",
    "        h_step, w_step = self.step\n",
    "        h_len, w_len = self.subgrid_shape\n",
    "        updated_shape = (int((h-h_len+1)/h_step), int((w-w_len+1)/w_step))\n",
    "        \n",
    "        input_shape = updated_shape + (1,)\n",
    "        vals_shape = (self.env.num_possible_moves+1,)\n",
    "        \n",
    "        input1 = layers.Input(shape=input_shape)\n",
    "        input2 = layers.Input(shape=vals_shape)\n",
    "        conved1 = layers.Conv2D(32, (5, 5),padding=\"same\",input_shape=input_shape, activation=\"relu\")(input1)\n",
    "        conved2 = layers.Conv2D(32, (5, 5),padding=\"same\",input_shape=input_shape, activation=\"relu\")(conved1)\n",
    "        compressed = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conved2)\n",
    "        x = Flatten()(compressed)\n",
    "        processed = Dense(self.env.num_possible_moves+1, activation=\"relu\")(x)\n",
    "\n",
    "        merged = keras.layers.Concatenate(axis=1)([processed, input2])\n",
    "        a = Dense(24, activation=\"relu\")(merged)\n",
    "        b = Dense(48, activation=\"relu\")(a)\n",
    "        output = Dense(1, activation=\"linear\")(b)\n",
    "        model = keras.models.Model(inputs=[input1, input2], output=output)\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "            optimizer=Adam(lr=.01))\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "    \n",
    "    #eventually replaced with network on previous values TODO\n",
    "    def subgrid_val(self, subgrid):\n",
    "        #print(\"subgrid\",subgrid, np.sum(subgrid))\n",
    "        \n",
    "        #illegal move\n",
    "        if np.max(subgrid) == 2:\n",
    "            return -1\n",
    "        elif np.sum(subgrid) == 0:\n",
    "            return 0\n",
    "        elif np.sum(subgrid) == 1:\n",
    "            return .2\n",
    "        elif subgrid[0][0] == subgrid[1][1] and np.sum(subgrid) == 2:\n",
    "            return -.5\n",
    "        elif subgrid[0][0] != subgrid[1][1] and np.sum(subgrid) == 2:\n",
    "            return .4\n",
    "        elif np.sum(subgrid) == 3:\n",
    "            return .5\n",
    "        elif np.sum(subgrid) == 4:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def preprocess(self, state, action):\n",
    "        #print(\"STATE\", state, \"ACTION\", action)\n",
    "        h, w = self.env.board_shape\n",
    "        h_step, w_step = self.step\n",
    "        h_len, w_len = self.subgrid_shape\n",
    "        if not self.valid_move(state, action):\n",
    "            vals = -np.ones((int((h-h_len+1)/h_step), int((w-w_len+1)/w_step)))\n",
    "            return np.expand_dims(vals, axis=2)\n",
    "        potential_board = np.array(self.merge(state, action))\n",
    "        #print(\"potential board is\", potential_board)\n",
    "        \n",
    "        vals = []\n",
    "        for i in range(0, h-h_len+1, h_step):\n",
    "            for j in range(0, w-w_len+1, w_step):\n",
    "                subgrid = potential_board[i:i+h_len, j:j+w_len]\n",
    "                vals.append(self.subgrid_val(subgrid))\n",
    "        \n",
    "        vals = np.array(vals)\n",
    "        vals = vals.reshape(int((h-h_len+1)/h_step), int((w-w_len+1)/w_step), order='F')\n",
    "        #print(\"preprocessed is \", vals)\n",
    "        return np.expand_dims(vals, axis=2)\n",
    "\n",
    "    \n",
    "    def max_q(self, state):\n",
    "        #print(\"max_q state is\", state)\n",
    "        #new_shape = (1,) + self.env.observation_space.shape + (1,)\n",
    "        #input_state = state.reshape(new_shape)\n",
    "        actions = np.array([[int(j == i) for j in range(self.env.num_possible_moves+1)] for i in range(self.env.num_possible_moves+1)])\n",
    "        #input_states = np.array(list(input_state)*(self.env.num_possible_moves+1))\n",
    "        state = state.reshape(self.env.observation_space.shape)\n",
    "        input_states = [self.preprocess(np.copy(state), action) for action in range(self.env.num_possible_moves+1)]\n",
    "        input_states = np.array(input_states)\n",
    "        \n",
    "        #PREPREOCESS INPUT STATES\n",
    "        q_vals = self.target_model.predict([input_states, actions])\n",
    "        return max(q_vals)\n",
    "        \n",
    "    \n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        \n",
    "        \n",
    "        #new_shape = (1,) + self.env.observation_space.shape + (1,)\n",
    "        #input_state = state.reshape(new_shape)\n",
    "        actions = np.array([[int(j == i) for j in range(self.env.num_possible_moves+1)] for i in range(self.env.num_possible_moves+1)])\n",
    "        #input_states = np.array(list(input_state)*(self.env.num_possible_moves+1))\n",
    "        \n",
    "        state = state.reshape(self.env.observation_space.shape)\n",
    "        #print(\"prior state is \", state)\n",
    "        input_states = [self.preprocess(np.copy(state), action) for action in range(self.env.num_possible_moves+1)]\n",
    "        #print(\"posterior state is \", state)\n",
    "        input_states = np.array(input_states)\n",
    "        #PREPROCESS INPUT STATES\n",
    "        predictions = self.model.predict([input_states, actions])\n",
    "        for i in range(len(predictions)):\n",
    "            if not self.env.valid_move(i):\n",
    "                pass\n",
    "        return np.argmax(predictions)\n",
    "    \n",
    "    def trained_act(self, state):\n",
    "        #new_shape = (1,) + self.env.observation_space.shape + (1,)\n",
    "        #input_state = state.reshape(new_shape)\n",
    "        actions = np.array([[int(j == i) for j in range(self.env.num_possible_moves+1)] for i in range(self.env.num_possible_moves+1)])\n",
    "        #input_states = np.array(list(input_state)*(self.env.num_possible_moves+1))\n",
    "        \n",
    "        state = state.reshape(self.env.observation_space.shape)\n",
    "        input_states = [self.preprocess(np.copy(state), action) for action in range(self.env.num_possible_moves+1)]\n",
    "        input_states = np.array(input_states)\n",
    "        #PREPROCESS INPUT STATES\n",
    "        predictions = self.model.predict([input_states, actions])\n",
    "        for i in range(len(predictions)):\n",
    "            if not self.env.valid_move(i):\n",
    "                pass\n",
    "        return np.argmax(predictions)\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "    def replay(self):\n",
    "        batch_size = 32\n",
    "        if len(self.memory) < batch_size: \n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        states = []\n",
    "        outputs = []\n",
    "        actions = []\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            \n",
    "            output_prime = 0\n",
    "            if done:\n",
    "                output_prime = reward\n",
    "            else:\n",
    "                Q_future = self.max_q(new_state)\n",
    "                output_prime = reward + Q_future * self.gamma\n",
    "            outputs.append(output_prime)\n",
    "            #states.extend(state)\n",
    "            state = state.reshape(self.env.observation_space.shape)\n",
    "            states.append(self.preprocess(np.copy(state), action))\n",
    "            actions.append([int(j == action) for j in range(self.env.num_possible_moves+1)])\n",
    "        print(\"reward is\", reward, \"output_prime is\", output_prime)\n",
    "        states = np.array(states)\n",
    "        outputs = np.array(outputs)\n",
    "        actions = np.array(actions)\n",
    "        \n",
    "        #PREPROCESS STATES\n",
    "        self.model.fit([states,actions], outputs, epochs=1, verbose=0)\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        self.tau = max(self.min_tau, self.tau*self.tau_decay)\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #env = PackEnv2(board_shape=(2,2), input_shapes=[[[1]]]*2+[[[1,1],[0,0]]], replacement=False, max_moves=4)\n",
    "    max_moves = 8\n",
    "    env = PackEnv2(board_shape=(4,4), input_shapes=[[[1]]]*4+[[[1,1],[1,1]]]*3, replacement=False, max_moves=max_moves)\n",
    "    gamma   = 0.95\n",
    "    epsilon = .99\n",
    "\n",
    "    trials  = 501\n",
    "    trial_len = 50\n",
    "\n",
    "    # updateTargetNetwork = 1000\n",
    "    dqn_agent = PrupeQN(env=env)\n",
    "    accuracies = []\n",
    "    for trial in range(trials):\n",
    "        cur_state = env.reset()\n",
    "        state_shape = (1,) + env.observation_space.shape + (1,)\n",
    "        cur_state = cur_state.reshape(state_shape)\n",
    "        for step in range(trial_len):\n",
    "            action = dqn_agent.act(cur_state)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            new_state = new_state.reshape(state_shape)\n",
    "            dqn_agent.remember(cur_state, action, reward, new_state, done)\n",
    "            \n",
    "            dqn_agent.replay()       # internally iterates default (prediction) model\n",
    "            dqn_agent.target_train() # iterates target model\n",
    "\n",
    "            cur_state = new_state\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if (trial % 10) == 0 and trial !=0:\n",
    "            total_accuracy = 0\n",
    "            for i in range(30):\n",
    "                accuracy = 0\n",
    "                new_state = env.reset()\n",
    "                for j in range(max_moves):\n",
    "                    action = dqn_agent.trained_act(new_state)\n",
    "                    new_state, reward, done, _ = env.step(action)\n",
    "                    board_width = env.board_shape[1]\n",
    "                accuracy = np.sum(new_state[:,:board_width])/env.num_possible_moves\n",
    "                print(\"sub accuracy is\", accuracy)\n",
    "\n",
    "                total_accuracy += accuracy/30\n",
    "            accuracies.append(total_accuracy)\n",
    "            print(\"accuracy is \", total_accuracy)\n",
    "        print(\"trial #{}\".format(trial))\n",
    "        \n",
    "        \n",
    "        \n",
    "    return env, dqn_agent, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:103: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_71\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_141 (InputLayer)          (None, 3, 3, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 3, 3, 32)     832         input_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 3, 3, 32)     25632       conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling2D) (None, 2, 2, 32)     0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 128)          0           max_pooling2d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_281 (Dense)               (None, 17)           2193        flatten_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_142 (InputLayer)          (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 34)           0           dense_281[0][0]                  \n",
      "                                                                 input_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_282 (Dense)               (None, 24)           840         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_283 (Dense)               (None, 48)           1200        dense_282[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_284 (Dense)               (None, 1)            49          dense_283[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30,746\n",
      "Trainable params: 30,746\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_143 (InputLayer)          (None, 3, 3, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 3, 3, 32)     832         input_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 3, 3, 32)     25632       conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling2D) (None, 2, 2, 32)     0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 128)          0           max_pooling2d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_285 (Dense)               (None, 17)           2193        flatten_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_144 (InputLayer)          (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 34)           0           dense_285[0][0]                  \n",
      "                                                                 input_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_286 (Dense)               (None, 24)           840         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_287 (Dense)               (None, 48)           1200        dense_286[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_288 (Dense)               (None, 1)            49          dense_287[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30,746\n",
      "Trainable params: 30,746\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "trial #0\n",
      "trial #1\n",
      "trial #2\n",
      "reward is -1 output_prime is [-0.80708325]\n",
      "trial #3\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.8236928]\n",
      "reward is -1 output_prime is [-0.8190057]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [0.41054755]\n",
      "reward is 0.05 output_prime is [0.28494096]\n",
      "reward is -1 output_prime is [-0.77654386]\n",
      "reward is -1 output_prime is [-0.79881495]\n",
      "trial #4\n",
      "reward is 0.3375 output_prime is [0.5737877]\n",
      "reward is -1 output_prime is [-0.74338925]\n",
      "reward is 0.2 output_prime is [0.44183093]\n",
      "reward is 0.2 output_prime is [0.49221456]\n",
      "reward is -1 output_prime is [-0.8017329]\n",
      "reward is 0.05 output_prime is [0.19618727]\n",
      "reward is 0.2 output_prime is [0.55388093]\n",
      "reward is -1 output_prime is [-0.73987174]\n",
      "trial #5\n",
      "reward is 0.26666666666666666 output_prime is [0.63105583]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.5269829]\n",
      "reward is 0.20833333333333334 output_prime is [0.6755967]\n",
      "reward is -1 output_prime is [-0.4578371]\n",
      "reward is -1 output_prime is [-0.51291096]\n",
      "reward is 0.05 output_prime is [0.4772021]\n",
      "trial #6\n",
      "reward is -1 output_prime is [-0.39804012]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.43422484]\n",
      "reward is 0.2 output_prime is [0.86794364]\n",
      "reward is -1 output_prime is [-0.3066076]\n",
      "reward is -1 output_prime is [-0.2370618]\n",
      "reward is -1 output_prime is [-0.3204674]\n",
      "reward is -1 output_prime is [-0.33746338]\n",
      "trial #7\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.17630595]\n",
      "reward is 0.05 output_prime is [0.71033]\n",
      "reward is -1 output_prime is [-0.01251656]\n",
      "reward is 0.2 output_prime is [1.21093]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.06849599]\n",
      "reward is -1 output_prime is [0.09727705]\n",
      "trial #8\n",
      "reward is -1 output_prime is [-0.01757497]\n",
      "reward is 0.05 output_prime is [0.58209074]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.1911962]\n",
      "reward is -1 output_prime is [-0.0494988]\n",
      "reward is 0.05 output_prime is [0.7922797]\n",
      "reward is 0.2 output_prime is [1.4816238]\n",
      "reward is 0.2 output_prime is [1.2421445]\n",
      "trial #9\n",
      "reward is -1 output_prime is [0.06343842]\n",
      "reward is 0.05 output_prime is [1.0610373]\n",
      "reward is -1 output_prime is [0.14441645]\n",
      "reward is -1 output_prime is [0.1016016]\n",
      "reward is -1 output_prime is [0.36224878]\n",
      "reward is 0.05 output_prime is [1.2887195]\n",
      "reward is 0.05 output_prime is [1.3019121]\n",
      "reward is -1 output_prime is [0.32246852]\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.625\n",
      "accuracy is  0.5437500000000001\n",
      "trial #10\n",
      "reward is -1 output_prime is [0.81874764]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.5435426]\n",
      "reward is -1 output_prime is [0.3669293]\n",
      "reward is -1 output_prime is [0.49710572]\n",
      "reward is 0.05 output_prime is [1.412483]\n",
      "reward is -1 output_prime is [-0.10646451]\n",
      "trial #11\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.47876954]\n",
      "reward is -1 output_prime is [0.5819702]\n",
      "reward is -1 output_prime is [0.5991614]\n",
      "reward is 0.05 output_prime is [1.1381336]\n",
      "reward is 0.20833333333333334 output_prime is [1.8701392]\n",
      "reward is 0.20833333333333334 output_prime is [1.8727912]\n",
      "reward is -1 output_prime is [0.686296]\n",
      "trial #12\n",
      "reward is 0.20833333333333334 output_prime is [1.3235221]\n",
      "reward is -1 output_prime is [0.2648332]\n",
      "reward is -0.5 output_prime is [1.0405858]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [2.0316212]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.16406286]\n",
      "reward is 0.26666666666666666 output_prime is [1.593204]\n",
      "trial #13\n",
      "reward is -1 output_prime is [0.6634395]\n",
      "reward is -1 output_prime is [0.75454664]\n",
      "reward is 0.2 output_prime is [1.7110753]\n",
      "reward is 0.05 output_prime is [1.576754]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.15234315]\n",
      "reward is -1 output_prime is [0.9876065]\n",
      "reward is 0.2 output_prime is [1.6578671]\n",
      "trial #14\n",
      "reward is -1 output_prime is [1.043091]\n",
      "reward is -0.5 output_prime is [1.2058842]\n",
      "reward is 0.20833333333333334 output_prime is [2.239702]\n",
      "reward is -1 output_prime is [0.4892907]\n",
      "reward is 0.20833333333333334 output_prime is [2.1059132]\n",
      "reward is -1 output_prime is [0.7608992]\n",
      "reward is -1 output_prime is [1.0348153]\n",
      "reward is -1 output_prime is [0.7668245]\n",
      "trial #15\n",
      "reward is 0.2 output_prime is [1.9622693]\n",
      "reward is -1 output_prime is [1.0787752]\n",
      "reward is 0.05 output_prime is [1.915709]\n",
      "reward is 0.2 output_prime is [1.7280378]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.20955157]\n",
      "reward is -0.5 output_prime is [1.381716]\n",
      "reward is -1 output_prime is [0.8990537]\n",
      "trial #16\n",
      "reward is -1 output_prime is [0.9375837]\n",
      "reward is -1 output_prime is [0.5521927]\n",
      "reward is 0.05 output_prime is [1.0814576]\n",
      "reward is -1 output_prime is [0.59929967]\n",
      "reward is -1 output_prime is [0.6425191]\n",
      "reward is -1 output_prime is [1.0433686]\n",
      "reward is -1 output_prime is [0.98717916]\n",
      "reward is -1 output_prime is [1.0964744]\n",
      "trial #17\n",
      "reward is 0.2 output_prime is [2.2967675]\n",
      "reward is -1 output_prime is [0.72129667]\n",
      "reward is -1 output_prime is [1.1405468]\n",
      "reward is -1 output_prime is [1.0758405]\n",
      "reward is -1 output_prime is [0.8725345]\n",
      "reward is -1 output_prime is [1.0180163]\n",
      "reward is -1 output_prime is [1.1260374]\n",
      "reward is -1 output_prime is [1.1222892]\n",
      "trial #18\n",
      "reward is -0.5 output_prime is [1.6596138]\n",
      "reward is -1 output_prime is [0.89478254]\n",
      "reward is -1 output_prime is [1.3088937]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.3084643]\n",
      "reward is 0.05 output_prime is [2.2194324]\n",
      "reward is -1 output_prime is [1.0124776]\n",
      "reward is 0.3375 output_prime is [1.6035796]\n",
      "trial #19\n",
      "reward is -1 output_prime is [1.2457085]\n",
      "reward is 0.20833333333333334 output_prime is [2.6218548]\n",
      "reward is -1 output_prime is [1.2233913]\n",
      "reward is -1 output_prime is [1.2675991]\n",
      "reward is -1 output_prime is [0.6417227]\n",
      "reward is -1 output_prime is [0.8047738]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "accuracy is  0.6687500000000003\n",
      "trial #20\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.3969128]\n",
      "reward is -1 output_prime is [1.241677]\n",
      "reward is -1 output_prime is [1.2461565]\n",
      "reward is -1 output_prime is [1.2392023]\n",
      "reward is -1 output_prime is [1.3610816]\n",
      "reward is 0.05 output_prime is [2.4357865]\n",
      "reward is -1 output_prime is -1\n",
      "trial #21\n",
      "reward is -1 output_prime is [1.2054284]\n",
      "reward is 0.05 output_prime is [2.3401284]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.3778756]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.2631273]\n",
      "reward is 0.05 output_prime is [2.4072845]\n",
      "reward is 0.05 output_prime is [2.3431993]\n",
      "trial #22\n",
      "reward is 0.2 output_prime is [1.8204075]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.2954233]\n",
      "reward is -1 output_prime is [1.1945844]\n",
      "reward is -1 output_prime is [0.744167]\n",
      "reward is 0.2 output_prime is [2.3713148]\n",
      "reward is 0.05 output_prime is [1.027669]\n",
      "reward is -1 output_prime is [1.2914128]\n",
      "trial #23\n",
      "reward is -1 output_prime is [1.0059378]\n",
      "reward is 0.05 output_prime is [1.8046671]\n",
      "reward is -1 output_prime is [0.55999887]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.2794862]\n",
      "reward is 0.05 output_prime is [1.8060879]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.36832654]\n",
      "trial #24\n",
      "reward is -1 output_prime is [1.0112288]\n",
      "reward is -1 output_prime is [1.2910614]\n",
      "reward is -1 output_prime is [1.0694487]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.4355892]\n",
      "reward is -1 output_prime is [1.2502365]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.85213983]\n",
      "trial #25\n",
      "reward is 0.05 output_prime is [2.2711024]\n",
      "reward is -1 output_prime is [0.70033]\n",
      "reward is -1 output_prime is [0.6930386]\n",
      "reward is 0.05 output_prime is [2.9089754]\n",
      "reward is 0.2 output_prime is [2.7586913]\n",
      "reward is -0.5 output_prime is [1.079816]\n",
      "reward is -1 output_prime is [1.5370128]\n",
      "reward is -1 output_prime is [1.4276798]\n",
      "trial #26\n",
      "reward is -1 output_prime is [1.1919091]\n",
      "reward is -1 output_prime is [1.4552846]\n",
      "reward is 0.05 output_prime is [2.0921402]\n",
      "reward is -1 output_prime is [1.4559739]\n",
      "reward is -1 output_prime is [0.32763863]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.4106326]\n",
      "reward is -1 output_prime is -1\n",
      "trial #27\n",
      "reward is 0.05 output_prime is [2.7426102]\n",
      "reward is 0.05 output_prime is [2.4246125]\n",
      "reward is -1 output_prime is [1.4058423]\n",
      "reward is 0.2 output_prime is [2.7440836]\n",
      "reward is 0.05 output_prime is [2.39989]\n",
      "reward is -1 output_prime is [1.6368856]\n",
      "reward is 0.2 output_prime is [2.258867]\n",
      "reward is -1 output_prime is [0.7108314]\n",
      "trial #28\n",
      "reward is 0.05 output_prime is [1.6666576]\n",
      "reward is -1 output_prime is [1.3997204]\n",
      "reward is -1 output_prime is [1.4723663]\n",
      "reward is 0.05 output_prime is [3.3351007]\n",
      "reward is -1 output_prime is [1.434169]\n",
      "reward is 0.05 output_prime is [2.5738695]\n",
      "reward is 0.4 output_prime is [2.8477092]\n",
      "reward is -1 output_prime is -1\n",
      "trial #29\n",
      "reward is -1 output_prime is [1.4737976]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.3772414]\n",
      "reward is -1 output_prime is [-0.06149155]\n",
      "reward is 0.20833333333333334 output_prime is [1.2953632]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.7092526]\n",
      "reward is 0.20416666666666666 output_prime is [3.3833559]\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "accuracy is  0.5333333333333333\n",
      "trial #30\n",
      "reward is 0.05 output_prime is [2.6813176]\n",
      "reward is -1 output_prime is [1.0926905]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.6211803]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [3.188376]\n",
      "reward is -1 output_prime is [2.0501335]\n",
      "reward is -1 output_prime is [2.043634]\n",
      "trial #31\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.2442949]\n",
      "reward is 0.26666666666666666 output_prime is [2.0021703]\n",
      "reward is -1 output_prime is [1.7331331]\n",
      "reward is 0.2 output_prime is [1.5263165]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.8171036]\n",
      "trial #32\n",
      "reward is -1 output_prime is [1.4240878]\n",
      "reward is -1 output_prime is [1.9618173]\n",
      "reward is -1 output_prime is [0.24859905]\n",
      "reward is 0.05 output_prime is [2.7547624]\n",
      "reward is 0.26666666666666666 output_prime is [3.1422215]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.4187436]\n",
      "reward is 0.3375 output_prime is [3.3887148]\n",
      "trial #33\n",
      "reward is -0.5 output_prime is [0.8569404]\n",
      "reward is 0.2 output_prime is [2.8055959]\n",
      "reward is -1 output_prime is [1.6190746]\n",
      "reward is -1 output_prime is [0.41766417]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [2.7615712]\n",
      "reward is 0.3375 output_prime is [3.9223695]\n",
      "reward is -1 output_prime is [1.4762232]\n",
      "trial #34\n",
      "reward is -1 output_prime is [2.2499275]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.4646227]\n",
      "reward is -1 output_prime is [1.9549177]\n",
      "reward is -1 output_prime is [1.3069072]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [2.0154617]\n",
      "reward is 0.05 output_prime is [3.8771574]\n",
      "trial #35\n",
      "reward is -1 output_prime is [1.5869541]\n",
      "reward is 0.05 output_prime is [2.8856478]\n",
      "reward is 0.2 output_prime is [3.3840647]\n",
      "reward is -1 output_prime is [2.2354345]\n",
      "reward is -1 output_prime is [0.4492135]\n",
      "reward is 0.2 output_prime is [3.1939905]\n",
      "reward is -1 output_prime is [1.7545142]\n",
      "reward is 0.05 output_prime is [2.937328]\n",
      "trial #36\n",
      "reward is 0.2 output_prime is [2.0891504]\n",
      "reward is 0.3375 output_prime is [3.6411505]\n",
      "reward is -1 output_prime is [1.7022879]\n",
      "reward is -1 output_prime is [1.6615376]\n",
      "reward is 0.1 output_prime is [2.1199846]\n",
      "reward is 0.26666666666666666 output_prime is [1.6847974]\n",
      "reward is -1 output_prime is [0.8583604]\n",
      "reward is 0.05 output_prime is [2.8855824]\n",
      "trial #37\n",
      "reward is 0.20416666666666666 output_prime is [3.1278346]\n",
      "reward is -1 output_prime is [2.3970766]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [2.5797355]\n",
      "reward is 0.20833333333333334 output_prime is [1.5546237]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.6011834]\n",
      "reward is -1 output_prime is [2.3670092]\n",
      "trial #38\n",
      "reward is 0.05 output_prime is [3.104674]\n",
      "reward is 0.05 output_prime is [3.0587504]\n",
      "reward is 0.05 output_prime is [2.9764469]\n",
      "reward is 0.2 output_prime is [1.485387]\n",
      "reward is -1 output_prime is [0.60517085]\n",
      "reward is -1 output_prime is [2.4402225]\n",
      "reward is 0.20833333333333334 output_prime is [3.6050067]\n",
      "reward is -1 output_prime is [0.15982056]\n",
      "trial #39\n",
      "reward is 0.2 output_prime is [1.2973573]\n",
      "reward is 0.4166666666666667 output_prime is [2.2502224]\n",
      "reward is 0.1 output_prime is [2.5356443]\n",
      "reward is 0.4166666666666667 output_prime is [1.8196102]\n",
      "reward is -1 output_prime is [1.8415136]\n",
      "reward is -1 output_prime is [2.3914216]\n",
      "reward is 0.05 output_prime is [2.666348]\n",
      "reward is 0.05 output_prime is [3.0807376]\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5625\n",
      "accuracy is  0.5729166666666667\n",
      "trial #40\n",
      "reward is 0.20833333333333334 output_prime is [2.7349234]\n",
      "reward is 0.26666666666666666 output_prime is [1.951802]\n",
      "reward is 0.2 output_prime is [1.8207724]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [1.1116159]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.588522]\n",
      "reward is -1 output_prime is [0.89707184]\n",
      "trial #41\n",
      "reward is -1 output_prime is [0.60080075]\n",
      "reward is -1 output_prime is [0.55965614]\n",
      "reward is -1 output_prime is [0.5759537]\n",
      "reward is 0.05 output_prime is [2.7812176]\n",
      "reward is 0.378125 output_prime is [2.4937654]\n",
      "reward is -1 output_prime is [2.2449627]\n",
      "reward is -1 output_prime is [1.5120032]\n",
      "reward is 0.20833333333333334 output_prime is [1.2486529]\n",
      "trial #42\n",
      "reward is 0.2 output_prime is [1.8669881]\n",
      "reward is 0.05 output_prime is [3.1637752]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.2400212]\n",
      "reward is 0.2 output_prime is [4.1387324]\n",
      "reward is -1 output_prime is [0.78949356]\n",
      "reward is -1 output_prime is [0.763206]\n",
      "reward is -1 output_prime is [1.5236642]\n",
      "trial #43\n",
      "reward is 0.05 output_prime is [2.9553373]\n",
      "reward is -1 output_prime is [1.4332759]\n",
      "reward is -1 output_prime is [1.7727714]\n",
      "reward is -1 output_prime is [1.0005922]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.67314076]\n",
      "reward is 0.05 output_prime is [3.3455513]\n",
      "reward is 0.2 output_prime is [2.27019]\n",
      "trial #44\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [3.13176]\n",
      "reward is 0.20416666666666666 output_prime is [1.8121912]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.3390117]\n",
      "reward is 0.3375 output_prime is [2.372408]\n",
      "reward is 0.2 output_prime is [2.3035448]\n",
      "trial #45\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.69833076]\n",
      "reward is 0.20833333333333334 output_prime is [4.435442]\n",
      "reward is 0.05 output_prime is [3.9047706]\n",
      "reward is -1 output_prime is [1.0432105]\n",
      "reward is 0.05 output_prime is [3.451841]\n",
      "reward is -1 output_prime is [0.88405514]\n",
      "reward is -1 output_prime is [1.553211]\n",
      "trial #46\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.0427468]\n",
      "reward is -1 output_prime is [2.1813421]\n",
      "reward is 0.05 output_prime is [3.8766637]\n",
      "reward is 0.05 output_prime is [2.0392802]\n",
      "reward is 0.20416666666666666 output_prime is [1.3366196]\n",
      "reward is -1 output_prime is [2.458706]\n",
      "reward is 0.2 output_prime is [2.0711749]\n",
      "trial #47\n",
      "reward is 0.20416666666666666 output_prime is [1.3422039]\n",
      "reward is 0.05 output_prime is [4.088646]\n",
      "reward is 0.05 output_prime is [2.682498]\n",
      "reward is 0.20833333333333334 output_prime is [2.2352226]\n",
      "reward is -1 output_prime is [1.9842017]\n",
      "reward is -1 output_prime is [1.0964684]\n",
      "reward is 0.20416666666666666 output_prime is [3.2499125]\n",
      "reward is 0.20833333333333334 output_prime is [2.034183]\n",
      "trial #48\n",
      "reward is -1 output_prime is [3.168507]\n",
      "reward is 0.05 output_prime is [3.2501137]\n",
      "reward is -1 output_prime is [2.358971]\n",
      "reward is 0.2 output_prime is [2.7686853]\n",
      "reward is 0.20833333333333334 output_prime is [2.1255817]\n",
      "reward is 0.2 output_prime is [2.0502448]\n",
      "reward is 0.3125 output_prime is [1.9472091]\n",
      "reward is -1 output_prime is [0.61686456]\n",
      "trial #49\n",
      "reward is -1 output_prime is [2.3537517]\n",
      "reward is -1 output_prime is [0.8683506]\n",
      "reward is 0.05 output_prime is [3.4031608]\n",
      "reward is 0.3375 output_prime is [2.4912527]\n",
      "reward is -0.5 output_prime is [5.8383493]\n",
      "reward is 0.225 output_prime is [3.2850854]\n",
      "reward is -1 output_prime is [2.4734888]\n",
      "reward is -1 output_prime is -1\n",
      "sub accuracy is 0.25\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.25\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.25\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.25\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.375\n",
      "accuracy is  0.3937500000000001\n",
      "trial #50\n",
      "reward is -1 output_prime is [3.772439]\n",
      "reward is -1 output_prime is [3.4244595]\n",
      "reward is 0.378125 output_prime is [2.7169237]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.7935622]\n",
      "reward is 0.05 output_prime is [2.7054217]\n",
      "reward is -1 output_prime is -1\n",
      "trial #51\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.4551997]\n",
      "reward is -1 output_prime is [1.2073002]\n",
      "reward is 0.05 output_prime is [3.6576886]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [2.605442]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.6357696]\n",
      "trial #52\n",
      "reward is 0.05 output_prime is [2.4917848]\n",
      "reward is 0.2 output_prime is [2.467]\n",
      "reward is 0.2 output_prime is [2.5437987]\n",
      "reward is -0.5 output_prime is [1.3086363]\n",
      "reward is 0.05 output_prime is [2.7597644]\n",
      "reward is -1 output_prime is [1.1526754]\n",
      "reward is -1 output_prime is [1.4181504]\n",
      "reward is 0.2 output_prime is [3.7228062]\n",
      "trial #53\n",
      "reward is 0.05 output_prime is [3.506507]\n",
      "reward is 0.3375 output_prime is [1.9212055]\n",
      "reward is -1 output_prime is [2.1721911]\n",
      "reward is 0.3375 output_prime is [2.8343155]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.1527941]\n",
      "reward is -1 output_prime is [2.0143685]\n",
      "reward is -1 output_prime is -1\n",
      "trial #54\n",
      "reward is 0.26666666666666666 output_prime is [2.8249369]\n",
      "reward is 0.05 output_prime is [3.365464]\n",
      "reward is -1 output_prime is [2.9452403]\n",
      "reward is 0.3375 output_prime is [4.05867]\n",
      "reward is -1 output_prime is [1.4886894]\n",
      "reward is -0.5 output_prime is [1.180902]\n",
      "reward is 0.2 output_prime is [3.6930819]\n",
      "reward is 0.3125 output_prime is [2.7744358]\n",
      "trial #55\n",
      "reward is -1 output_prime is [1.1000745]\n",
      "reward is 0.05 output_prime is [3.0378652]\n",
      "reward is 0.2 output_prime is [2.7742856]\n",
      "reward is -1 output_prime is [1.0251608]\n",
      "reward is 0.05 output_prime is [1.9434913]\n",
      "reward is 0.253125 output_prime is [4.386088]\n",
      "reward is 0.05 output_prime is [2.466928]\n",
      "reward is -0.5 output_prime is [2.0937698]\n",
      "trial #56\n",
      "reward is 0.05 output_prime is [3.2864807]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [1.7161683]\n",
      "reward is -1 output_prime is [2.6303415]\n",
      "reward is 0.05 output_prime is [3.3493013]\n",
      "reward is -1 output_prime is [1.9536355]\n",
      "reward is 0.2 output_prime is [3.466985]\n",
      "reward is -1 output_prime is -1\n",
      "trial #57\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.2459984]\n",
      "reward is -1 output_prime is [1.4539073]\n",
      "reward is 0.2 output_prime is [3.5494208]\n",
      "reward is 0.2 output_prime is [3.5502794]\n",
      "reward is 0.26666666666666666 output_prime is [2.890028]\n",
      "reward is -0.5 output_prime is [2.8335018]\n",
      "reward is 0.05 output_prime is [3.1758163]\n",
      "trial #58\n",
      "reward is 0.05 output_prime is [2.793073]\n",
      "reward is 0.20833333333333334 output_prime is [3.1278064]\n",
      "reward is 0.26666666666666666 output_prime is [2.5660117]\n",
      "reward is -1 output_prime is [2.7138305]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.2704148]\n",
      "reward is -1 output_prime is [0.35797465]\n",
      "trial #59\n",
      "reward is -1 output_prime is [1.7343223]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [3.6537318]\n",
      "reward is 0.2 output_prime is [2.8998466]\n",
      "reward is -1 output_prime is [1.425839]\n",
      "reward is -1 output_prime is [1.1923418]\n",
      "reward is -1 output_prime is [0.6322175]\n",
      "reward is 0.2 output_prime is [2.4136717]\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5625\n",
      "accuracy is  0.61875\n",
      "trial #60\n",
      "reward is 0.05 output_prime is [2.7669647]\n",
      "reward is 0.2 output_prime is [2.8294656]\n",
      "reward is 0.20833333333333334 output_prime is [3.4613473]\n",
      "reward is 0.05 output_prime is [3.6695786]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [3.3983843]\n",
      "reward is -1 output_prime is [1.0208583]\n",
      "reward is -1 output_prime is [2.5594056]\n",
      "trial #61\n",
      "reward is -1 output_prime is [2.4006367]\n",
      "reward is -1 output_prime is [1.0614283]\n",
      "reward is -0.5 output_prime is [0.83829963]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.2615681]\n",
      "reward is 0.2 output_prime is [2.4577458]\n",
      "reward is 0.20416666666666666 output_prime is [2.2469573]\n",
      "reward is -1 output_prime is -1\n",
      "trial #62\n",
      "reward is 0.2 output_prime is [2.918724]\n",
      "reward is 0.2 output_prime is [2.5741456]\n",
      "reward is -1 output_prime is [1.1949542]\n",
      "reward is -1 output_prime is [2.6194446]\n",
      "reward is -1 output_prime is [0.8768424]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [1.5999483]\n",
      "reward is 0.05 output_prime is [3.0411603]\n",
      "trial #63\n",
      "reward is -1 output_prime is [1.6267457]\n",
      "reward is -1 output_prime is [1.2084596]\n",
      "reward is -1 output_prime is [0.3877468]\n",
      "reward is 0.05 output_prime is [3.0909383]\n",
      "reward is -1 output_prime is [2.494912]\n",
      "reward is 0.2 output_prime is [2.5834556]\n",
      "reward is 0.3375 output_prime is [2.753091]\n",
      "reward is 0.2 output_prime is [3.6133618]\n",
      "trial #64\n",
      "reward is -1 output_prime is [2.047633]\n",
      "reward is 0.05 output_prime is [2.8450193]\n",
      "reward is -1 output_prime is [1.6054857]\n",
      "reward is 0.26666666666666666 output_prime is [3.6158655]\n",
      "reward is 0.05 output_prime is [4.0879335]\n",
      "reward is 0.2 output_prime is [4.1805897]\n",
      "reward is 0.20833333333333334 output_prime is [3.4393795]\n",
      "reward is -1 output_prime is [1.4523127]\n",
      "trial #65\n",
      "reward is 0.2 output_prime is [3.3709087]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.2328378]\n",
      "reward is 0.05 output_prime is [3.2961743]\n",
      "reward is -1 output_prime is [1.0596879]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [1.8108624]\n",
      "trial #66\n",
      "reward is 0.20833333333333334 output_prime is [2.207323]\n",
      "reward is 0.05 output_prime is [3.7477968]\n",
      "reward is -1 output_prime is [1.4083307]\n",
      "reward is -1 output_prime is [0.92620456]\n",
      "reward is -1 output_prime is [2.3182127]\n",
      "reward is 0.1 output_prime is [2.7965093]\n",
      "reward is 0.225 output_prime is [3.054097]\n",
      "reward is -1 output_prime is -1\n",
      "trial #67\n",
      "reward is 0.05 output_prime is [1.343187]\n",
      "reward is 0.20833333333333334 output_prime is [1.9001385]\n",
      "reward is 0.2 output_prime is [3.933155]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.1202457]\n",
      "reward is -0.5 output_prime is [2.355918]\n",
      "reward is -1 output_prime is [0.5168487]\n",
      "reward is 0.05 output_prime is [3.4409702]\n",
      "trial #68\n",
      "reward is 0.05 output_prime is [3.8075392]\n",
      "reward is 0.05 output_prime is [2.703042]\n",
      "reward is -1 output_prime is [2.5528805]\n",
      "reward is -1 output_prime is [0.39877486]\n",
      "reward is 0.05 output_prime is [3.707452]\n",
      "reward is -1 output_prime is [0.37380755]\n",
      "reward is 0.2 output_prime is [3.1591263]\n",
      "reward is -1 output_prime is [2.6819518]\n",
      "trial #69\n",
      "reward is -1 output_prime is [2.840149]\n",
      "reward is 0.2 output_prime is [3.3384933]\n",
      "reward is 0.4 output_prime is [3.737508]\n",
      "reward is 0.20833333333333334 output_prime is [3.8889647]\n",
      "reward is -1 output_prime is [2.3706505]\n",
      "reward is 0.05 output_prime is [3.671145]\n",
      "reward is -1 output_prime is [2.3929422]\n",
      "reward is 0.05 output_prime is [1.3840636]\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.5083333333333335\n",
      "trial #70\n",
      "reward is -1 output_prime is [2.769715]\n",
      "reward is 0.05 output_prime is [1.3798044]\n",
      "reward is 0.2 output_prime is [3.8537962]\n",
      "reward is -1 output_prime is [2.499675]\n",
      "reward is 0.2 output_prime is [3.3861737]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [3.3989213]\n",
      "reward is 0.20833333333333334 output_prime is [3.7161064]\n",
      "trial #71\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.3068552]\n",
      "reward is -1 output_prime is [2.2166173]\n",
      "reward is -1 output_prime is [2.0783014]\n",
      "reward is 0.05 output_prime is [3.5424807]\n",
      "reward is 0.2 output_prime is [3.726143]\n",
      "reward is -1 output_prime is [1.9060333]\n",
      "reward is -1 output_prime is -1\n",
      "trial #72\n",
      "reward is 0.2 output_prime is [3.7771719]\n",
      "reward is 0.2 output_prime is [2.6758132]\n",
      "reward is -1 output_prime is [1.2607172]\n",
      "reward is -1 output_prime is [0.9762454]\n",
      "reward is 0.20833333333333334 output_prime is [3.0365775]\n",
      "reward is 0.3125 output_prime is [2.1581326]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.43229353]\n",
      "trial #73\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.3188536]\n",
      "reward is 0.26666666666666666 output_prime is [3.6858497]\n",
      "reward is -0.5 output_prime is [1.6095619]\n",
      "reward is -1 output_prime is [2.5318213]\n",
      "reward is 0.2 output_prime is [3.1813238]\n",
      "reward is 0.2 output_prime is [3.7287495]\n",
      "reward is -1 output_prime is [2.6438222]\n",
      "trial #74\n",
      "reward is 0.2 output_prime is [2.6489785]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.79113305]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.6387978]\n",
      "reward is -1 output_prime is [1.3678131]\n",
      "reward is 0.05 output_prime is [3.2979224]\n",
      "reward is -1 output_prime is -1\n",
      "trial #75\n",
      "reward is -1 output_prime is [0.6644863]\n",
      "reward is -0.5 output_prime is [1.3330957]\n",
      "reward is 0.2 output_prime is [3.9995897]\n",
      "reward is -1 output_prime is [2.3624196]\n",
      "reward is -1 output_prime is [1.432296]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [3.7749603]\n",
      "reward is 0.05 output_prime is [3.2472672]\n",
      "trial #76\n",
      "reward is -1 output_prime is [0.96995485]\n",
      "reward is -0.5 output_prime is [1.5166099]\n",
      "reward is -1 output_prime is [2.398434]\n",
      "reward is 0.05 output_prime is [3.5363934]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.18129718]\n",
      "reward is -1 output_prime is [2.7483666]\n",
      "reward is -1 output_prime is -1\n",
      "trial #77\n",
      "reward is -1 output_prime is [1.4067922]\n",
      "reward is -1 output_prime is [1.0003705]\n",
      "reward is -1 output_prime is [0.62469554]\n",
      "reward is 0.4 output_prime is [2.4147317]\n",
      "reward is -1 output_prime is [0.8985878]\n",
      "reward is -1 output_prime is [0.21615505]\n",
      "reward is -1 output_prime is [1.8162644]\n",
      "reward is -1 output_prime is [0.5215032]\n",
      "trial #78\n",
      "reward is 0.05 output_prime is [3.7223568]\n",
      "reward is 0.26666666666666666 output_prime is [3.89357]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.543483]\n",
      "reward is 0.3125 output_prime is [1.993519]\n",
      "reward is 0.2 output_prime is [4.1084166]\n",
      "reward is 0.4 output_prime is [3.8401356]\n",
      "reward is -1 output_prime is -1\n",
      "trial #79\n",
      "reward is 0.2 output_prime is [3.1038756]\n",
      "reward is -1 output_prime is [2.0920522]\n",
      "reward is -1 output_prime is [1.0181837]\n",
      "reward is -1 output_prime is [0.1907109]\n",
      "reward is -0.5 output_prime is [2.130647]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.3351753]\n",
      "reward is 0.26666666666666666 output_prime is [3.3865335]\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.25\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "accuracy is  0.41666666666666663\n",
      "trial #80\n",
      "reward is 0.05 output_prime is [4.068075]\n",
      "reward is 0.2 output_prime is [2.6697717]\n",
      "reward is 0.2 output_prime is [3.4758804]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.4385169]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [3.6186824]\n",
      "reward is -1 output_prime is -1\n",
      "trial #81\n",
      "reward is -1 output_prime is [1.8328862]\n",
      "reward is 0.26666666666666666 output_prime is [3.2380443]\n",
      "reward is -0.5 output_prime is [1.1194762]\n",
      "reward is 0.05 output_prime is [3.028332]\n",
      "reward is 0.2 output_prime is [2.2991836]\n",
      "reward is 0.2 output_prime is [3.5544806]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.2726557]\n",
      "trial #82\n",
      "reward is -1 output_prime is [2.6510878]\n",
      "reward is 0.05 output_prime is [3.3731396]\n",
      "reward is -1 output_prime is [0.6627177]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.4709144]\n",
      "reward is 0.1 output_prime is [2.8755026]\n",
      "reward is -1 output_prime is [2.185319]\n",
      "reward is 0.05 output_prime is [3.9099061]\n",
      "trial #83\n",
      "reward is -1 output_prime is [1.3096123]\n",
      "reward is 0.26666666666666666 output_prime is [3.7533493]\n",
      "reward is 0.6125 output_prime is [1.7871513]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [4.0444374]\n",
      "reward is 0.05 output_prime is [3.307735]\n",
      "reward is -1 output_prime is [2.4291754]\n",
      "reward is 0.4 output_prime is [2.6719449]\n",
      "trial #84\n",
      "reward is -1 output_prime is [1.9915855]\n",
      "reward is 0.05 output_prime is [3.3913038]\n",
      "reward is -1 output_prime is [2.412039]\n",
      "reward is -1 output_prime is [0.17007995]\n",
      "reward is -1 output_prime is [1.0995758]\n",
      "reward is 0.378125 output_prime is [2.0558808]\n",
      "reward is 0.05 output_prime is [3.6291957]\n",
      "reward is 0.4 output_prime is [4.146528]\n",
      "trial #85\n",
      "reward is 0.2 output_prime is [3.8924377]\n",
      "reward is 0.2 output_prime is [3.766515]\n",
      "reward is 0.05 output_prime is [3.1845682]\n",
      "reward is 0.20833333333333334 output_prime is [3.939698]\n",
      "reward is 0.20833333333333334 output_prime is [2.96703]\n",
      "reward is 0.2 output_prime is [2.236988]\n",
      "reward is 0.05 output_prime is [3.6205692]\n",
      "reward is 0.378125 output_prime is [2.5999258]\n",
      "trial #86\n",
      "reward is 0.05 output_prime is [3.0693076]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [2.8234937]\n",
      "reward is 0.05 output_prime is [3.6353188]\n",
      "reward is 0.2 output_prime is [2.2580285]\n",
      "reward is -1 output_prime is [1.0505207]\n",
      "reward is 0.05 output_prime is [3.4665818]\n",
      "reward is -1 output_prime is [1.05684]\n",
      "trial #87\n",
      "reward is 0.20416666666666666 output_prime is [1.3805335]\n",
      "reward is 0.2 output_prime is [2.7758005]\n",
      "reward is -1 output_prime is [1.7039409]\n",
      "reward is -1 output_prime is [0.43229687]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.18830395]\n",
      "reward is -1 output_prime is [1.1827769]\n",
      "reward is 0.20833333333333334 output_prime is [3.6673276]\n",
      "trial #88\n",
      "reward is 0.20833333333333334 output_prime is [2.6740642]\n",
      "reward is -1 output_prime is [0.55626106]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.20122123]\n",
      "reward is -1 output_prime is [1.3881414]\n",
      "reward is 0.3125 output_prime is [3.1095982]\n",
      "reward is -1 output_prime is [1.9019871]\n",
      "reward is 0.2 output_prime is [1.3979758]\n",
      "trial #89\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.2445952]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [3.2932203]\n",
      "reward is -1 output_prime is [2.620214]\n",
      "reward is 0.3125 output_prime is [1.4968276]\n",
      "reward is 0.378125 output_prime is [1.5588844]\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "accuracy is  0.6416666666666667\n",
      "trial #90\n",
      "reward is 0.20833333333333334 output_prime is [4.231533]\n",
      "reward is -1 output_prime is [1.2421732]\n",
      "reward is 0.05 output_prime is [1.2286115]\n",
      "reward is 0.05 output_prime is [1.2266198]\n",
      "reward is 0.4166666666666667 output_prime is [1.590729]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [3.7855213]\n",
      "reward is 0.20416666666666666 output_prime is [1.7864851]\n",
      "trial #91\n",
      "reward is 0.20416666666666666 output_prime is [3.037457]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.766922]\n",
      "reward is 0.05 output_prime is [3.6563172]\n",
      "reward is 0.05 output_prime is [3.1321356]\n",
      "reward is 0.2 output_prime is [4.1968193]\n",
      "reward is 0.20833333333333334 output_prime is [2.6113052]\n",
      "trial #92\n",
      "reward is 0.05 output_prime is [3.3109462]\n",
      "reward is -1 output_prime is [0.7831149]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.3094273]\n",
      "reward is 0.05 output_prime is [3.1373305]\n",
      "reward is 0.05 output_prime is [3.2472334]\n",
      "reward is -1 output_prime is [1.5174344]\n",
      "reward is 0.20833333333333334 output_prime is [2.924102]\n",
      "trial #93\n",
      "reward is 0.378125 output_prime is [2.486482]\n",
      "reward is 0.528125 output_prime is [1.7206933]\n",
      "reward is -0.5 output_prime is [2.8267646]\n",
      "reward is -1 output_prime is [1.6658683]\n",
      "reward is -1 output_prime is [2.258749]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.29523933]\n",
      "reward is 0.26666666666666666 output_prime is [3.1844099]\n",
      "trial #94\n",
      "reward is -1 output_prime is [2.5570662]\n",
      "reward is 0.05 output_prime is [2.924085]\n",
      "reward is 0.378125 output_prime is [1.4538696]\n",
      "reward is 0.05 output_prime is [3.3918521]\n",
      "reward is 0.05 output_prime is [1.9684695]\n",
      "reward is -1 output_prime is [1.0957341]\n",
      "reward is 0.225 output_prime is [2.50365]\n",
      "reward is 0.2 output_prime is [3.743869]\n",
      "trial #95\n",
      "reward is -1 output_prime is [0.97575736]\n",
      "reward is 0.05 output_prime is [3.298924]\n",
      "reward is 0.2 output_prime is [3.9336374]\n",
      "reward is -1 output_prime is [0.93509305]\n",
      "reward is -0.5 output_prime is [1.5218053]\n",
      "reward is -1 output_prime is [0.94605625]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.8876275]\n",
      "trial #96\n",
      "reward is -1 output_prime is [-0.03601527]\n",
      "reward is -0.5 output_prime is [1.9762218]\n",
      "reward is 0.2 output_prime is [4.13428]\n",
      "reward is -1 output_prime is [0.31105077]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [2.3952627]\n",
      "reward is -1 output_prime is [1.2821808]\n",
      "trial #97\n",
      "reward is -1 output_prime is [1.0814607]\n",
      "reward is 0.05 output_prime is [3.112012]\n",
      "reward is 0.26666666666666666 output_prime is [3.2425916]\n",
      "reward is -1 output_prime is [1.2888026]\n",
      "reward is -1 output_prime is [1.319145]\n",
      "reward is -1 output_prime is [0.9285151]\n",
      "reward is 0.05 output_prime is [3.2997177]\n",
      "reward is -1 output_prime is -1\n",
      "trial #98\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.02365291]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.1135495]\n",
      "reward is 0.20416666666666666 output_prime is [1.5381896]\n",
      "reward is -1 output_prime is [0.86109173]\n",
      "reward is -1 output_prime is [2.472167]\n",
      "trial #99\n",
      "reward is -1 output_prime is [1.7091632]\n",
      "reward is 0.20833333333333334 output_prime is [1.7010336]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.3756454]\n",
      "reward is -1 output_prime is [2.4588501]\n",
      "reward is -1 output_prime is [-0.02322018]\n",
      "reward is 0.3375 output_prime is [2.6768248]\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.625\n",
      "accuracy is  0.4708333333333334\n",
      "trial #100\n",
      "reward is 0.3375 output_prime is [2.433597]\n",
      "reward is -1 output_prime is [0.42846477]\n",
      "reward is 0.1 output_prime is [3.3514893]\n",
      "reward is -1 output_prime is [1.1957331]\n",
      "reward is -1 output_prime is [2.7327547]\n",
      "reward is 0.4166666666666667 output_prime is [2.3751204]\n",
      "reward is -1 output_prime is [1.1609607]\n",
      "reward is -1 output_prime is [1.6791506]\n",
      "trial #101\n",
      "reward is 0.05 output_prime is [3.0935304]\n",
      "reward is -1 output_prime is [0.01392579]\n",
      "reward is 0.2 output_prime is [3.4388847]\n",
      "reward is -1 output_prime is [0.6442847]\n",
      "reward is 0.20833333333333334 output_prime is [2.2835412]\n",
      "reward is 0.20833333333333334 output_prime is [1.9828482]\n",
      "reward is 0.378125 output_prime is [2.946202]\n",
      "reward is 0.45 output_prime is [1.4734828]\n",
      "trial #102\n",
      "reward is -0.5 output_prime is [3.2531378]\n",
      "reward is -0.5 output_prime is [0.56023526]\n",
      "reward is -1 output_prime is [0.29728448]\n",
      "reward is 0.3125 output_prime is [1.3271103]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.0682116]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [2.709203]\n",
      "trial #103\n",
      "reward is -1 output_prime is [1.1723952]\n",
      "reward is 0.05 output_prime is [3.571693]\n",
      "reward is -1 output_prime is [1.0161135]\n",
      "reward is 0.05 output_prime is [2.5305474]\n",
      "reward is -1 output_prime is [0.02332997]\n",
      "reward is -1 output_prime is [0.82509184]\n",
      "reward is -1 output_prime is [0.02278543]\n",
      "reward is 0.05 output_prime is [3.428541]\n",
      "trial #104\n",
      "reward is 0.05 output_prime is [2.327313]\n",
      "reward is 0.05 output_prime is [1.0654185]\n",
      "reward is -0.5 output_prime is [1.278222]\n",
      "reward is 0.05 output_prime is [2.4725177]\n",
      "reward is 0.2 output_prime is [2.2879324]\n",
      "reward is -1 output_prime is [1.4377677]\n",
      "reward is -1 output_prime is [-0.00770134]\n",
      "reward is 0.3375 output_prime is [2.7467482]\n",
      "trial #105\n",
      "reward is -1 output_prime is [0.18990815]\n",
      "reward is 0.1 output_prime is [1.0953987]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [1.3766725]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [3.2889218]\n",
      "reward is 0.20416666666666666 output_prime is [2.2484665]\n",
      "reward is 0.1 output_prime is [1.0928563]\n",
      "trial #106\n",
      "reward is -0.5 output_prime is [0.51066124]\n",
      "reward is -1 output_prime is [0.84752107]\n",
      "reward is 0.05 output_prime is [3.252178]\n",
      "reward is 0.2 output_prime is [2.2190216]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.169848]\n",
      "reward is 0.05 output_prime is [2.9655836]\n",
      "reward is 0.3375 output_prime is [2.851922]\n",
      "trial #107\n",
      "reward is 0.45 output_prime is [1.3937433]\n",
      "reward is -1 output_prime is [1.0692363]\n",
      "reward is -1 output_prime is [-0.07101101]\n",
      "reward is -1 output_prime is [1.5031624]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.2156603]\n",
      "reward is 0.05 output_prime is [0.9459911]\n",
      "reward is 0.4 output_prime is [3.5644631]\n",
      "trial #108\n",
      "reward is -1 output_prime is [0.87707007]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.528125 output_prime is [1.9425564]\n",
      "reward is 0.20833333333333334 output_prime is [2.2954497]\n",
      "reward is 0.05 output_prime is [2.057352]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [3.195572]\n",
      "reward is -1 output_prime is -1\n",
      "trial #109\n",
      "reward is 0.225 output_prime is [1.6979216]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [3.6405885]\n",
      "reward is 0.05 output_prime is [3.3971622]\n",
      "reward is 0.2 output_prime is [1.9796809]\n",
      "reward is 0.05 output_prime is [3.2475145]\n",
      "reward is -0.5 output_prime is [2.9091733]\n",
      "reward is 0.4166666666666667 output_prime is [2.3032286]\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.3125\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "accuracy is  0.5541666666666666\n",
      "trial #110\n",
      "reward is 0.3375 output_prime is [2.3923628]\n",
      "reward is 0.26666666666666666 output_prime is [2.3636017]\n",
      "reward is -1 output_prime is [1.1056087]\n",
      "reward is 0.3375 output_prime is [3.1763024]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.3104227]\n",
      "reward is -1 output_prime is [0.27803135]\n",
      "reward is -1 output_prime is [2.188217]\n",
      "trial #111\n",
      "reward is 0.05 output_prime is [0.8469703]\n",
      "reward is 0.2 output_prime is [0.9963956]\n",
      "reward is -1 output_prime is [2.0571213]\n",
      "reward is 0.20833333333333334 output_prime is [1.9689591]\n",
      "reward is 0.378125 output_prime is [2.2531505]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.5218631]\n",
      "reward is -1 output_prime is -1\n",
      "trial #112\n",
      "reward is -1 output_prime is [0.80471754]\n",
      "reward is 0.2 output_prime is [2.9294393]\n",
      "reward is -1 output_prime is [-0.20440036]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.9003887]\n",
      "reward is -1 output_prime is [1.1198368]\n",
      "reward is -0.5 output_prime is [2.0478928]\n",
      "reward is 0.20833333333333334 output_prime is [2.0305524]\n",
      "trial #113\n",
      "reward is -1 output_prime is [0.5127336]\n",
      "reward is -1 output_prime is [0.73489213]\n",
      "reward is 0.20833333333333334 output_prime is [1.6398221]\n",
      "reward is -1 output_prime is [0.73076046]\n",
      "reward is 0.05 output_prime is [3.374242]\n",
      "reward is 0.378125 output_prime is [1.2176168]\n",
      "reward is -1 output_prime is [0.48714817]\n",
      "reward is -1 output_prime is [2.0276518]\n",
      "trial #114\n",
      "reward is 0.2 output_prime is [1.9600315]\n",
      "reward is -1 output_prime is [-0.20784217]\n",
      "reward is 0.253125 output_prime is [1.9190686]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.21648788]\n",
      "reward is -1 output_prime is [1.6589434]\n",
      "reward is 0.20833333333333334 output_prime is [1.9434962]\n",
      "reward is 0.2 output_prime is [2.3604114]\n",
      "trial #115\n",
      "reward is 0.05 output_prime is [0.91791314]\n",
      "reward is 0.05 output_prime is [3.271533]\n",
      "reward is -0.5 output_prime is [1.0967942]\n",
      "reward is 0.05 output_prime is [3.026797]\n",
      "reward is 0.05 output_prime is [2.8847919]\n",
      "reward is -1 output_prime is [1.3755381]\n",
      "reward is -1 output_prime is [-0.22445178]\n",
      "reward is -1 output_prime is [1.6039143]\n",
      "trial #116\n",
      "reward is -1 output_prime is [-0.22693986]\n",
      "reward is -1 output_prime is [-0.22813374]\n",
      "reward is -1 output_prime is [1.0399835]\n",
      "reward is 0.253125 output_prime is [1.4936032]\n",
      "reward is -0.5 output_prime is [2.1782885]\n",
      "reward is 0.2 output_prime is [2.2447352]\n",
      "reward is 0.05 output_prime is [2.7539506]\n",
      "reward is -1 output_prime is -1\n",
      "trial #117\n",
      "reward is 0.20833333333333334 output_prime is [2.5837939]\n",
      "reward is -1 output_prime is [0.20978618]\n",
      "reward is 0.528125 output_prime is [1.5109586]\n",
      "reward is -1 output_prime is [0.36976218]\n",
      "reward is 0.3375 output_prime is [2.201978]\n",
      "reward is 0.2 output_prime is [1.4619262]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.23901033]\n",
      "trial #118\n",
      "reward is 0.2 output_prime is [2.954761]\n",
      "reward is -1 output_prime is [-0.27710134]\n",
      "reward is -0.5 output_prime is [2.3619611]\n",
      "reward is 0.2 output_prime is [4.109198]\n",
      "reward is 0.2 output_prime is [2.4363823]\n",
      "reward is -1 output_prime is [1.7925272]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.4166666666666667 output_prime is [1.0998553]\n",
      "trial #119\n",
      "reward is 0.05 output_prime is [3.0277233]\n",
      "reward is 0.2 output_prime is [2.312271]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [3.414976]\n",
      "reward is -1 output_prime is [-0.3442027]\n",
      "reward is -0.5 output_prime is [0.3744759]\n",
      "reward is 0.05 output_prime is [3.0431721]\n",
      "reward is -1 output_prime is [0.3603773]\n",
      "sub accuracy is 0.125\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.125\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.1875\n",
      "sub accuracy is 0.125\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.25\n",
      "sub accuracy is 0.375\n",
      "accuracy is  0.4229166666666668\n",
      "trial #120\n",
      "reward is -1 output_prime is [2.143292]\n",
      "reward is -1 output_prime is [0.75870395]\n",
      "reward is -1 output_prime is [0.5437522]\n",
      "reward is -1 output_prime is [2.0205495]\n",
      "reward is -1 output_prime is [0.49549985]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [0.34419578]\n",
      "reward is -1 output_prime is -1\n",
      "trial #121\n",
      "reward is 0.05 output_prime is [2.265469]\n",
      "reward is 0.20833333333333334 output_prime is [2.2770352]\n",
      "reward is 0.20833333333333334 output_prime is [3.11875]\n",
      "reward is 0.05 output_prime is [2.8152196]\n",
      "reward is -1 output_prime is [-0.43101132]\n",
      "reward is 0.2 output_prime is [2.4986098]\n",
      "reward is 0.2 output_prime is [3.0638025]\n",
      "reward is -1 output_prime is [-0.44415915]\n",
      "trial #122\n",
      "reward is 0.2 output_prime is [3.0720549]\n",
      "reward is -0.5 output_prime is [0.95517147]\n",
      "reward is -1 output_prime is [2.0431695]\n",
      "reward is 0.253125 output_prime is [2.1831377]\n",
      "reward is -0.5 output_prime is [0.9052806]\n",
      "reward is -1 output_prime is [0.32304156]\n",
      "reward is 0.4 output_prime is [3.0496836]\n",
      "reward is -1 output_prime is -1\n",
      "trial #123\n",
      "reward is 0.3375 output_prime is [2.1248775]\n",
      "reward is 0.3375 output_prime is [2.3096697]\n",
      "reward is 0.05 output_prime is [2.908115]\n",
      "reward is -1 output_prime is [1.8806853]\n",
      "reward is -0.5 output_prime is [0.01832205]\n",
      "reward is 0.05 output_prime is [2.94612]\n",
      "reward is -0.5 output_prime is [0.6969811]\n",
      "reward is -1 output_prime is [-0.4867308]\n",
      "trial #124\n",
      "reward is 0.528125 output_prime is [1.0396698]\n",
      "reward is -1 output_prime is [1.9514925]\n",
      "reward is 0.3375 output_prime is [1.9974344]\n",
      "reward is 0.2 output_prime is [2.4099984]\n",
      "reward is -1 output_prime is [0.815655]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [2.0487628]\n",
      "reward is -1 output_prime is [0.61266005]\n",
      "trial #125\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [1.1130028]\n",
      "reward is -0.5 output_prime is [1.5196362]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.7005086]\n",
      "reward is 0.2 output_prime is [2.3117378]\n",
      "reward is 0.2 output_prime is [2.5243292]\n",
      "reward is 0.2 output_prime is [2.3869076]\n",
      "trial #126\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.5190904]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [1.5761745]\n",
      "reward is -0.5 output_prime is [0.03539604]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.5301424]\n",
      "reward is -1 output_prime is [0.18265688]\n",
      "trial #127\n",
      "reward is 0.1 output_prime is [2.4841974]\n",
      "reward is -1 output_prime is [0.5923103]\n",
      "reward is 0.4166666666666667 output_prime is [0.87857985]\n",
      "reward is -1 output_prime is [1.1879256]\n",
      "reward is 0.1 output_prime is [0.5578546]\n",
      "reward is 0.3125 output_prime is [0.7682244]\n",
      "reward is -1 output_prime is [0.44338953]\n",
      "reward is 0.2 output_prime is [3.1423757]\n",
      "trial #128\n",
      "reward is 0.05 output_prime is [2.873675]\n",
      "reward is 0.05 output_prime is [2.1414874]\n",
      "reward is 0.05 output_prime is [2.8609824]\n",
      "reward is 0.3375 output_prime is [0.78217196]\n",
      "reward is 0.378125 output_prime is [2.0327566]\n",
      "reward is -1 output_prime is [0.26192594]\n",
      "reward is 0.05 output_prime is [2.367594]\n",
      "reward is -1 output_prime is [0.6027812]\n",
      "trial #129\n",
      "reward is 0.4166666666666667 output_prime is [0.852563]\n",
      "reward is -1 output_prime is [0.12469959]\n",
      "reward is 0.27222222222222225 output_prime is [0.7034644]\n",
      "reward is 0.05 output_prime is [2.9174228]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.7828078]\n",
      "reward is 0.20833333333333334 output_prime is [1.6348494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is [1.6238377]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.375\n",
      "accuracy is  0.6875000000000001\n",
      "trial #130\n",
      "reward is 0.2 output_prime is [2.8128314]\n",
      "reward is -0.5 output_prime is [1.4575155]\n",
      "reward is -1 output_prime is [1.1111696]\n",
      "reward is 0.5041666666666667 output_prime is [0.91411114]\n",
      "reward is -1 output_prime is [-0.59270215]\n",
      "reward is 0.26666666666666666 output_prime is [2.2889967]\n",
      "reward is 0.27222222222222225 output_prime is [0.67394495]\n",
      "reward is 0.05 output_prime is [2.2819815]\n",
      "trial #131\n",
      "reward is -0.5 output_prime is [-0.10385582]\n",
      "reward is 0.2 output_prime is [1.8911161]\n",
      "reward is -1 output_prime is [0.5263412]\n",
      "reward is 0.2 output_prime is [2.829673]\n",
      "reward is 0.05 output_prime is [2.6778567]\n",
      "reward is 0.2 output_prime is [1.726257]\n",
      "reward is -1 output_prime is [0.9177244]\n",
      "reward is 0.5041666666666667 output_prime is [0.883582]\n",
      "trial #132\n",
      "reward is 0.20833333333333334 output_prime is [1.6677822]\n",
      "reward is -1 output_prime is [-0.6255267]\n",
      "reward is 0.2 output_prime is [3.185512]\n",
      "reward is -1 output_prime is [0.29939246]\n",
      "reward is -0.5 output_prime is [-0.13356715]\n",
      "reward is -1 output_prime is [0.57701683]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-0.14085457]\n",
      "trial #133\n",
      "reward is -0.5 output_prime is [1.4962873]\n",
      "reward is -1 output_prime is [0.03810263]\n",
      "reward is -0.5 output_prime is [0.8055936]\n",
      "reward is 0.2 output_prime is [2.9574606]\n",
      "reward is 0.2 output_prime is [2.7503555]\n",
      "reward is -1 output_prime is [-0.65208477]\n",
      "reward is 0.20833333333333334 output_prime is [1.6701858]\n",
      "reward is -1 output_prime is [0.8544259]\n",
      "trial #134\n",
      "reward is -0.5 output_prime is [-0.15787739]\n",
      "reward is 0.378125 output_prime is [0.71810746]\n",
      "reward is -1 output_prime is [1.2011325]\n",
      "reward is 0.05 output_prime is [1.5642663]\n",
      "reward is 0.05 output_prime is [2.6061509]\n",
      "reward is -1 output_prime is [-0.27897626]\n",
      "reward is -0.5 output_prime is [1.8165812]\n",
      "reward is -0.5 output_prime is [-0.17090696]\n",
      "trial #135\n",
      "reward is -1 output_prime is [0.50450957]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.6742029]\n",
      "reward is 0.2 output_prime is [2.037953]\n",
      "reward is 0.2 output_prime is [2.2530062]\n",
      "reward is 0.20833333333333334 output_prime is [2.8292022]\n",
      "reward is 0.528125 output_prime is [1.3864009]\n",
      "reward is 0.4 output_prime is [1.7492192]\n",
      "trial #136\n",
      "reward is -0.5 output_prime is [2.4175427]\n",
      "reward is -1 output_prime is [0.28008616]\n",
      "reward is 0.20833333333333334 output_prime is [2.3707807]\n",
      "reward is 0.2 output_prime is [1.7797644]\n",
      "reward is 0.05 output_prime is [2.5577836]\n",
      "reward is -1 output_prime is [1.9456186]\n",
      "reward is 0.2 output_prime is [2.8666654]\n",
      "reward is 0.05 output_prime is [2.203342]\n",
      "trial #137\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.49221587]\n",
      "reward is 0.05 output_prime is [2.4711044]\n",
      "reward is -1 output_prime is [0.48541307]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.45 output_prime is [0.78130555]\n",
      "reward is 0.05 output_prime is [2.2486835]\n",
      "trial #138\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.0537403]\n",
      "reward is 0.05 output_prime is [2.3375509]\n",
      "reward is 0.2 output_prime is [2.7822235]\n",
      "reward is 0.3375 output_prime is [2.1939294]\n",
      "reward is 0.2 output_prime is [1.9985281]\n",
      "reward is 0.05 output_prime is [2.5863688]\n",
      "reward is -1 output_prime is [-0.6770523]\n",
      "trial #139\n",
      "reward is -0.5 output_prime is [0.49639374]\n",
      "reward is 0.05 output_prime is [2.605629]\n",
      "reward is 0.3375 output_prime is [2.060132]\n",
      "reward is -1 output_prime is [-0.68024933]\n",
      "reward is 0.05 output_prime is [2.1443377]\n",
      "reward is 0.4166666666666667 output_prime is [2.1025574]\n",
      "reward is -1 output_prime is [1.8609376]\n",
      "reward is 0.1 output_prime is [0.41602743]\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.70625\n",
      "trial #140\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.5319583]\n",
      "reward is 0.05 output_prime is [0.83345824]\n",
      "reward is 0.20833333333333334 output_prime is [1.0741643]\n",
      "reward is -1 output_prime is [1.0939159]\n",
      "reward is 0.20833333333333334 output_prime is [2.5488663]\n",
      "reward is -1 output_prime is [0.28219092]\n",
      "reward is -1 output_prime is [0.81665385]\n",
      "trial #141\n",
      "reward is 0.378125 output_prime is [0.6892299]\n",
      "reward is 0.27222222222222225 output_prime is [0.5831763]\n",
      "reward is 0.20833333333333334 output_prime is [1.3212541]\n",
      "reward is 0.20833333333333334 output_prime is [1.5158074]\n",
      "reward is 0.05 output_prime is [2.3472857]\n",
      "reward is -1 output_prime is [0.24121833]\n",
      "reward is -1 output_prime is [-0.69039965]\n",
      "reward is -1 output_prime is -1\n",
      "trial #142\n",
      "reward is 0.4166666666666667 output_prime is [1.3584255]\n",
      "reward is 0.05 output_prime is [2.4483993]\n",
      "reward is -1 output_prime is [0.9883082]\n",
      "reward is 0.1 output_prime is [2.2726116]\n",
      "reward is -1 output_prime is [1.7676227]\n",
      "reward is -0.5 output_prime is [0.21896279]\n",
      "reward is 0.2 output_prime is [2.8264513]\n",
      "reward is 0.20833333333333334 output_prime is [1.323199]\n",
      "trial #143\n",
      "reward is 0.3125 output_prime is [2.0651631]\n",
      "reward is 0.20833333333333334 output_prime is [2.0575643]\n",
      "reward is -1 output_prime is [1.3864107]\n",
      "reward is -0.5 output_prime is [-0.18983755]\n",
      "reward is -1 output_prime is [-0.68968683]\n",
      "reward is -0.5 output_prime is [-0.18966383]\n",
      "reward is -1 output_prime is [0.8749069]\n",
      "reward is -1 output_prime is [0.99582076]\n",
      "trial #144\n",
      "reward is -1 output_prime is [1.3341513]\n",
      "reward is 0.2 output_prime is [1.871673]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.075355]\n",
      "reward is 0.20833333333333334 output_prime is [0.51622355]\n",
      "reward is 0.05 output_prime is [0.35732356]\n",
      "reward is 0.26666666666666666 output_prime is [2.614026]\n",
      "reward is 0.05 output_prime is [0.3559095]\n",
      "trial #145\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [2.0560496]\n",
      "reward is -1 output_prime is [0.50647366]\n",
      "reward is 0.2 output_prime is [2.5520377]\n",
      "reward is -1 output_prime is [0.8489624]\n",
      "reward is 0.2 output_prime is [2.40412]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.7074249]\n",
      "trial #146\n",
      "reward is 0.4 output_prime is [2.457366]\n",
      "reward is 0.05 output_prime is [2.3439548]\n",
      "reward is -1 output_prime is [0.9416834]\n",
      "reward is 0.2 output_prime is [1.700751]\n",
      "reward is 0.05 output_prime is [2.5972087]\n",
      "reward is -0.5 output_prime is [-0.21048224]\n",
      "reward is 0.378125 output_prime is [0.79452956]\n",
      "reward is -1 output_prime is [-0.71393734]\n",
      "trial #147\n",
      "reward is 0.05 output_prime is [2.4028275]\n",
      "reward is -1 output_prime is [-0.7172954]\n",
      "reward is 0.45 output_prime is [0.7311834]\n",
      "reward is 0.253125 output_prime is [1.3895483]\n",
      "reward is 0.45 output_prime is [0.7301386]\n",
      "reward is -1 output_prime is [-0.7201116]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.4905376]\n",
      "trial #148\n",
      "reward is 0.05 output_prime is [1.9283625]\n",
      "reward is 0.3375 output_prime is [2.4604545]\n",
      "reward is -1 output_prime is [0.84585834]\n",
      "reward is 0.20833333333333334 output_prime is [2.879371]\n",
      "reward is 0.45 output_prime is [1.7662446]\n",
      "reward is 0.225 output_prime is [2.029072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is [1.199688]\n",
      "reward is 0.378125 output_prime is [1.4117689]\n",
      "trial #149\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.7222434]\n",
      "reward is 0.26666666666666666 output_prime is [2.5182292]\n",
      "reward is 0.3125 output_prime is [1.8619746]\n",
      "reward is 0.05 output_prime is [2.4383426]\n",
      "reward is -0.5 output_prime is [0.9503484]\n",
      "reward is 0.2 output_prime is [2.5796428]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "accuracy is  0.7625000000000002\n",
      "trial #150\n",
      "reward is 0.05 output_prime is [1.9466829]\n",
      "reward is 0.20833333333333334 output_prime is [1.9240118]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [1.7361137]\n",
      "reward is 0.5041666666666667 output_prime is [0.7780628]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [0.7576659]\n",
      "reward is 0.1 output_prime is [1.4854401]\n",
      "trial #151\n",
      "reward is -0.5 output_prime is [-0.23004588]\n",
      "reward is 0.2 output_prime is [2.7568517]\n",
      "reward is -1 output_prime is [-0.7325099]\n",
      "reward is 0.05 output_prime is [2.409429]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [0.36184758]\n",
      "reward is -1 output_prime is [-0.03018236]\n",
      "reward is -1 output_prime is [-0.01085466]\n",
      "trial #152\n",
      "reward is 0.4 output_prime is [2.2742462]\n",
      "reward is 0.26666666666666666 output_prime is [2.0488591]\n",
      "reward is 0.2 output_prime is [1.8652871]\n",
      "reward is -1 output_prime is [1.3406591]\n",
      "reward is -1 output_prime is [0.35576713]\n",
      "reward is 0.05 output_prime is [1.777022]\n",
      "reward is -1 output_prime is [-0.75546944]\n",
      "reward is 0.05 output_prime is [2.3914943]\n",
      "trial #153\n",
      "reward is 0.4 output_prime is [2.3047128]\n",
      "reward is 0.3375 output_prime is [1.2400366]\n",
      "reward is -1 output_prime is [-0.761226]\n",
      "reward is 0.2 output_prime is [1.641162]\n",
      "reward is 0.2 output_prime is [0.4364134]\n",
      "reward is 0.05 output_prime is [1.9230349]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "trial #154\n",
      "reward is 0.2 output_prime is [2.470295]\n",
      "reward is -0.5 output_prime is [-0.2678891]\n",
      "reward is -1 output_prime is [-0.7687161]\n",
      "reward is -0.5 output_prime is [-0.26975173]\n",
      "reward is -1 output_prime is [0.73690295]\n",
      "reward is 0.20833333333333334 output_prime is [1.9754945]\n",
      "reward is -0.5 output_prime is [0.92983985]\n",
      "reward is 0.20833333333333334 output_prime is [2.5533257]\n",
      "trial #155\n",
      "reward is 0.3125 output_prime is [1.7324203]\n",
      "reward is -0.5 output_prime is [1.2419697]\n",
      "reward is 0.2 output_prime is [2.3266852]\n",
      "reward is 0.05 output_prime is [2.080096]\n",
      "reward is 0.20833333333333334 output_prime is [1.9365227]\n",
      "reward is 0.05 output_prime is [1.6676143]\n",
      "reward is -1 output_prime is [0.44355357]\n",
      "reward is 0.05 output_prime is [1.987394]\n",
      "trial #156\n",
      "reward is 0.2 output_prime is [1.9525771]\n",
      "reward is 0.05 output_prime is [0.43421584]\n",
      "reward is -1 output_prime is [0.4692886]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.7931733]\n",
      "reward is 0.05 output_prime is [2.0232925]\n",
      "reward is -1 output_prime is [-0.06689459]\n",
      "reward is 0.20416666666666666 output_prime is [0.39430556]\n",
      "trial #157\n",
      "reward is -0.5 output_prime is [-0.3126799]\n",
      "reward is -1 output_prime is [1.2971699]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [2.0489225]\n",
      "reward is 0.378125 output_prime is [1.6883273]\n",
      "reward is 0.20416666666666666 output_prime is [1.6437967]\n",
      "hi\n",
      "reward is 0.1 output_prime is [1.7218217]\n",
      "trial #158\n",
      "reward is -1 output_prime is [1.3752108]\n",
      "reward is 0.2 output_prime is [2.2463655]\n",
      "reward is 0.05 output_prime is [2.3650982]\n",
      "reward is 0.05 output_prime is [0.20893793]\n",
      "reward is -1 output_prime is [0.41583502]\n",
      "reward is 0.05 output_prime is [1.9966947]\n",
      "reward is -0.5 output_prime is [1.0526352]\n",
      "reward is 0.1 output_prime is [1.6460227]\n",
      "trial #159\n",
      "reward is 0.05 output_prime is [1.9332058]\n",
      "reward is -0.5 output_prime is [-0.33602893]\n",
      "reward is -1 output_prime is [-0.83411753]\n",
      "reward is -1 output_prime is [0.7890241]\n",
      "reward is -1 output_prime is [0.8537303]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.84919447]\n",
      "reward is -1 output_prime is [-0.34561205]\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.6875000000000002\n",
      "trial #160\n",
      "reward is 0.05 output_prime is [2.4294734]\n",
      "reward is -1 output_prime is [-0.677843]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [1.733984]\n",
      "reward is 0.3375 output_prime is [1.819972]\n",
      "reward is -1 output_prime is [-0.82859373]\n",
      "reward is -1 output_prime is [-0.82944393]\n",
      "reward is 0.05 output_prime is [2.210724]\n",
      "trial #161\n",
      "reward is -0.5 output_prime is [0.49423963]\n",
      "reward is 0.05 output_prime is [2.51013]\n",
      "reward is -0.5 output_prime is [-0.33210546]\n",
      "reward is -1 output_prime is [1.2462523]\n",
      "reward is 0.3125 output_prime is [1.622951]\n",
      "reward is 0.05 output_prime is [0.83414423]\n",
      "reward is 0.1 output_prime is [1.6886456]\n",
      "reward is 0.2 output_prime is [1.0195551]\n",
      "trial #162\n",
      "reward is 0.05 output_prime is [2.2658033]\n",
      "reward is 0.3375 output_prime is [1.8373163]\n",
      "reward is -1 output_prime is [1.4158807]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.5806139]\n",
      "reward is -1 output_prime is [1.3887331]\n",
      "reward is 0.05 output_prime is [2.1529028]\n",
      "trial #163\n",
      "reward is 0.1 output_prime is [1.9831473]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.5785474]\n",
      "reward is 0.20833333333333334 output_prime is [2.2471702]\n",
      "reward is 0.20833333333333334 output_prime is [2.2510562]\n",
      "reward is -0.5 output_prime is [-0.37559316]\n",
      "reward is 0.05 output_prime is [1.8583112]\n",
      "reward is -1 output_prime is [0.64951825]\n",
      "trial #164\n",
      "reward is -0.5 output_prime is [1.8817298]\n",
      "reward is 0.378125 output_prime is [2.010808]\n",
      "reward is -1 output_prime is [-0.14770687]\n",
      "reward is -1 output_prime is [0.19965339]\n",
      "reward is 0.2 output_prime is [1.8888397]\n",
      "reward is 0.3 output_prime is [1.9132097]\n",
      "reward is 0.3125 output_prime is [2.0010948]\n",
      "reward is -1 output_prime is -1\n",
      "trial #165\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [0.32401705]\n",
      "reward is 0.2 output_prime is [0.35112792]\n",
      "reward is -1 output_prime is [-0.6269413]\n",
      "reward is 0.5041666666666667 output_prime is [0.6647232]\n",
      "reward is -0.5 output_prime is [-0.3845153]\n",
      "reward is 0.2 output_prime is [2.4047036]\n",
      "trial #166\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.5892651]\n",
      "reward is 0.05 output_prime is [1.4828238]\n",
      "reward is -1 output_prime is [0.5957265]\n",
      "reward is 0.05 output_prime is [1.7781755]\n",
      "reward is 0.2 output_prime is [1.497407]\n",
      "reward is -0.5 output_prime is [1.2764846]\n",
      "reward is -1 output_prime is [-0.8953258]\n",
      "trial #167\n",
      "reward is -1 output_prime is [-0.8965144]\n",
      "reward is -1 output_prime is [0.31294644]\n",
      "reward is -1 output_prime is [0.7941364]\n",
      "reward is -1 output_prime is [0.36085033]\n",
      "reward is 0.3125 output_prime is [1.8639423]\n",
      "reward is 0.05 output_prime is [2.073188]\n",
      "reward is 0.05 output_prime is [2.089057]\n",
      "reward is -1 output_prime is [-0.9081321]\n",
      "trial #168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.5500456]\n",
      "reward is -1 output_prime is [0.7449912]\n",
      "reward is 0.05 output_prime is [2.1237297]\n",
      "reward is 0.05 output_prime is [2.2026577]\n",
      "reward is -1 output_prime is [-0.06589222]\n",
      "trial #169\n",
      "reward is 0.2 output_prime is [2.234842]\n",
      "reward is -1 output_prime is [-0.9248602]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.1406548]\n",
      "reward is -1 output_prime is [-0.69387686]\n",
      "reward is 0.378125 output_prime is [1.6145699]\n",
      "reward is 0.378125 output_prime is [1.2826972]\n",
      "reward is -1 output_prime is [-0.6922329]\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "accuracy is  0.7000000000000001\n",
      "trial #170\n",
      "reward is 0.05 output_prime is [1.5818416]\n",
      "reward is 0.5041666666666667 output_prime is [0.62109554]\n",
      "reward is 0.45 output_prime is [0.51005125]\n",
      "reward is -1 output_prime is [0.33425415]\n",
      "reward is 0.528125 output_prime is [2.1836355]\n",
      "reward is -1 output_prime is [0.22016323]\n",
      "reward is -0.5 output_prime is [0.64902735]\n",
      "reward is -1 output_prime is [-0.934909]\n",
      "trial #171\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [1.0768334]\n",
      "reward is -1 output_prime is [0.35572278]\n",
      "reward is -1 output_prime is [-0.13209957]\n",
      "reward is -1 output_prime is [0.79134405]\n",
      "reward is -1 output_prime is [-0.9488919]\n",
      "reward is 0.378125 output_prime is [0.42834088]\n",
      "trial #172\n",
      "reward is -1 output_prime is [0.52546966]\n",
      "reward is 0.05 output_prime is [2.0809557]\n",
      "reward is -1 output_prime is [0.4816302]\n",
      "reward is 0.20416666666666666 output_prime is [0.9649613]\n",
      "reward is -0.5 output_prime is [0.7134907]\n",
      "reward is 0.2 output_prime is [0.25033122]\n",
      "reward is 0.2 output_prime is [2.0455568]\n",
      "reward is 0.05 output_prime is [0.23421383]\n",
      "trial #173\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.90646446]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.0543501]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.0707317]\n",
      "reward is -1 output_prime is [1.07371]\n",
      "reward is 0.05 output_prime is [1.7027277]\n",
      "trial #174\n",
      "reward is -1 output_prime is [0.18212652]\n",
      "reward is 0.05 output_prime is [1.8502003]\n",
      "reward is 0.05 output_prime is [1.8728193]\n",
      "reward is 0.20833333333333334 output_prime is [0.2648973]\n",
      "reward is -1 output_prime is [-0.9440464]\n",
      "reward is -0.5 output_prime is [1.1362122]\n",
      "reward is -0.5 output_prime is [-0.14495298]\n",
      "reward is 0.05 output_prime is [1.9799966]\n",
      "trial #175\n",
      "reward is 0.3125 output_prime is [0.36376256]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [2.1232057]\n",
      "reward is 0.26666666666666666 output_prime is [1.379282]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [0.08852091]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [0.40919933]\n",
      "trial #176\n",
      "reward is -1 output_prime is [0.5602226]\n",
      "reward is 0.1 output_prime is [0.12330443]\n",
      "reward is -1 output_prime is [-0.01186031]\n",
      "reward is -1 output_prime is [1.1023035]\n",
      "reward is -0.5 output_prime is [-0.48420674]\n",
      "reward is 0.26666666666666666 output_prime is [1.877546]\n",
      "reward is 0.3125 output_prime is [1.5776886]\n",
      "reward is 0.2 output_prime is [1.716909]\n",
      "trial #177\n",
      "reward is -1 output_prime is [1.1052883]\n",
      "reward is 0.2 output_prime is [2.046334]\n",
      "reward is 0.1 output_prime is [0.10916293]\n",
      "reward is 0.2 output_prime is [2.0741148]\n",
      "reward is 0.05 output_prime is [1.7817988]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.975242]\n",
      "reward is -1 output_prime is [-0.84992045]\n",
      "trial #178\n",
      "reward is 0.05 output_prime is [1.7723658]\n",
      "reward is -1 output_prime is [0.4937358]\n",
      "reward is -0.5 output_prime is [-0.5005309]\n",
      "reward is -0.5 output_prime is [0.3496564]\n",
      "reward is -1 output_prime is [-0.29342902]\n",
      "reward is 0.225 output_prime is [1.6270726]\n",
      "reward is 0.05 output_prime is [1.8945041]\n",
      "reward is -0.5 output_prime is [-0.5054625]\n",
      "trial #179\n",
      "reward is 0.703125 output_prime is [0.6966001]\n",
      "reward is 0.378125 output_prime is [1.2509061]\n",
      "reward is -1 output_prime is [0.42876387]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.7924318]\n",
      "reward is 0.2 output_prime is [1.6059312]\n",
      "reward is -1 output_prime is -1\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.6291666666666665\n",
      "trial #180\n",
      "reward is -1 output_prime is [-0.7527189]\n",
      "reward is 0.2 output_prime is [1.2425444]\n",
      "reward is -0.5 output_prime is [-0.5212295]\n",
      "reward is 0.05 output_prime is [1.7151809]\n",
      "reward is 0.528125 output_prime is [1.3121521]\n",
      "reward is 0.05 output_prime is [1.458495]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.0306602]\n",
      "trial #181\n",
      "reward is 0.4 output_prime is [2.044427]\n",
      "reward is 0.2 output_prime is [2.320236]\n",
      "reward is 0.3375 output_prime is [1.237784]\n",
      "reward is 0.20833333333333334 output_prime is [1.8709682]\n",
      "reward is 0.05 output_prime is [1.8780528]\n",
      "reward is 0.20833333333333334 output_prime is [1.9538013]\n",
      "reward is 0.05 output_prime is [1.6300966]\n",
      "reward is -1 output_prime is [0.2953123]\n",
      "trial #182\n",
      "reward is 0.3 output_prime is [1.4667902]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.0731196]\n",
      "reward is 0.20833333333333334 output_prime is [1.953915]\n",
      "reward is -1 output_prime is [0.95397544]\n",
      "reward is 0.2 output_prime is [2.3238866]\n",
      "reward is 0.05 output_prime is [1.8357675]\n",
      "reward is -1 output_prime is [0.74535775]\n",
      "trial #183\n",
      "reward is -1 output_prime is [-1.0761507]\n",
      "reward is 0.05 output_prime is [2.0165532]\n",
      "reward is 0.2 output_prime is [1.8903766]\n",
      "reward is 0.05 output_prime is [1.4156253]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.0900736]\n",
      "reward is 0.05 output_prime is [2.0568197]\n",
      "reward is -1 output_prime is [-0.03452432]\n",
      "trial #184\n",
      "reward is -1 output_prime is [0.09685445]\n",
      "reward is 0.3375 output_prime is [0.8085495]\n",
      "reward is 0.3375 output_prime is [1.6493449]\n",
      "reward is 0.2 output_prime is [1.5495043]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.8651283]\n",
      "reward is 0.253125 output_prime is [1.7417035]\n",
      "reward is 0.378125 output_prime is [1.2493062]\n",
      "trial #185\n",
      "reward is -1 output_prime is [0.6965134]\n",
      "reward is 0.2 output_prime is [2.2644763]\n",
      "reward is -0.5 output_prime is [-0.2267142]\n",
      "reward is 0.05 output_prime is [2.070477]\n",
      "reward is 0.05 output_prime is [1.9972736]\n",
      "reward is 0.20833333333333334 output_prime is [1.8882023]\n",
      "reward is -1 output_prime is [1.2338881]\n",
      "reward is -1 output_prime is [0.15126574]\n",
      "trial #186\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.1254926]\n",
      "reward is 0.45 output_prime is [0.32580316]\n",
      "reward is 0.05 output_prime is [2.2029793]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.2171701]\n",
      "reward is -0.5 output_prime is [1.0494775]\n",
      "reward is 0.3125 output_prime is [0.19377476]\n",
      "trial #187\n",
      "reward is -1 output_prime is [0.41410613]\n",
      "reward is 0.45 output_prime is [1.6800365]\n",
      "reward is 0.20833333333333334 output_prime is [2.1519778]\n",
      "reward is -1 output_prime is -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.2 output_prime is [1.9456053]\n",
      "reward is -1 output_prime is [-1.1128592]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.214042]\n",
      "trial #188\n",
      "reward is 0.05 output_prime is [2.3092628]\n",
      "reward is -0.5 output_prime is [0.449907]\n",
      "reward is 0.20833333333333334 output_prime is [1.5203716]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.9724324]\n",
      "reward is -0.5 output_prime is [1.0266097]\n",
      "reward is -0.5 output_prime is [0.68631935]\n",
      "trial #189\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [2.1695104]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.0985684]\n",
      "reward is 0.2 output_prime is [2.1110146]\n",
      "reward is 0.2 output_prime is [2.2774482]\n",
      "reward is 0.2 output_prime is [0.76553965]\n",
      "reward is 0.2 output_prime is [2.1691062]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.7583333333333335\n",
      "trial #190\n",
      "reward is -1 output_prime is [-1.0984534]\n",
      "reward is -1 output_prime is [-1.0987941]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.5041666666666667 output_prime is [1.173392]\n",
      "reward is 0.2 output_prime is [1.1942773]\n",
      "reward is -1 output_prime is [0.16415751]\n",
      "reward is 0.253125 output_prime is [1.5507421]\n",
      "reward is 0.05 output_prime is [1.6552418]\n",
      "trial #191\n",
      "reward is 0.05 output_prime is [1.9146657]\n",
      "reward is -1 output_prime is [1.100728]\n",
      "reward is 0.20833333333333334 output_prime is [1.8271415]\n",
      "reward is 0.2 output_prime is [2.2333598]\n",
      "reward is 0.378125 output_prime is [0.30785018]\n",
      "reward is 0.5041666666666667 output_prime is [0.4004826]\n",
      "reward is -1 output_prime is [0.03055465]\n",
      "reward is -1 output_prime is [-1.1042945]\n",
      "trial #192\n",
      "reward is 0.05 output_prime is [1.7114758]\n",
      "reward is -0.5 output_prime is [0.7705952]\n",
      "reward is 0.225 output_prime is [0.11958916]\n",
      "reward is 0.05 output_prime is [1.9268695]\n",
      "reward is -0.5 output_prime is [0.32735568]\n",
      "reward is 0.1 output_prime is [-0.00638895]\n",
      "reward is 0.20833333333333334 output_prime is [0.84027797]\n",
      "reward is 0.45 output_prime is [0.34305832]\n",
      "trial #193\n",
      "reward is -1 output_prime is [0.18885136]\n",
      "reward is 0.378125 output_prime is [0.27055132]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [1.3892043]\n",
      "reward is 0.225 output_prime is [0.8476981]\n",
      "reward is -1 output_prime is [0.21717143]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.01116723]\n",
      "trial #194\n",
      "reward is 0.5041666666666667 output_prime is [0.39374048]\n",
      "reward is 0.20833333333333334 output_prime is [1.4516599]\n",
      "reward is 0.378125 output_prime is [1.1942424]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.66776645]\n",
      "reward is -0.5 output_prime is [0.27690494]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [1.6377234]\n",
      "trial #195\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.7086947]\n",
      "reward is 0.2 output_prime is [2.0191934]\n",
      "reward is 0.20833333333333334 output_prime is [1.8262887]\n",
      "reward is 0.20833333333333334 output_prime is [1.8247336]\n",
      "reward is -1 output_prime is [0.89462006]\n",
      "reward is 0.2 output_prime is [1.7506042]\n",
      "reward is -1 output_prime is [-0.38802826]\n",
      "trial #196\n",
      "reward is 0.2 output_prime is [2.0751123]\n",
      "reward is 0.378125 output_prime is [0.26630533]\n",
      "reward is 0.26666666666666666 output_prime is [1.4587855]\n",
      "reward is -1 output_prime is [0.65042496]\n",
      "reward is 0.26666666666666666 output_prime is [1.4100634]\n",
      "reward is -1 output_prime is [0.36242115]\n",
      "reward is 0.05 output_prime is [-0.05972741]\n",
      "reward is -0.5 output_prime is [0.91909325]\n",
      "trial #197\n",
      "reward is -1 output_prime is [1.0404973]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [1.0459359]\n",
      "reward is -1 output_prime is [0.21730936]\n",
      "reward is 0.378125 output_prime is [0.27373102]\n",
      "reward is 0.4 output_prime is [1.8007385]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [1.6769869]\n",
      "trial #198\n",
      "reward is 0.20833333333333334 output_prime is [1.4656265]\n",
      "reward is -1 output_prime is [-0.79186076]\n",
      "reward is 0.3125 output_prime is [1.471222]\n",
      "reward is 0.5041666666666667 output_prime is [1.1042769]\n",
      "reward is 0.20833333333333334 output_prime is [1.4985902]\n",
      "reward is 0.3375 output_prime is [1.5269033]\n",
      "reward is 0.05 output_prime is [1.3669239]\n",
      "reward is -1 output_prime is [-1.0898439]\n",
      "trial #199\n",
      "reward is -1 output_prime is [-0.1472686]\n",
      "reward is 0.05 output_prime is [-0.03745734]\n",
      "reward is 0.2 output_prime is [1.5976745]\n",
      "reward is 0.05 output_prime is [1.4088954]\n",
      "reward is 0.45 output_prime is [0.3653693]\n",
      "reward is 0.26666666666666666 output_prime is [1.5233573]\n",
      "reward is 0.2 output_prime is [1.972622]\n",
      "reward is -1 output_prime is [0.9398459]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "accuracy is  0.6479166666666669\n",
      "trial #200\n",
      "reward is 0.3375 output_prime is [1.2144812]\n",
      "reward is -1 output_prime is [0.08832645]\n",
      "reward is 0.3375 output_prime is [1.530044]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.32544136]\n",
      "reward is -0.5 output_prime is [-0.5799879]\n",
      "reward is -1 output_prime is [0.16287601]\n",
      "reward is 0.703125 output_prime is [0.94567144]\n",
      "trial #201\n",
      "reward is 0.20833333333333334 output_prime is [1.7697752]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.0815548]\n",
      "reward is 0.3125 output_prime is [0.23041156]\n",
      "reward is -1 output_prime is [0.5783981]\n",
      "reward is 0.05 output_prime is [0.78107774]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.712306]\n",
      "trial #202\n",
      "reward is -1 output_prime is [-0.7494019]\n",
      "reward is 0.20416666666666666 output_prime is [1.0970757]\n",
      "reward is 0.3125 output_prime is [1.2442935]\n",
      "reward is -1 output_prime is [0.08983791]\n",
      "reward is 0.3 output_prime is [0.98436105]\n",
      "reward is 0.20833333333333334 output_prime is [1.5841337]\n",
      "reward is -1 output_prime is [-1.0876215]\n",
      "reward is 0.05 output_prime is [1.8550981]\n",
      "trial #203\n",
      "reward is -0.5 output_prime is [-0.58863175]\n",
      "reward is -0.5 output_prime is [0.562757]\n",
      "reward is 0.05 output_prime is [1.7045358]\n",
      "reward is -0.5 output_prime is [0.852088]\n",
      "reward is 0.27222222222222225 output_prime is [0.98845637]\n",
      "reward is 0.4 output_prime is [1.6711338]\n",
      "reward is -0.5 output_prime is [0.5516052]\n",
      "reward is 0.3125 output_prime is [1.4843315]\n",
      "trial #204\n",
      "reward is 0.2 output_prime is [1.6728357]\n",
      "reward is -1 output_prime is [0.8563708]\n",
      "reward is 0.1 output_prime is [0.00715102]\n",
      "reward is -1 output_prime is [-1.0931771]\n",
      "reward is -0.5 output_prime is [-0.5935032]\n",
      "reward is 0.2 output_prime is [1.7446748]\n",
      "reward is 0.5041666666666667 output_prime is [1.5160465]\n",
      "reward is 0.45 output_prime is [1.4283034]\n",
      "trial #205\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.0957022]\n",
      "reward is 0.3125 output_prime is [1.2776258]\n",
      "reward is 0.3125 output_prime is [1.3912024]\n",
      "reward is -1 output_prime is [0.55347705]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.4417001]\n",
      "trial #206\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.4166666666666667 output_prime is [1.2304475]\n",
      "reward is 0.2 output_prime is [1.7640743]\n",
      "reward is 0.2 output_prime is [1.939955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.20833333333333334 output_prime is [1.5128584]\n",
      "reward is -1 output_prime is [-0.5008539]\n",
      "reward is 0.2 output_prime is [1.821062]\n",
      "reward is 0.2 output_prime is [1.6351994]\n",
      "trial #207\n",
      "reward is -1 output_prime is [0.03316879]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.1086485]\n",
      "reward is 0.20416666666666666 output_prime is [0.09482536]\n",
      "reward is 0.1 output_prime is [-0.01003982]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.404125]\n",
      "reward is 0.05 output_prime is [1.2505072]\n",
      "trial #208\n",
      "reward is 0.2 output_prime is [0.08670399]\n",
      "reward is -1 output_prime is [-1.1140563]\n",
      "reward is -1 output_prime is [0.20435452]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [1.6470683]\n",
      "reward is -1 output_prime is [0.15067911]\n",
      "reward is -1 output_prime is [0.5797684]\n",
      "reward is -1 output_prime is -1\n",
      "trial #209\n",
      "reward is -1 output_prime is [-0.171233]\n",
      "reward is 0.45 output_prime is [0.43802208]\n",
      "reward is 0.2 output_prime is [1.5105072]\n",
      "reward is 0.05 output_prime is [1.3591022]\n",
      "reward is -1 output_prime is [-1.1195464]\n",
      "reward is -1 output_prime is [0.1873728]\n",
      "reward is -1 output_prime is [-0.87819]\n",
      "reward is 0.20833333333333334 output_prime is [1.2507995]\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "accuracy is  0.804166666666667\n",
      "trial #210\n",
      "reward is 0.2 output_prime is [1.2377778]\n",
      "reward is 0.4166666666666667 output_prime is [1.3369176]\n",
      "reward is 0.2 output_prime is [1.7432338]\n",
      "reward is 0.5041666666666667 output_prime is [0.3784713]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [0.83868784]\n",
      "reward is 0.378125 output_prime is [0.24938497]\n",
      "reward is -1 output_prime is -1\n",
      "trial #211\n",
      "reward is 0.45 output_prime is [0.49088442]\n",
      "reward is -1 output_prime is [-1.1316818]\n",
      "reward is 0.2 output_prime is [1.6838977]\n",
      "reward is 0.20833333333333334 output_prime is [0.6773028]\n",
      "reward is 0.4166666666666667 output_prime is [1.0640607]\n",
      "reward is -1 output_prime is [-1.1354657]\n",
      "reward is 0.20833333333333334 output_prime is [0.9327894]\n",
      "reward is 0.225 output_prime is [1.542382]\n",
      "trial #212\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [1.2729857]\n",
      "reward is 0.3125 output_prime is [0.92104137]\n",
      "reward is 0.20833333333333334 output_prime is [0.97511417]\n",
      "reward is 0.05 output_prime is [1.7707142]\n",
      "reward is 0.20833333333333334 output_prime is [1.3337027]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "trial #213\n",
      "reward is -1 output_prime is [-0.799473]\n",
      "reward is -0.5 output_prime is [0.82220554]\n",
      "reward is -1 output_prime is [-1.1466084]\n",
      "reward is -1 output_prime is [-1.1474375]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-0.12711686]\n",
      "reward is 0.05 output_prime is [1.8132089]\n",
      "reward is 0.05 output_prime is [1.4609038]\n",
      "trial #214\n",
      "reward is -1 output_prime is [-0.7746143]\n",
      "reward is 0.3 output_prime is [0.83430487]\n",
      "reward is -1 output_prime is [-1.1529701]\n",
      "reward is 0.2 output_prime is [1.6515107]\n",
      "reward is 0.20833333333333334 output_prime is [1.3286381]\n",
      "reward is -1 output_prime is [0.22087419]\n",
      "reward is -1 output_prime is [-1.1554202]\n",
      "reward is -1 output_prime is [-1.1560214]\n",
      "trial #215\n",
      "reward is 0.2 output_prime is [1.6329911]\n",
      "reward is -1 output_prime is [-0.9545152]\n",
      "reward is 0.20833333333333334 output_prime is [0.53713036]\n",
      "reward is -0.5 output_prime is [-0.6583828]\n",
      "reward is 0.378125 output_prime is [0.21918981]\n",
      "reward is 0.2 output_prime is [1.7712308]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [0.83463883]\n",
      "trial #216\n",
      "reward is 0.378125 output_prime is [0.8952666]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [0.29681832]\n",
      "reward is 0.05 output_prime is [1.5095356]\n",
      "reward is -1 output_prime is [0.6212865]\n",
      "reward is 0.20833333333333334 output_prime is [0.8687975]\n",
      "reward is 0.20833333333333334 output_prime is [1.1314092]\n",
      "reward is -1 output_prime is [-0.33181864]\n",
      "trial #217\n",
      "reward is -1 output_prime is [-1.1663394]\n",
      "reward is 0.05 output_prime is [1.6645827]\n",
      "reward is 0.6125 output_prime is [1.3783512]\n",
      "reward is 0.3375 output_prime is [1.4801437]\n",
      "reward is -1 output_prime is [0.4280275]\n",
      "reward is 0.1 output_prime is [1.625867]\n",
      "reward is 0.3125 output_prime is [0.14235847]\n",
      "reward is 0.45 output_prime is [0.27929628]\n",
      "trial #218\n",
      "reward is 0.253125 output_prime is [1.1141615]\n",
      "reward is -0.5 output_prime is [0.7196269]\n",
      "reward is -0.5 output_prime is [-0.67239183]\n",
      "reward is -1 output_prime is [-1.1729755]\n",
      "reward is -1 output_prime is [-0.05400342]\n",
      "reward is 0.1 output_prime is [1.193082]\n",
      "reward is 0.05 output_prime is [-0.1248285]\n",
      "reward is 0.20833333333333334 output_prime is [1.5779978]\n",
      "trial #219\n",
      "reward is 0.20833333333333334 output_prime is [1.3449107]\n",
      "reward is -0.5 output_prime is [-0.32761246]\n",
      "reward is -1 output_prime is [-1.177534]\n",
      "reward is -1 output_prime is [-1.1782491]\n",
      "reward is 0.05 output_prime is [-0.12899424]\n",
      "reward is -0.5 output_prime is [-0.679763]\n",
      "reward is -1 output_prime is [0.32901835]\n",
      "reward is -1 output_prime is [-0.01803827]\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "accuracy is  0.6833333333333336\n",
      "trial #220\n",
      "reward is 0.20833333333333334 output_prime is [1.6404477]\n",
      "reward is 0.05 output_prime is [1.4310045]\n",
      "reward is 0.3 output_prime is [1.0693295]\n",
      "reward is -1 output_prime is [0.79495454]\n",
      "reward is 0.2 output_prime is [0.0058655]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.4337128]\n",
      "trial #221\n",
      "reward is 0.2 output_prime is [0.8026847]\n",
      "reward is -1 output_prime is [-1.2087349]\n",
      "reward is 0.225 output_prime is [1.1550202]\n",
      "reward is 0.3375 output_prime is [1.0915847]\n",
      "reward is 0.2 output_prime is [1.7338731]\n",
      "reward is -1 output_prime is [-1.108453]\n",
      "reward is 0.2 output_prime is [1.0673065]\n",
      "reward is -1 output_prime is -1\n",
      "trial #222\n",
      "reward is 0.2 output_prime is [1.4675995]\n",
      "reward is 0.378125 output_prime is [0.18312201]\n",
      "reward is 0.3125 output_prime is [1.2222488]\n",
      "reward is 0.2 output_prime is [1.7485552]\n",
      "reward is 0.05 output_prime is [1.5331199]\n",
      "reward is 0.26666666666666666 output_prime is [1.657091]\n",
      "reward is 0.5041666666666667 output_prime is [0.23581836]\n",
      "reward is 1 output_prime is 1\n",
      "trial #223\n",
      "reward is -1 output_prime is [-0.22756696]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [0.09227231]\n",
      "reward is 0.05 output_prime is [1.5729496]\n",
      "reward is -1 output_prime is [-1.2939258]\n",
      "reward is -1 output_prime is [-0.76861924]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "trial #224\n",
      "reward is 0.05 output_prime is [1.5399455]\n",
      "reward is 0.3375 output_prime is [1.7899387]\n",
      "reward is -0.5 output_prime is [-0.7518728]\n",
      "reward is -0.5 output_prime is [-0.16082749]\n",
      "reward is 0.3125 output_prime is [1.2216547]\n",
      "reward is 0.3375 output_prime is [0.93184495]\n",
      "reward is 0.05 output_prime is [1.5518247]\n",
      "reward is 0.2 output_prime is [1.8648465]\n",
      "trial #225\n",
      "reward is 0.27222222222222225 output_prime is [1.0968156]\n",
      "reward is 0.2 output_prime is [1.8016881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is [-0.13302141]\n",
      "reward is -0.5 output_prime is [0.01001167]\n",
      "reward is 0.703125 output_prime is [0.6591063]\n",
      "reward is 0.2 output_prime is [0.87730396]\n",
      "reward is 0.20416666666666666 output_prime is [0.7745424]\n",
      "reward is 0.20833333333333334 output_prime is [1.0188593]\n",
      "trial #226\n",
      "reward is 0.20833333333333334 output_prime is [1.0884578]\n",
      "reward is -1 output_prime is [-1.3539587]\n",
      "reward is 0.2 output_prime is [1.6766077]\n",
      "reward is 0.4 output_prime is [1.6610684]\n",
      "reward is 0.4166666666666667 output_prime is [1.2201672]\n",
      "reward is -1 output_prime is [0.04025817]\n",
      "reward is 0.2 output_prime is [1.8051958]\n",
      "reward is -1 output_prime is [-0.92691946]\n",
      "trial #227\n",
      "reward is -1 output_prime is [0.03289485]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.3882669]\n",
      "reward is 0.2 output_prime is [1.8430005]\n",
      "reward is 0.5041666666666667 output_prime is [1.0115278]\n",
      "reward is 0.2 output_prime is [1.3160753]\n",
      "reward is -1 output_prime is [-0.14947915]\n",
      "reward is 0.2 output_prime is [1.0833814]\n",
      "trial #228\n",
      "reward is 0.26666666666666666 output_prime is [1.2086579]\n",
      "reward is 0.225 output_prime is [1.1052322]\n",
      "reward is 0.2 output_prime is [1.0920446]\n",
      "reward is 0.4 output_prime is [1.696728]\n",
      "reward is 0.378125 output_prime is [1.0388663]\n",
      "reward is 0.05 output_prime is [1.5787427]\n",
      "reward is 0.2 output_prime is [1.6524795]\n",
      "reward is -0.5 output_prime is [-0.8676717]\n",
      "trial #229\n",
      "reward is -1 output_prime is [-1.3670942]\n",
      "reward is 0.05 output_prime is [0.5586068]\n",
      "reward is 0.20833333333333334 output_prime is [1.2709851]\n",
      "reward is 0.20833333333333334 output_prime is [1.5143634]\n",
      "reward is -1 output_prime is [-0.44678366]\n",
      "reward is -1 output_prime is [0.43228424]\n",
      "reward is -1 output_prime is [0.12765837]\n",
      "reward is 0.20833333333333334 output_prime is [1.7351134]\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.875\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.7312500000000002\n",
      "trial #230\n",
      "reward is 0.2 output_prime is [1.5570674]\n",
      "reward is 0.5041666666666667 output_prime is [0.14562446]\n",
      "reward is -1 output_prime is [-1.3578231]\n",
      "reward is 0.05 output_prime is [-0.3072134]\n",
      "reward is -0.5 output_prime is [0.93826544]\n",
      "reward is -1 output_prime is [-1.3561983]\n",
      "reward is 0.05 output_prime is [0.91428435]\n",
      "reward is 0.2 output_prime is [1.3862078]\n",
      "trial #231\n",
      "reward is 0.253125 output_prime is [1.6153145]\n",
      "reward is 0.2 output_prime is [1.3169484]\n",
      "reward is 0.05 output_prime is [1.0853057]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.3320998]\n",
      "reward is -1 output_prime is [-0.62856746]\n",
      "reward is 0.528125 output_prime is [1.5184345]\n",
      "reward is 0.20833333333333334 output_prime is [1.5366353]\n",
      "trial #232\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [1.3179418]\n",
      "reward is -0.5 output_prime is [-0.74917215]\n",
      "reward is 0.05 output_prime is [1.490263]\n",
      "reward is 0.378125 output_prime is [1.0577631]\n",
      "reward is 0.3125 output_prime is [-0.04483819]\n",
      "reward is -1 output_prime is [0.16736674]\n",
      "reward is 0.45 output_prime is [0.09070191]\n",
      "trial #233\n",
      "reward is -1 output_prime is [-1.3605707]\n",
      "reward is -1 output_prime is [0.27917373]\n",
      "reward is 0.05 output_prime is [1.4783181]\n",
      "reward is -1 output_prime is [0.17462659]\n",
      "reward is -1 output_prime is [-0.03497618]\n",
      "reward is 0.05 output_prime is [0.36752662]\n",
      "reward is -1 output_prime is [-0.09330624]\n",
      "reward is -1 output_prime is [0.66747725]\n",
      "trial #234\n",
      "reward is 0.5041666666666667 output_prime is [0.12919062]\n",
      "reward is -1 output_prime is [-0.3190946]\n",
      "reward is -1 output_prime is [-0.40924585]\n",
      "reward is 0.05 output_prime is [1.3463444]\n",
      "reward is 0.253125 output_prime is [1.558459]\n",
      "reward is -1 output_prime is [0.30274332]\n",
      "reward is -1 output_prime is [0.4175818]\n",
      "reward is -1 output_prime is [0.6726451]\n",
      "trial #235\n",
      "reward is -1 output_prime is [-0.35047638]\n",
      "reward is 0.05 output_prime is [1.0274081]\n",
      "reward is 0.05 output_prime is [1.4647194]\n",
      "reward is 0.2 output_prime is [1.2506158]\n",
      "reward is 0.05 output_prime is [0.9685166]\n",
      "reward is 0.05 output_prime is [1.359617]\n",
      "reward is 0.05 output_prime is [0.9350244]\n",
      "reward is -1 output_prime is [0.3621807]\n",
      "trial #236\n",
      "reward is 0.4166666666666667 output_prime is [0.01567659]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.7136737]\n",
      "reward is 0.05 output_prime is [0.65380776]\n",
      "reward is -1 output_prime is [-1.408911]\n",
      "reward is -1 output_prime is [-0.8284405]\n",
      "reward is -1 output_prime is [-0.3537078]\n",
      "reward is -1 output_prime is [0.32069898]\n",
      "trial #237\n",
      "reward is 0.26666666666666666 output_prime is [1.0895249]\n",
      "reward is 0.2 output_prime is [1.5418137]\n",
      "reward is -1 output_prime is [0.05036926]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.4331548]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [1.0050373]\n",
      "reward is -1 output_prime is -1\n",
      "trial #238\n",
      "reward is 0.2 output_prime is [1.545137]\n",
      "reward is 0.4 output_prime is [1.5184739]\n",
      "reward is 0.45 output_prime is [-0.00210813]\n",
      "reward is -1 output_prime is [-0.22315103]\n",
      "reward is -1 output_prime is [-1.4559911]\n",
      "reward is 0.05 output_prime is [1.4150271]\n",
      "reward is 0.378125 output_prime is [0.73230773]\n",
      "reward is -1 output_prime is [-0.89947176]\n",
      "trial #239\n",
      "reward is 0.05 output_prime is [1.0838565]\n",
      "reward is 0.4 output_prime is [1.0764368]\n",
      "reward is 0.26666666666666666 output_prime is [1.1796759]\n",
      "reward is 0.2 output_prime is [0.48144966]\n",
      "reward is 0.05 output_prime is [1.4211881]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.35315233]\n",
      "reward is 0.05 output_prime is [1.4822624]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.7375\n",
      "trial #240\n",
      "reward is 0.2 output_prime is [1.5170907]\n",
      "reward is -0.5 output_prime is [0.8453413]\n",
      "reward is 0.2 output_prime is [1.2580519]\n",
      "reward is 0.378125 output_prime is [-0.09061176]\n",
      "reward is 0.2 output_prime is [1.6985301]\n",
      "reward is -0.5 output_prime is [-0.9704092]\n",
      "reward is 0.378125 output_prime is [-0.09316564]\n",
      "reward is 0.2 output_prime is [1.5220299]\n",
      "trial #241\n",
      "reward is 0.2 output_prime is [1.6589333]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.6167141]\n",
      "reward is -1 output_prime is [-0.1086725]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.233532]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [-0.2772445]\n",
      "trial #242\n",
      "reward is 0.05 output_prime is [0.8306665]\n",
      "reward is -0.5 output_prime is [0.29399312]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.107405]\n",
      "reward is -1 output_prime is [-1.474652]\n",
      "reward is -0.5 output_prime is [-0.25698984]\n",
      "reward is -1 output_prime is [0.26142287]\n",
      "reward is 0.2 output_prime is [1.583192]\n",
      "trial #243\n",
      "reward is 0.05 output_prime is [-0.42438585]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.4748969]\n",
      "reward is 0.05 output_prime is [1.3874747]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [1.0125902]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.4747579]\n",
      "trial #244\n",
      "reward is 0.05 output_prime is [1.4351535]\n",
      "reward is -1 output_prime is -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is [-1.4747972]\n",
      "reward is -1 output_prime is [0.16517997]\n",
      "reward is 0.26666666666666666 output_prime is [1.5704646]\n",
      "reward is -0.5 output_prime is [0.7141788]\n",
      "reward is 0.45 output_prime is [-0.0240081]\n",
      "reward is 0.2 output_prime is [1.294069]\n",
      "trial #245\n",
      "reward is 0.378125 output_prime is [0.8172219]\n",
      "reward is 0.1 output_prime is [1.367153]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [0.96921855]\n",
      "reward is -0.5 output_prime is [-0.10065499]\n",
      "reward is -1 output_prime is [-1.4695021]\n",
      "reward is 0.05 output_prime is [0.82759553]\n",
      "reward is -0.5 output_prime is [0.18895203]\n",
      "trial #246\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [-0.41614053]\n",
      "reward is -1 output_prime is [0.5842477]\n",
      "reward is -0.5 output_prime is [-0.96468776]\n",
      "reward is 0.05 output_prime is [1.3717165]\n",
      "reward is 0.4166666666666667 output_prime is [0.90144795]\n",
      "reward is 0.20833333333333334 output_prime is [1.0081775]\n",
      "reward is 0.4166666666666667 output_prime is [-0.04568475]\n",
      "trial #247\n",
      "reward is 0.1 output_prime is [1.227967]\n",
      "reward is 0.3375 output_prime is [1.2508644]\n",
      "reward is -1 output_prime is [0.5780896]\n",
      "reward is 0.05 output_prime is [1.1299441]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.5828928]\n",
      "reward is 0.2 output_prime is [1.3933449]\n",
      "trial #248\n",
      "reward is 0.05 output_prime is [0.98916334]\n",
      "reward is 0.4166666666666667 output_prime is [1.0760703]\n",
      "reward is 0.3 output_prime is [1.4067941]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.6 output_prime is [0.14790082]\n",
      "reward is -1 output_prime is [-0.2814551]\n",
      "reward is 0.05 output_prime is [1.5300512]\n",
      "reward is 0.05 output_prime is [1.5047927]\n",
      "trial #249\n",
      "reward is 0.2 output_prime is [1.4871304]\n",
      "reward is 0.26666666666666666 output_prime is [0.9264915]\n",
      "reward is 0.05 output_prime is [1.4353263]\n",
      "reward is -1 output_prime is [0.01813757]\n",
      "reward is -1 output_prime is [-0.39105606]\n",
      "reward is 0.3375 output_prime is [-0.10990667]\n",
      "reward is 0.2 output_prime is [0.8928625]\n",
      "reward is 0.05 output_prime is [1.370409]\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.375\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "accuracy is  0.6916666666666665\n",
      "trial #250\n",
      "reward is 0.05 output_prime is [1.4391071]\n",
      "reward is 0.05 output_prime is [0.8475511]\n",
      "reward is 0.378125 output_prime is [0.7662263]\n",
      "reward is 0.45 output_prime is [-0.00107998]\n",
      "reward is -1 output_prime is [-0.5604023]\n",
      "reward is -0.5 output_prime is [-0.9533454]\n",
      "reward is -0.5 output_prime is [0.55899584]\n",
      "reward is -1 output_prime is [-1.4558886]\n",
      "trial #251\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [1.4617299]\n",
      "reward is 0.378125 output_prime is [-0.08231294]\n",
      "reward is 0.1 output_prime is [1.1437727]\n",
      "reward is -1 output_prime is [-1.4635277]\n",
      "reward is 0.05 output_prime is [1.4198178]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #252\n",
      "reward is 0.1 output_prime is [-0.368884]\n",
      "reward is -1 output_prime is [-0.07818586]\n",
      "reward is -1 output_prime is [-1.3606575]\n",
      "reward is 0.26666666666666666 output_prime is [1.4512292]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.4981302]\n",
      "reward is -1 output_prime is [0.1854173]\n",
      "reward is 0.05 output_prime is [1.027486]\n",
      "trial #253\n",
      "reward is 0.27222222222222225 output_prime is [-0.21007892]\n",
      "reward is -0.5 output_prime is [0.4944479]\n",
      "reward is -1 output_prime is [0.5061573]\n",
      "reward is -1 output_prime is [-1.4853368]\n",
      "reward is 0.2 output_prime is [1.079662]\n",
      "reward is 0.2 output_prime is [1.2980695]\n",
      "reward is -1 output_prime is [-1.4873546]\n",
      "reward is -0.5 output_prime is [-0.23158222]\n",
      "trial #254\n",
      "reward is 0.20833333333333334 output_prime is [1.1393504]\n",
      "reward is 0.20833333333333334 output_prime is [1.1103983]\n",
      "reward is -0.5 output_prime is [-0.9901792]\n",
      "reward is 0.05 output_prime is [0.70552105]\n",
      "reward is 0.3375 output_prime is [-0.15515152]\n",
      "reward is 0.05 output_prime is [0.9651906]\n",
      "reward is -1 output_prime is [-1.4955568]\n",
      "reward is -1 output_prime is [-0.3993039]\n",
      "trial #255\n",
      "reward is 0.3125 output_prime is [0.71996677]\n",
      "reward is -1 output_prime is [-0.2624231]\n",
      "reward is 0.20833333333333334 output_prime is [1.4065686]\n",
      "reward is -1 output_prime is [-1.5047874]\n",
      "reward is -1 output_prime is [-0.34663236]\n",
      "reward is 0.05 output_prime is [1.348921]\n",
      "reward is -0.5 output_prime is [-1.0122379]\n",
      "reward is 0.20833333333333334 output_prime is [-0.30664748]\n",
      "trial #256\n",
      "reward is 0.378125 output_prime is [0.69238937]\n",
      "reward is -1 output_prime is [-1.5208175]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [0.31652188]\n",
      "reward is 0.05 output_prime is [1.2223502]\n",
      "reward is 0.05 output_prime is [1.2790146]\n",
      "hi\n",
      "reward is 0.05 output_prime is [-0.48793566]\n",
      "trial #257\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.1019988]\n",
      "reward is 0.05 output_prime is [1.3570569]\n",
      "reward is 0.05 output_prime is [1.356192]\n",
      "reward is -1 output_prime is [-1.2462976]\n",
      "reward is 0.2 output_prime is [1.4677211]\n",
      "reward is 0.05 output_prime is [1.352949]\n",
      "reward is 0.05 output_prime is [1.3850074]\n",
      "trial #258\n",
      "reward is 0.20833333333333334 output_prime is [1.3614427]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [0.7331464]\n",
      "reward is 0.2 output_prime is [1.4405638]\n",
      "reward is 0.05 output_prime is [1.1713046]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.2138848]\n",
      "reward is -1 output_prime is -1\n",
      "trial #259\n",
      "reward is 0.26666666666666666 output_prime is [0.8012537]\n",
      "reward is 0.225 output_prime is [1.325558]\n",
      "reward is 0.3375 output_prime is [0.89013946]\n",
      "reward is 0.3125 output_prime is [0.8828564]\n",
      "reward is 0.05 output_prime is [1.065619]\n",
      "reward is 0.2 output_prime is [1.4847332]\n",
      "reward is 0.05 output_prime is [1.0801871]\n",
      "reward is 0.05 output_prime is [1.1232462]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.4375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.80625\n",
      "trial #260\n",
      "reward is -1 output_prime is [-1.583775]\n",
      "reward is 0.3 output_prime is [0.7094245]\n",
      "reward is -1 output_prime is [-1.5853367]\n",
      "reward is 0.20833333333333334 output_prime is [1.0854506]\n",
      "reward is 0.20833333333333334 output_prime is [0.60140663]\n",
      "reward is -1 output_prime is [-0.11327106]\n",
      "reward is 0.05 output_prime is [1.1767733]\n",
      "reward is -1 output_prime is [0.43770087]\n",
      "trial #261\n",
      "reward is 0.05 output_prime is [1.0400169]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [0.4835265]\n",
      "reward is 0.05 output_prime is [-0.54424137]\n",
      "reward is 0.5041666666666667 output_prime is [-0.0920366]\n",
      "reward is 0.253125 output_prime is [1.1180553]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #262\n",
      "reward is -0.5 output_prime is [-1.1035985]\n",
      "reward is 0.05 output_prime is [1.1381148]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.4001716]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [0.9237684]\n",
      "reward is -1 output_prime is [0.40331578]\n",
      "reward is -1 output_prime is [-1.6278782]\n",
      "trial #263\n",
      "reward is 0.26666666666666666 output_prime is [0.88186944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.05 output_prime is [1.306732]\n",
      "reward is 0.05 output_prime is [1.3940756]\n",
      "reward is 0.2 output_prime is [1.429411]\n",
      "reward is 0.05 output_prime is [0.79143673]\n",
      "reward is -0.5 output_prime is [0.5474986]\n",
      "reward is 0.6125 output_prime is [0.73203415]\n",
      "reward is -1 output_prime is -1\n",
      "trial #264\n",
      "reward is -1 output_prime is [-1.6401808]\n",
      "reward is -1 output_prime is [0.23520291]\n",
      "reward is -1 output_prime is [0.40844297]\n",
      "reward is 0.378125 output_prime is [0.9573756]\n",
      "reward is 0.3375 output_prime is [1.2641346]\n",
      "reward is -1 output_prime is [-0.6371488]\n",
      "reward is 0.05 output_prime is [1.1305758]\n",
      "reward is -1 output_prime is -1\n",
      "trial #265\n",
      "reward is 0.05 output_prime is [1.1238309]\n",
      "reward is -0.5 output_prime is [-1.1396081]\n",
      "reward is 0.05 output_prime is [-0.58888245]\n",
      "reward is 0.2 output_prime is [1.0827379]\n",
      "reward is -1 output_prime is [-0.20525247]\n",
      "reward is 0.3375 output_prime is [-0.29981568]\n",
      "reward is 0.3125 output_prime is [0.756956]\n",
      "reward is 0.2 output_prime is [0.6592069]\n",
      "trial #266\n",
      "reward is 0.05 output_prime is [1.1509979]\n",
      "reward is 0.05 output_prime is [0.86302394]\n",
      "reward is 0.528125 output_prime is [1.10557]\n",
      "reward is 0.378125 output_prime is [-0.25793725]\n",
      "reward is 0.4166666666666667 output_prime is [0.91785085]\n",
      "reward is -1 output_prime is [-0.0958181]\n",
      "hi\n",
      "reward is 0.6 output_prime is [-0.03524184]\n",
      "trial #267\n",
      "reward is -1 output_prime is [-0.3615085]\n",
      "reward is -1 output_prime is [-1.6344332]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.64786166]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.6339204]\n",
      "reward is -1 output_prime is [-0.6415322]\n",
      "reward is 0.4166666666666667 output_prime is [0.9085441]\n",
      "trial #268\n",
      "reward is 0.1 output_prime is [1.0168761]\n",
      "reward is 0.05 output_prime is [0.77584016]\n",
      "reward is -1 output_prime is [0.32566988]\n",
      "reward is 0.2 output_prime is [0.8871533]\n",
      "reward is 0.05 output_prime is [1.3232895]\n",
      "reward is 0.1 output_prime is [1.0390934]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [0.7473163]\n",
      "trial #269\n",
      "reward is 0.378125 output_prime is [-0.27452743]\n",
      "reward is -0.5 output_prime is [-0.24536675]\n",
      "reward is 0.3125 output_prime is [0.48988542]\n",
      "reward is 0.378125 output_prime is [-0.28272218]\n",
      "reward is -1 output_prime is [0.32082307]\n",
      "reward is 0.2 output_prime is [0.9959726]\n",
      "reward is -1 output_prime is [-1.2645419]\n",
      "reward is 0.4166666666666667 output_prime is [0.7685591]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "accuracy is  0.760416666666667\n",
      "trial #270\n",
      "reward is 0.2 output_prime is [1.3845173]\n",
      "reward is 0.20833333333333334 output_prime is [1.2738879]\n",
      "reward is -1 output_prime is [-0.49158674]\n",
      "reward is 0.3375 output_prime is [0.694631]\n",
      "reward is -1 output_prime is [-1.6790913]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.6811426]\n",
      "reward is -1 output_prime is -1\n",
      "trial #271\n",
      "reward is 0.20833333333333334 output_prime is [0.7829362]\n",
      "reward is 0.20833333333333334 output_prime is [0.9352673]\n",
      "reward is 0.05 output_prime is [1.1605073]\n",
      "reward is 0.20416666666666666 output_prime is [-0.48394948]\n",
      "reward is 0.45 output_prime is [-0.2397945]\n",
      "reward is -1 output_prime is [-1.6913999]\n",
      "reward is -0.5 output_prime is [-0.14228103]\n",
      "reward is 0.3125 output_prime is [0.90346247]\n",
      "trial #272\n",
      "reward is 0.20833333333333334 output_prime is [0.94924134]\n",
      "reward is -1 output_prime is [0.13528156]\n",
      "reward is 0.05 output_prime is [0.5941498]\n",
      "reward is -1 output_prime is [-0.7011448]\n",
      "reward is 0.3 output_prime is [1.3827853]\n",
      "reward is 0.05 output_prime is [1.0301789]\n",
      "reward is -1 output_prime is [-0.4014712]\n",
      "reward is 0.2 output_prime is [1.3233935]\n",
      "trial #273\n",
      "reward is -1 output_prime is [-1.7091476]\n",
      "reward is -1 output_prime is [-1.7098155]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [-0.37378296]\n",
      "reward is -1 output_prime is [-0.49095172]\n",
      "reward is -1 output_prime is [-1.7126689]\n",
      "reward is 0.2 output_prime is [0.9955876]\n",
      "reward is -1 output_prime is -1\n",
      "trial #274\n",
      "reward is 0.225 output_prime is [1.2436593]\n",
      "reward is 0.2 output_prime is [1.1875151]\n",
      "reward is -1 output_prime is [-0.17650157]\n",
      "reward is 0.2 output_prime is [0.48335052]\n",
      "reward is 0.05 output_prime is [0.9723294]\n",
      "reward is -1 output_prime is [0.3386265]\n",
      "reward is 0.05 output_prime is [0.7889435]\n",
      "reward is 0.05 output_prime is [1.1978607]\n",
      "trial #275\n",
      "reward is 0.378125 output_prime is [-0.3451714]\n",
      "reward is 0.05 output_prime is [1.1814739]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [0.17808759]\n",
      "reward is 0.2 output_prime is [1.182749]\n",
      "reward is 0.20416666666666666 output_prime is [-0.52315503]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.15546238]\n",
      "trial #276\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.4 output_prime is [0.8421521]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.4105683]\n",
      "reward is 0.26666666666666666 output_prime is [1.3732195]\n",
      "reward is -0.5 output_prime is [0.42093033]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.1649104]\n",
      "trial #277\n",
      "reward is -1 output_prime is [-0.22737068]\n",
      "reward is 0.05 output_prime is [0.97187024]\n",
      "reward is 0.2 output_prime is [1.4151765]\n",
      "reward is 0.3125 output_prime is [1.0734813]\n",
      "reward is 0.20833333333333334 output_prime is [0.78164095]\n",
      "reward is 0.2 output_prime is [1.3539962]\n",
      "hi\n",
      "reward is -0.5 output_prime is [-1.2272737]\n",
      "trial #278\n",
      "reward is -1 output_prime is [-0.8859415]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [0.78810346]\n",
      "reward is 0.45 output_prime is [-0.27607745]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.1631678]\n",
      "reward is 0.378125 output_prime is [-0.34780604]\n",
      "reward is -1 output_prime is [-0.93862617]\n",
      "trial #279\n",
      "reward is -1 output_prime is [-0.62632275]\n",
      "reward is 0.27222222222222225 output_prime is [-0.4542235]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [0.69280446]\n",
      "reward is 0.05 output_prime is [1.2303563]\n",
      "reward is 0.45 output_prime is [-0.27783453]\n",
      "reward is -1 output_prime is [-1.7281444]\n",
      "reward is 0.05 output_prime is [1.1746557]\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.8687500000000001\n",
      "trial #280\n",
      "reward is 0.4166666666666667 output_prime is [0.54850835]\n",
      "reward is 0.378125 output_prime is [-0.35046476]\n",
      "reward is -1 output_prime is [-0.1566847]\n",
      "reward is 0.05 output_prime is [1.0758828]\n",
      "reward is 0.253125 output_prime is [1.2514381]\n",
      "reward is 0.3375 output_prime is [0.816698]\n",
      "reward is -1 output_prime is [-0.6547647]\n",
      "reward is 0.05 output_prime is [0.82816464]\n",
      "trial #281\n",
      "reward is 0.2 output_prime is [0.8858335]\n",
      "reward is 0.05 output_prime is [-0.67562664]\n",
      "reward is 0.20833333333333334 output_prime is [1.174412]\n",
      "reward is 0.20416666666666666 output_prime is [0.2457439]\n",
      "reward is 0.225 output_prime is [1.2108399]\n",
      "reward is -1 output_prime is [-0.59185004]\n",
      "reward is 0.05 output_prime is [0.9750795]\n",
      "reward is 0.05 output_prime is [0.85724723]\n",
      "trial #282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.3125 output_prime is [0.93526614]\n",
      "reward is 0.378125 output_prime is [-0.34407675]\n",
      "reward is 0.05 output_prime is [0.9912939]\n",
      "reward is 0.2 output_prime is [0.71933115]\n",
      "reward is 0.3375 output_prime is [1.5591584]\n",
      "reward is 0.3 output_prime is [0.19940929]\n",
      "reward is 0.26666666666666666 output_prime is [0.8416207]\n",
      "reward is 0.378125 output_prime is [0.6020158]\n",
      "trial #283\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.1357195]\n",
      "reward is -1 output_prime is [-0.57129276]\n",
      "reward is 0.1125 output_prime is [0.82011646]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.1060884]\n",
      "reward is -1 output_prime is [0.05657828]\n",
      "reward is 0.20833333333333334 output_prime is [0.6114711]\n",
      "trial #284\n",
      "reward is 0.4 output_prime is [0.8155596]\n",
      "reward is 0.20833333333333334 output_prime is [0.99490356]\n",
      "reward is 0.3375 output_prime is [-0.37700644]\n",
      "reward is 0.3375 output_prime is [0.90196645]\n",
      "reward is 0.20833333333333334 output_prime is [1.2383031]\n",
      "reward is -1 output_prime is [-1.7147865]\n",
      "reward is 0.2 output_prime is [1.2729875]\n",
      "reward is -0.5 output_prime is [-1.0704975]\n",
      "trial #285\n",
      "reward is -0.5 output_prime is [-1.2141976]\n",
      "reward is 0.3125 output_prime is [0.49625182]\n",
      "reward is -1 output_prime is [-0.5425252]\n",
      "reward is 0.378125 output_prime is [-0.33532047]\n",
      "reward is -1 output_prime is [-1.7130619]\n",
      "reward is 0.1125 output_prime is [1.3101199]\n",
      "reward is 0.253125 output_prime is [1.2002791]\n",
      "reward is 0.2 output_prime is [1.5010786]\n",
      "trial #286\n",
      "reward is 0.3 output_prime is [1.3609023]\n",
      "reward is 0.30625 output_prime is [0.4672749]\n",
      "reward is 0.2 output_prime is [1.0067818]\n",
      "reward is 0.20833333333333334 output_prime is [1.3793756]\n",
      "reward is -1 output_prime is [-1.7148912]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is 0.1125 output_prime is [1.0916055]\n",
      "trial #287\n",
      "reward is 0.2 output_prime is [1.2617748]\n",
      "reward is 0.3 output_prime is [0.5301827]\n",
      "reward is -1 output_prime is [-0.0618068]\n",
      "reward is 0.20833333333333334 output_prime is [1.1130424]\n",
      "reward is 0.05 output_prime is [1.3287113]\n",
      "reward is -1 output_prime is [-1.7332137]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [0.52682287]\n",
      "trial #288\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.703125 output_prime is [0.30126885]\n",
      "reward is -1 output_prime is [-0.0248751]\n",
      "reward is 0.05 output_prime is [-0.6990677]\n",
      "reward is 0.05 output_prime is [1.0275942]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [-0.4447968]\n",
      "reward is -1 output_prime is -1\n",
      "trial #289\n",
      "reward is 0.3125 output_prime is [0.86702543]\n",
      "reward is -1 output_prime is [-1.7613869]\n",
      "reward is -1 output_prime is [-1.0360079]\n",
      "reward is 0.2 output_prime is [1.2422906]\n",
      "reward is -1 output_prime is [-1.7615898]\n",
      "reward is 0.1 output_prime is [0.7114398]\n",
      "reward is -1 output_prime is [-0.31290084]\n",
      "reward is 0.2 output_prime is [1.2349762]\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.8166666666666668\n",
      "trial #290\n",
      "reward is 0.2 output_prime is [1.2321975]\n",
      "reward is 0.05 output_prime is [0.47016564]\n",
      "reward is 0.05 output_prime is [1.0592929]\n",
      "reward is 0.05 output_prime is [0.8832028]\n",
      "reward is -1 output_prime is [-0.37011617]\n",
      "reward is 0.20833333333333334 output_prime is [1.0053487]\n",
      "reward is -1 output_prime is [-1.7568848]\n",
      "reward is 0.3125 output_prime is [1.0593209]\n",
      "trial #291\n",
      "reward is 0.30625 output_prime is [0.5644604]\n",
      "reward is 0.225 output_prime is [0.8040451]\n",
      "reward is -1 output_prime is [-0.60070443]\n",
      "reward is 0.05 output_prime is [0.9622466]\n",
      "reward is 0.05 output_prime is [0.38851494]\n",
      "reward is -0.5 output_prime is [0.18103969]\n",
      "hi\n",
      "reward is 0.30625 output_prime is [1.5084791]\n",
      "trial #292\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.19053215]\n",
      "reward is 0.45 output_prime is [-0.29673374]\n",
      "reward is 0.1 output_prime is [0.7866179]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.236388]\n",
      "reward is 0.4166666666666667 output_prime is [0.6126258]\n",
      "reward is 0.4166666666666667 output_prime is [-0.32236287]\n",
      "trial #293\n",
      "reward is 0.20416666666666666 output_prime is [0.32705808]\n",
      "reward is 0.26666666666666666 output_prime is [1.2091684]\n",
      "reward is 0.05 output_prime is [1.3202306]\n",
      "reward is 0.27222222222222225 output_prime is [0.4785213]\n",
      "reward is 0.05 output_prime is [0.7594928]\n",
      "reward is 0.2 output_prime is [1.3804811]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.45 output_prime is [-0.2755248]\n",
      "trial #294\n",
      "reward is 0.2 output_prime is [1.3624513]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.48915857]\n",
      "reward is 0.45 output_prime is [-0.26971948]\n",
      "reward is 0.05 output_prime is [1.0154766]\n",
      "reward is 0.2 output_prime is [1.2336003]\n",
      "reward is 0.05 output_prime is [1.0579576]\n",
      "reward is 0.3375 output_prime is [0.9924462]\n",
      "trial #295\n",
      "reward is 0.05 output_prime is [0.82989985]\n",
      "reward is 0.30625 output_prime is [1.4363478]\n",
      "reward is -1 output_prime is [-1.7093768]\n",
      "reward is -1 output_prime is [-0.9227157]\n",
      "reward is -1 output_prime is [-0.55134034]\n",
      "reward is 0.20833333333333334 output_prime is [0.9663446]\n",
      "reward is -1 output_prime is [-1.701452]\n",
      "reward is -0.5 output_prime is [-1.1993668]\n",
      "trial #296\n",
      "reward is 0.2 output_prime is [1.2245985]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-0.56394076]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.76288486]\n",
      "reward is 0.05 output_prime is [1.0955278]\n",
      "reward is 0.20833333333333334 output_prime is [0.236867]\n",
      "reward is 0.378125 output_prime is [0.56997997]\n",
      "trial #297\n",
      "reward is -1 output_prime is [0.2813313]\n",
      "reward is 0.20416666666666666 output_prime is [0.19139355]\n",
      "reward is 0.6125 output_prime is [0.50259435]\n",
      "reward is 0.20833333333333334 output_prime is [1.1370177]\n",
      "reward is 0.05 output_prime is [-0.09794356]\n",
      "reward is -1 output_prime is [-0.40256673]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [1.2627635]\n",
      "trial #298\n",
      "reward is -1 output_prime is [-0.27978772]\n",
      "reward is 0.20416666666666666 output_prime is [0.14171481]\n",
      "reward is 0.20833333333333334 output_prime is [0.6474918]\n",
      "reward is 0.378125 output_prime is [0.88501257]\n",
      "reward is -1 output_prime is [-0.02559012]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [0.89554733]\n",
      "reward is 0.20833333333333334 output_prime is [1.1666087]\n",
      "trial #299\n",
      "reward is 0.2 output_prime is [1.3098215]\n",
      "reward is 0.20833333333333334 output_prime is [0.92166454]\n",
      "reward is 0.05 output_prime is [1.0475948]\n",
      "reward is 0.05 output_prime is [1.1693888]\n",
      "reward is 0.253125 output_prime is [1.1652732]\n",
      "reward is 0.20833333333333334 output_prime is [1.1100959]\n",
      "reward is 0.2 output_prime is [0.8428434]\n",
      "reward is 0.20833333333333334 output_prime is [1.19737]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.7937500000000003\n",
      "trial #300\n",
      "reward is 0.05 output_prime is [1.2638489]\n",
      "reward is -1 output_prime is [-0.48803544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is [-1.6692111]\n",
      "reward is 0.3125 output_prime is [0.8747916]\n",
      "reward is 0.05 output_prime is [-0.6217622]\n",
      "reward is 0.3375 output_prime is [1.0537806]\n",
      "reward is 0.3 output_prime is [0.7071508]\n",
      "reward is 0.2 output_prime is [1.2362435]\n",
      "trial #301\n",
      "reward is -0.5 output_prime is [-0.9738825]\n",
      "reward is 0.05 output_prime is [1.0680206]\n",
      "reward is 0.20833333333333334 output_prime is [0.60851634]\n",
      "reward is -0.5 output_prime is [0.32851875]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.20416666666666666 output_prime is [0.43198365]\n",
      "reward is -1 output_prime is -1\n",
      "trial #302\n",
      "reward is 0.3375 output_prime is [0.6140008]\n",
      "reward is 0.20833333333333334 output_prime is [0.7297744]\n",
      "reward is -1 output_prime is [-1.6716113]\n",
      "reward is 0.3375 output_prime is [1.0957135]\n",
      "reward is 0.05 output_prime is [0.5983634]\n",
      "reward is -0.5 output_prime is [0.5388038]\n",
      "reward is 0.3375 output_prime is [0.6395403]\n",
      "reward is 0.225 output_prime is [0.9544128]\n",
      "trial #303\n",
      "reward is 0.05 output_prime is [1.0359623]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.45 output_prime is [-0.23500806]\n",
      "reward is -1 output_prime is [0.25506425]\n",
      "reward is 0.378125 output_prime is [-0.31069767]\n",
      "reward is 0.05 output_prime is [0.8534694]\n",
      "reward is -1 output_prime is [0.26293504]\n",
      "reward is 0.4 output_prime is [0.57471]\n",
      "trial #304\n",
      "reward is 0.3375 output_prime is [0.815314]\n",
      "reward is 0.2 output_prime is [1.2141179]\n",
      "reward is 0.3375 output_prime is [0.89470553]\n",
      "reward is -1 output_prime is [-0.5258769]\n",
      "reward is 0.2 output_prime is [1.2032408]\n",
      "reward is 0.253125 output_prime is [1.1229309]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.08503586]\n",
      "trial #305\n",
      "reward is 0.703125 output_prime is [0.84618783]\n",
      "reward is -1 output_prime is [-0.08177912]\n",
      "reward is 0.2 output_prime is [-0.5171204]\n",
      "reward is 0.26666666666666666 output_prime is [0.8786596]\n",
      "reward is 0.05 output_prime is [1.0943713]\n",
      "reward is 0.3375 output_prime is [-0.3857253]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [0.24707556]\n",
      "trial #306\n",
      "reward is 0.3125 output_prime is [0.732942]\n",
      "reward is 0.3125 output_prime is [-0.41634643]\n",
      "reward is 0.1 output_prime is [1.063706]\n",
      "reward is 0.3375 output_prime is [1.5055581]\n",
      "reward is 0.45 output_prime is [0.5884042]\n",
      "reward is -0.5 output_prime is [-0.06118873]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-0.94435346]\n",
      "trial #307\n",
      "reward is 0.05 output_prime is [1.2804378]\n",
      "reward is -1 output_prime is [-1.7357266]\n",
      "reward is -1 output_prime is [-0.52427346]\n",
      "reward is 0.05 output_prime is [0.93587273]\n",
      "reward is -1 output_prime is [-1.7367275]\n",
      "reward is 0.3125 output_prime is [-0.42436224]\n",
      "reward is 0.2 output_prime is [1.0261022]\n",
      "reward is -1 output_prime is [-0.5011984]\n",
      "trial #308\n",
      "reward is -0.5 output_prime is [-1.2367561]\n",
      "reward is -1 output_prime is [-1.7364199]\n",
      "reward is -1 output_prime is [-1.7359395]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.3776846]\n",
      "reward is 0.05 output_prime is [1.1293539]\n",
      "reward is 0.05 output_prime is [0.11937867]\n",
      "reward is 0.2 output_prime is [1.2616364]\n",
      "trial #309\n",
      "reward is 0.6125 output_prime is [1.0698533]\n",
      "reward is 0.05 output_prime is [0.75858957]\n",
      "reward is 0.05 output_prime is [1.2916197]\n",
      "reward is 0.05 output_prime is [0.776112]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [0.20492847]\n",
      "reward is 0.05 output_prime is [1.23103]\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.9125\n",
      "trial #310\n",
      "reward is 0.05 output_prime is [0.8881575]\n",
      "reward is 0.3375 output_prime is [0.39211607]\n",
      "reward is -1 output_prime is [-1.5292106]\n",
      "reward is 0.20833333333333334 output_prime is [0.5611955]\n",
      "reward is 0.26666666666666666 output_prime is [0.8334323]\n",
      "reward is 0.05 output_prime is [0.7104542]\n",
      "reward is -1 output_prime is [-0.5110335]\n",
      "reward is 0.20833333333333334 output_prime is [1.2216412]\n",
      "trial #311\n",
      "reward is 0.3375 output_prime is [0.7347466]\n",
      "reward is -1 output_prime is [-0.5169785]\n",
      "reward is -1 output_prime is [0.00541377]\n",
      "reward is 0.26666666666666666 output_prime is [1.264361]\n",
      "reward is 0.20833333333333334 output_prime is [0.74210215]\n",
      "reward is 0.27222222222222225 output_prime is [0.31997615]\n",
      "reward is 0.253125 output_prime is [1.2023842]\n",
      "reward is 0.05 output_prime is [1.0414864]\n",
      "trial #312\n",
      "reward is 0.05 output_prime is [0.8695227]\n",
      "reward is -1 output_prime is [-1.6734611]\n",
      "reward is 0.45 output_prime is [-0.22221994]\n",
      "reward is -0.5 output_prime is [-1.1711398]\n",
      "reward is 0.05 output_prime is [0.1110741]\n",
      "reward is 0.4166666666666667 output_prime is [1.0781327]\n",
      "reward is 0.27222222222222225 output_prime is [0.5948517]\n",
      "reward is 0.378125 output_prime is [0.8763399]\n",
      "trial #313\n",
      "reward is -1 output_prime is [0.07400584]\n",
      "reward is 0.05 output_prime is [1.1336945]\n",
      "reward is -0.5 output_prime is [-0.16656518]\n",
      "reward is 0.378125 output_prime is [0.57675874]\n",
      "reward is 0.1 output_prime is [0.77893054]\n",
      "reward is -1 output_prime is [0.14219403]\n",
      "reward is -1 output_prime is [-1.4645681]\n",
      "reward is -1 output_prime is -1\n",
      "trial #314\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.9650297]\n",
      "reward is -0.5 output_prime is [-1.1734588]\n",
      "reward is -1 output_prime is [-1.6742074]\n",
      "reward is -1 output_prime is [-1.6749824]\n",
      "reward is 0.2 output_prime is [0.58842784]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.1034664]\n",
      "trial #315\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.3306979]\n",
      "reward is 0.225 output_prime is [0.9394045]\n",
      "reward is 0.20833333333333334 output_prime is [1.2182231]\n",
      "reward is -1 output_prime is [0.00452232]\n",
      "hi\n",
      "reward is 0.45 output_prime is [-0.23644531]\n",
      "trial #316\n",
      "reward is 0.1 output_prime is [-0.5884756]\n",
      "reward is 0.2 output_prime is [1.1469833]\n",
      "reward is 0.05 output_prime is [0.65497535]\n",
      "reward is 0.05 output_prime is [1.0031013]\n",
      "reward is 0.4 output_prime is [-0.29979464]\n",
      "reward is 0.05 output_prime is [1.0202086]\n",
      "hi\n",
      "reward is 0.2 output_prime is [1.2032269]\n",
      "trial #317\n",
      "reward is -1 output_prime is [-0.34489644]\n",
      "reward is 0.2 output_prime is [1.2342631]\n",
      "reward is 0.6125 output_prime is [0.92747074]\n",
      "reward is 0.05 output_prime is [1.2339591]\n",
      "reward is 0.3125 output_prime is [0.8911718]\n",
      "reward is 0.4166666666666667 output_prime is [-0.3051546]\n",
      "reward is 0.4 output_prime is [0.99769187]\n",
      "reward is -1 output_prime is -1\n",
      "trial #318\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-1.2268052]\n",
      "reward is -1 output_prime is [-1.0224732]\n",
      "reward is 0.20833333333333334 output_prime is [1.2344515]\n",
      "reward is -1 output_prime is [-0.5813755]\n",
      "reward is 0.2 output_prime is [0.3266964]\n",
      "reward is 0.378125 output_prime is [-0.34813416]\n",
      "trial #319\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.0490113]\n",
      "reward is -0.5 output_prime is [0.87412465]\n",
      "reward is -1 output_prime is [-0.37442774]\n",
      "reward is -1 output_prime is [-0.6676028]\n",
      "reward is -1 output_prime is [-1.7175777]\n",
      "reward is -1 output_prime is [0.07483888]\n",
      "reward is -1 output_prime is [-0.11029911]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.5625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.8437500000000002\n",
      "trial #320\n",
      "reward is -0.5 output_prime is [-0.844959]\n",
      "reward is -0.5 output_prime is [-1.2050326]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.3752909]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [1.3167534]\n",
      "reward is 0.05 output_prime is [0.92646056]\n",
      "reward is -1 output_prime is -1\n",
      "trial #321\n",
      "reward is 0.27222222222222225 output_prime is [0.86134624]\n",
      "reward is -1 output_prime is [-1.6843388]\n",
      "reward is 0.20833333333333334 output_prime is [0.9233584]\n",
      "reward is 0.2 output_prime is [-0.48028517]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.14425236]\n",
      "reward is -1 output_prime is [-0.10547251]\n",
      "reward is -1 output_prime is [-0.34610772]\n",
      "trial #322\n",
      "reward is 0.3375 output_prime is [1.1302028]\n",
      "reward is -1 output_prime is [-0.0469107]\n",
      "reward is 0.3125 output_prime is [1.0632966]\n",
      "reward is 0.20833333333333334 output_prime is [1.117157]\n",
      "reward is -1 output_prime is [-0.5111145]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-1.1609033]\n",
      "reward is -1 output_prime is [0.10601628]\n",
      "trial #323\n",
      "reward is -1 output_prime is [-1.6588378]\n",
      "reward is -1 output_prime is [0.06051838]\n",
      "reward is 0.378125 output_prime is [0.8154172]\n",
      "reward is 0.3 output_prime is [0.9888486]\n",
      "reward is -1 output_prime is [-0.5168402]\n",
      "reward is 0.1 output_prime is [0.444428]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [0.6008011]\n",
      "trial #324\n",
      "reward is 0.703125 output_prime is [0.8493284]\n",
      "reward is 0.2 output_prime is [1.1410947]\n",
      "reward is 0.3125 output_prime is [1.047377]\n",
      "reward is -1 output_prime is [-0.26650977]\n",
      "reward is 0.253125 output_prime is [1.2801654]\n",
      "reward is 0.378125 output_prime is [-0.2857141]\n",
      "reward is 0.3375 output_prime is [0.56681967]\n",
      "reward is 0.20833333333333334 output_prime is [0.01945685]\n",
      "trial #325\n",
      "reward is 0.05 output_prime is [0.7070586]\n",
      "reward is -1 output_prime is [0.0982362]\n",
      "reward is 0.6125 output_prime is [0.97476393]\n",
      "reward is -0.5 output_prime is [-1.1667942]\n",
      "reward is 0.05 output_prime is [0.54698676]\n",
      "reward is 0.378125 output_prime is [0.9059232]\n",
      "reward is 0.4166666666666667 output_prime is [0.9542533]\n",
      "reward is 0.4166666666666667 output_prime is [0.8987508]\n",
      "trial #326\n",
      "reward is 0.05 output_prime is [1.1054624]\n",
      "reward is 0.4 output_prime is [1.0009484]\n",
      "reward is 0.378125 output_prime is [0.85540646]\n",
      "reward is -1 output_prime is [-0.7284876]\n",
      "reward is 0.2 output_prime is [1.3309184]\n",
      "reward is 0.3125 output_prime is [0.97277844]\n",
      "reward is 0.2 output_prime is [1.4945656]\n",
      "reward is 0.2 output_prime is [0.82104677]\n",
      "trial #327\n",
      "reward is -1 output_prime is [0.36178517]\n",
      "reward is 0.4 output_prime is [1.3309913]\n",
      "reward is -1 output_prime is [0.13352835]\n",
      "reward is 0.3125 output_prime is [0.8299854]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.44316703]\n",
      "hi\n",
      "reward is 0.4 output_prime is [1.3407506]\n",
      "trial #328\n",
      "reward is -0.5 output_prime is [-1.1647639]\n",
      "reward is 0.2 output_prime is [1.4635026]\n",
      "reward is 0.30625 output_prime is [0.9260782]\n",
      "reward is 0.2 output_prime is [1.487534]\n",
      "reward is 0.05 output_prime is [1.1987606]\n",
      "reward is -0.5 output_prime is [-0.37742212]\n",
      "reward is -1 output_prime is [-1.6689672]\n",
      "reward is 0.3375 output_prime is [0.40182668]\n",
      "trial #329\n",
      "reward is 0.26666666666666666 output_prime is [1.3744589]\n",
      "reward is -1 output_prime is [0.16021872]\n",
      "reward is -1 output_prime is [-1.6765883]\n",
      "reward is 0.05 output_prime is [0.9730168]\n",
      "reward is 0.3125 output_prime is [-0.36870253]\n",
      "reward is -1 output_prime is [-1.683493]\n",
      "reward is -1 output_prime is [-1.6857132]\n",
      "reward is -1 output_prime is [-0.02899867]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.5\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.8062500000000001\n",
      "trial #330\n",
      "reward is 0.1 output_prime is [1.4612557]\n",
      "reward is 0.20833333333333334 output_prime is [1.5166701]\n",
      "reward is -1 output_prime is [0.15877235]\n",
      "reward is 0.3125 output_prime is [1.4059618]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.6125 output_prime is [1.0608451]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.7020471]\n",
      "trial #331\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.03812349]\n",
      "reward is 0.05 output_prime is [0.33489096]\n",
      "reward is 0.05 output_prime is [1.0145606]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.4458776]\n",
      "hi\n",
      "reward is 0.4166666666666667 output_prime is [-0.29811445]\n",
      "trial #332\n",
      "reward is -1 output_prime is [-0.10517901]\n",
      "reward is -1 output_prime is [-1.7178657]\n",
      "reward is 0.2 output_prime is [1.52412]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.12968582]\n",
      "reward is -0.5 output_prime is [-1.2301042]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #333\n",
      "reward is 0.05 output_prime is [0.7775392]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.4028306]\n",
      "reward is 0.20833333333333334 output_prime is [0.5670854]\n",
      "reward is -1 output_prime is [0.3931259]\n",
      "reward is 0.45 output_prime is [-0.2862801]\n",
      "reward is 0.20416666666666666 output_prime is [-0.5343305]\n",
      "reward is -1 output_prime is -1\n",
      "trial #334\n",
      "reward is 0.225 output_prime is [1.3598922]\n",
      "reward is -1 output_prime is [-1.7390838]\n",
      "reward is -1 output_prime is [-1.7394254]\n",
      "reward is 0.225 output_prime is [1.3230579]\n",
      "reward is 0.4166666666666667 output_prime is [0.91599643]\n",
      "reward is -1 output_prime is [-0.9096556]\n",
      "hi\n",
      "reward is -1 output_prime is [0.423568]\n",
      "trial #335\n",
      "reward is -1 output_prime is [-1.7411835]\n",
      "reward is -1 output_prime is [0.05622649]\n",
      "reward is -1 output_prime is [-1.7421241]\n",
      "reward is 0.05 output_prime is [1.0280071]\n",
      "reward is 0.2 output_prime is [1.0520207]\n",
      "reward is -1 output_prime is [-0.11616707]\n",
      "reward is 0.45 output_prime is [-0.29504555]\n",
      "reward is -1 output_prime is [-1.7459757]\n",
      "trial #336\n",
      "reward is -1 output_prime is [-1.7470028]\n",
      "reward is -1 output_prime is [-0.6798976]\n",
      "reward is 0.20833333333333334 output_prime is [0.82463837]\n",
      "reward is -1 output_prime is [-0.33307874]\n",
      "reward is 0.4166666666666667 output_prime is [1.1448284]\n",
      "reward is 0.2 output_prime is [1.0478497]\n",
      "reward is 0.20833333333333334 output_prime is [1.3506036]\n",
      "reward is 0.05 output_prime is [1.1707633]\n",
      "trial #337\n",
      "reward is -1 output_prime is [-1.7513452]\n",
      "reward is 0.703125 output_prime is [-0.04801261]\n",
      "reward is 0.05 output_prime is [0.93429655]\n",
      "reward is 0.05 output_prime is [1.0747163]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [1.3950458]\n",
      "reward is 0.378125 output_prime is [1.0024672]\n",
      "reward is -1 output_prime is -1\n",
      "trial #338\n",
      "reward is -1 output_prime is [-0.13433993]\n",
      "reward is 0.2 output_prime is [1.3371934]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.7433186]\n",
      "reward is 0.3375 output_prime is [0.64274687]\n",
      "reward is 0.05 output_prime is [0.22690842]\n",
      "reward is 0.3125 output_prime is [0.9647695]\n",
      "reward is 0.3 output_prime is [1.3786845]\n",
      "trial #339\n",
      "reward is -1 output_prime is [0.39233994]\n",
      "reward is -1 output_prime is [-1.7407509]\n",
      "reward is 0.05 output_prime is [0.9151786]\n",
      "reward is -0.5 output_prime is [-1.2414169]\n",
      "reward is -1 output_prime is [-0.10021502]\n",
      "reward is -1 output_prime is [-1.742589]\n",
      "reward is 0.703125 output_prime is [-0.04025829]\n",
      "reward is 0.20833333333333334 output_prime is [1.4248039]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9166666666666666\n",
      "trial #340\n",
      "reward is -1 output_prime is [-1.7458678]\n",
      "reward is 0.378125 output_prime is [0.6879592]\n",
      "reward is 0.3375 output_prime is [0.7914909]\n",
      "reward is 0.378125 output_prime is [-0.37307292]\n",
      "reward is 0.26666666666666666 output_prime is [0.70623815]\n",
      "reward is -1 output_prime is [-1.7552681]\n",
      "reward is 0.05 output_prime is [1.1401306]\n",
      "reward is -1 output_prime is [-1.7582667]\n",
      "trial #341\n",
      "reward is 0.3375 output_prime is [0.8002993]\n",
      "reward is 0.6125 output_prime is [0.798874]\n",
      "reward is -1 output_prime is [-0.07525194]\n",
      "reward is 0.45 output_prime is [-0.30676126]\n",
      "reward is 0.45 output_prime is [-0.3067615]\n",
      "reward is 0.1 output_prime is [0.8455304]\n",
      "reward is 0.26666666666666666 output_prime is [1.1534381]\n",
      "reward is 0.3125 output_prime is [-0.44519937]\n",
      "trial #342\n",
      "reward is -1 output_prime is [-1.346823]\n",
      "reward is -1 output_prime is [-1.7590777]\n",
      "reward is -1 output_prime is [-0.5826887]\n",
      "reward is 0.05 output_prime is [0.9127095]\n",
      "reward is 0.703125 output_prime is [-0.05838197]\n",
      "reward is 0.05 output_prime is [0.53916043]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.44372964]\n",
      "trial #343\n",
      "reward is -1 output_prime is [-1.2196555]\n",
      "reward is -0.5 output_prime is [-1.2636089]\n",
      "reward is 0.2 output_prime is [0.5769856]\n",
      "reward is 0.6125 output_prime is [0.33911157]\n",
      "reward is 0.378125 output_prime is [-0.38574082]\n",
      "reward is 0.2 output_prime is [1.1402695]\n",
      "reward is -1 output_prime is [-0.28956062]\n",
      "reward is 0.05 output_prime is [0.08653962]\n",
      "trial #344\n",
      "reward is 0.20833333333333334 output_prime is [0.68595976]\n",
      "reward is -1 output_prime is [-0.47536165]\n",
      "reward is -1 output_prime is [0.06125402]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20416666666666666 output_prime is [1.4637088]\n",
      "reward is 0.378125 output_prime is [1.0109575]\n",
      "reward is 0.05 output_prime is [1.426103]\n",
      "reward is 0.378125 output_prime is [-0.38477427]\n",
      "trial #345\n",
      "reward is 0.20833333333333334 output_prime is [1.3833444]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.528125 output_prime is [0.62022]\n",
      "reward is 0.2 output_prime is [1.1521918]\n",
      "reward is 0.05 output_prime is [1.0918345]\n",
      "reward is -1 output_prime is [-1.7649546]\n",
      "hi\n",
      "reward is 1 output_prime is 1\n",
      "trial #346\n",
      "reward is -1 output_prime is -1\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.378125 output_prime is [0.8048167]\n",
      "reward is 0.225 output_prime is [1.2281226]\n",
      "reward is 0.45 output_prime is [-0.32015032]\n",
      "reward is 0.2 output_prime is [1.4052628]\n",
      "reward is 0.05 output_prime is [0.7758779]\n",
      "reward is 0.3375 output_prime is [0.719124]\n",
      "trial #347\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [0.7550849]\n",
      "reward is 0.1 output_prime is [1.2021956]\n",
      "reward is 0.20833333333333334 output_prime is [1.4298236]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.94157994]\n",
      "trial #348\n",
      "reward is 0.30625 output_prime is [1.4802603]\n",
      "reward is 0.05 output_prime is [1.3550856]\n",
      "reward is 0.378125 output_prime is [0.59897166]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [0.62301195]\n",
      "reward is 0.225 output_prime is [1.2945119]\n",
      "reward is 0.05 output_prime is [1.1433828]\n",
      "reward is -1 output_prime is [-1.1470773]\n",
      "trial #349\n",
      "reward is 0.05 output_prime is [0.12504382]\n",
      "reward is 0.05 output_prime is [0.67426455]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.7893877]\n",
      "reward is -0.5 output_prime is [-1.2894974]\n",
      "reward is -0.5 output_prime is [0.79234576]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.64004266]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9916666666666666\n",
      "trial #350\n",
      "reward is 0.703125 output_prime is [0.3623352]\n",
      "reward is 0.2 output_prime is [1.5719944]\n",
      "reward is 0.20833333333333334 output_prime is [1.2276801]\n",
      "reward is -0.5 output_prime is [-1.2918434]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.3375 output_prime is [0.9499161]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.1170295]\n",
      "trial #351\n",
      "reward is 0.2 output_prime is [0.35650188]\n",
      "reward is 0.30625 output_prime is [0.964211]\n",
      "reward is 0.2 output_prime is [1.1104697]\n",
      "reward is 0.4 output_prime is [0.81511843]\n",
      "reward is -1 output_prime is [-0.46117127]\n",
      "reward is -1 output_prime is [0.31795335]\n",
      "hi\n",
      "reward is 0.1 output_prime is [-0.6931019]\n",
      "trial #352\n",
      "reward is -1 output_prime is [0.04589093]\n",
      "reward is -1 output_prime is [-0.2850796]\n",
      "reward is -1 output_prime is [-1.7904676]\n",
      "reward is 0.05 output_prime is [0.7652466]\n",
      "reward is 0.26666666666666666 output_prime is [0.79425216]\n",
      "reward is -0.5 output_prime is [0.457604]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.3375 output_prime is [0.91886747]\n",
      "trial #353\n",
      "reward is 0.3375 output_prime is [1.3335634]\n",
      "reward is 0.703125 output_prime is [0.48078167]\n",
      "reward is -1 output_prime is [-1.7805052]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.7789083]\n",
      "reward is -1 output_prime is [-1.7781622]\n",
      "hi\n",
      "reward is 0.378125 output_prime is [-0.39940178]\n",
      "trial #354\n",
      "reward is -1 output_prime is [0.04187322]\n",
      "reward is 0.05 output_prime is [0.39281744]\n",
      "reward is 0.20833333333333334 output_prime is [1.4200805]\n",
      "reward is 0.20833333333333334 output_prime is [1.4425843]\n",
      "reward is 0.05 output_prime is [1.0150483]\n",
      "reward is -1 output_prime is [-1.7744775]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #355\n",
      "reward is 0.05 output_prime is [0.9896852]\n",
      "reward is -0.5 output_prime is [-1.271075]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [0.86760485]\n",
      "reward is 0.2 output_prime is [0.9859744]\n",
      "reward is 0.2 output_prime is [1.1332475]\n",
      "reward is 0.05 output_prime is [0.95978683]\n",
      "reward is 0.2 output_prime is [1.1201487]\n",
      "trial #356\n",
      "reward is -1 output_prime is [-1.7621193]\n",
      "reward is 0.30625 output_prime is [0.47623637]\n",
      "reward is -0.5 output_prime is [0.65273297]\n",
      "reward is 0.2 output_prime is [1.543028]\n",
      "reward is 0.2 output_prime is [1.6096387]\n",
      "reward is 0.3125 output_prime is [1.0695186]\n",
      "hi\n",
      "reward is 0.45 output_prime is [-0.3056826]\n",
      "trial #357\n",
      "reward is -0.5 output_prime is [0.14058423]\n",
      "reward is 0.20833333333333334 output_prime is [1.6053969]\n",
      "reward is 0.3125 output_prime is [1.0665032]\n",
      "reward is 0.225 output_prime is [0.8576174]\n",
      "reward is -1 output_prime is [-0.58197296]\n",
      "reward is 0.2 output_prime is [1.0365232]\n",
      "hi\n",
      "reward is -0.5 output_prime is [-1.2514756]\n",
      "trial #358\n",
      "reward is -1 output_prime is [-1.0682954]\n",
      "reward is -1 output_prime is [-0.1666649]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.52723]\n",
      "reward is 0.45 output_prime is [-0.3023131]\n",
      "hi\n",
      "reward is 0.2 output_prime is [1.1515292]\n",
      "trial #359\n",
      "reward is 0.1 output_prime is [0.25489342]\n",
      "reward is 0.45 output_prime is [-0.30467248]\n",
      "reward is 0.05 output_prime is [0.50970113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.1638273]\n",
      "reward is 0.05 output_prime is [1.2108482]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.7633991]\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.5\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.9375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.8937499999999999\n",
      "trial #360\n",
      "reward is 0.05 output_prime is [1.2041613]\n",
      "reward is -1 output_prime is [-1.7681742]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.3526759]\n",
      "reward is 0.05 output_prime is [-0.08055212]\n",
      "reward is 0.3375 output_prime is [0.34504765]\n",
      "hi\n",
      "reward is 0.2 output_prime is [1.3519968]\n",
      "trial #361\n",
      "reward is 0.3375 output_prime is [1.0859982]\n",
      "reward is -1 output_prime is [-1.7874095]\n",
      "reward is 0.26666666666666666 output_prime is [1.470776]\n",
      "reward is -1 output_prime is [-1.2317829]\n",
      "reward is -0.5 output_prime is [-1.1444006]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.30625 output_prime is [0.8783393]\n",
      "reward is 0.05 output_prime is [-0.6713268]\n",
      "trial #362\n",
      "reward is 0.2 output_prime is [0.9405756]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.166174]\n",
      "reward is 0.05 output_prime is [-0.21103339]\n",
      "reward is 0.30625 output_prime is [1.1668313]\n",
      "reward is 0.703125 output_prime is [0.4516215]\n",
      "hi\n",
      "reward is 0.2 output_prime is [1.1151482]\n",
      "trial #363\n",
      "reward is 0.05 output_prime is [-0.7262996]\n",
      "reward is -1 output_prime is [0.25851715]\n",
      "reward is -1 output_prime is [-0.5838331]\n",
      "reward is 0.6125 output_prime is [1.3258655]\n",
      "reward is 0.20833333333333334 output_prime is [1.2676073]\n",
      "reward is 0.378125 output_prime is [1.0414212]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [1.4759759]\n",
      "trial #364\n",
      "reward is 0.20833333333333334 output_prime is [0.934253]\n",
      "reward is 0.3125 output_prime is [0.7692281]\n",
      "reward is -1 output_prime is [-1.2301092]\n",
      "reward is 0.3375 output_prime is [0.9006902]\n",
      "reward is 0.3375 output_prime is [0.8486444]\n",
      "reward is 0.4166666666666667 output_prime is [0.8325159]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.4493732]\n",
      "trial #365\n",
      "reward is 0.20833333333333334 output_prime is [0.12111022]\n",
      "reward is 0.2 output_prime is [1.5505421]\n",
      "reward is 0.05 output_prime is [0.2691106]\n",
      "reward is 0.20833333333333334 output_prime is [1.4630136]\n",
      "reward is 0.05 output_prime is [0.34052536]\n",
      "reward is 0.2 output_prime is [1.204046]\n",
      "reward is 0.30625 output_prime is [1.2098367]\n",
      "reward is -1 output_prime is [-0.01345634]\n",
      "trial #366\n",
      "reward is 0.2 output_prime is [1.6096082]\n",
      "reward is 0.20833333333333334 output_prime is [1.2648898]\n",
      "reward is -1 output_prime is [0.3744496]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.378125 output_prime is [0.514055]\n",
      "reward is 0.05 output_prime is [-0.07614316]\n",
      "hi\n",
      "reward is 0.703125 output_prime is [0.06649202]\n",
      "trial #367\n",
      "reward is 0.05 output_prime is [1.4999862]\n",
      "reward is -1 output_prime is [0.44573307]\n",
      "reward is 0.20833333333333334 output_prime is [0.44683892]\n",
      "reward is 0.05 output_prime is [0.34106743]\n",
      "reward is 0.1 output_prime is [0.93796]\n",
      "reward is 0.225 output_prime is [1.2463528]\n",
      "reward is 0.3375 output_prime is [0.960968]\n",
      "reward is 0.3125 output_prime is [0.65946794]\n",
      "trial #368\n",
      "reward is 0.05 output_prime is [1.5008764]\n",
      "reward is 0.05 output_prime is [0.6666913]\n",
      "reward is 0.2 output_prime is [0.84944206]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.0189425]\n",
      "reward is 0.253125 output_prime is [1.3866942]\n",
      "reward is 0.2 output_prime is [0.50177276]\n",
      "reward is 0.2 output_prime is [1.6282045]\n",
      "trial #369\n",
      "reward is 0.2 output_prime is [1.3537079]\n",
      "reward is 0.20833333333333334 output_prime is [1.0157105]\n",
      "reward is 0.05 output_prime is [1.2197657]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.2665137]\n",
      "reward is 0.6125 output_prime is [1.4116347]\n",
      "hi\n",
      "reward is 0.26666666666666666 output_prime is [1.1662916]\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.8833333333333334\n",
      "trial #370\n",
      "reward is -1 output_prime is [-0.00750744]\n",
      "reward is -1 output_prime is [-0.46183234]\n",
      "reward is -0.5 output_prime is [-1.1757003]\n",
      "reward is -1 output_prime is [-0.3460471]\n",
      "reward is 0.20833333333333334 output_prime is [0.859318]\n",
      "reward is -1 output_prime is [-1.671816]\n",
      "reward is 0.703125 output_prime is [1.2886462]\n",
      "reward is -1 output_prime is -1\n",
      "trial #371\n",
      "reward is 0.3125 output_prime is [1.0932593]\n",
      "reward is 0.2 output_prime is [1.2729617]\n",
      "reward is 0.45 output_prime is [-0.21770728]\n",
      "reward is 0.2 output_prime is [0.5749255]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [0.18215255]\n",
      "reward is 0.703125 output_prime is [1.001378]\n",
      "reward is 0.05 output_prime is [-0.61579585]\n",
      "trial #372\n",
      "reward is 0.05 output_prime is [1.2086099]\n",
      "reward is 0.05 output_prime is [1.2107351]\n",
      "reward is 0.2 output_prime is [1.5659469]\n",
      "reward is -1 output_prime is [-0.8091098]\n",
      "reward is 0.05 output_prime is [0.97469574]\n",
      "reward is 0.05 output_prime is [0.9221101]\n",
      "hi\n",
      "reward is 0.5041666666666667 output_prime is [0.8787866]\n",
      "trial #373\n",
      "reward is 0.05 output_prime is [1.285416]\n",
      "reward is 0.1 output_prime is [0.29428092]\n",
      "reward is 0.2 output_prime is [1.6680897]\n",
      "reward is 0.05 output_prime is [1.1055295]\n",
      "reward is 0.20833333333333334 output_prime is [1.6508383]\n",
      "reward is -1 output_prime is [-0.4912575]\n",
      "hi\n",
      "reward is 0.4 output_prime is [1.1180075]\n",
      "trial #374\n",
      "reward is -1 output_prime is [-0.5802073]\n",
      "reward is 0.2 output_prime is [0.5674383]\n",
      "reward is 0.225 output_prime is [1.1234359]\n",
      "reward is 0.26666666666666666 output_prime is [0.9868027]\n",
      "reward is 0.225 output_prime is [1.5356601]\n",
      "reward is -1 output_prime is [-1.4615355]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.6591246]\n",
      "trial #375\n",
      "reward is 0.20833333333333334 output_prime is [0.72247577]\n",
      "reward is -1 output_prime is [-1.6601536]\n",
      "reward is -1 output_prime is [-0.5915384]\n",
      "reward is -1 output_prime is [0.09170365]\n",
      "reward is 0.703125 output_prime is [0.71010524]\n",
      "reward is 0.05 output_prime is [1.0721173]\n",
      "hi\n",
      "reward is 0.378125 output_prime is [-0.28518027]\n",
      "trial #376\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.1227456]\n",
      "reward is -0.5 output_prime is [-1.164835]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [-0.14995404]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #377\n",
      "reward is 0.378125 output_prime is [1.214053]\n",
      "reward is 0.2 output_prime is [1.0287524]\n",
      "reward is 0.20833333333333334 output_prime is [1.3690246]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [-0.29037946]\n",
      "reward is 0.20416666666666666 output_prime is [0.7263036]\n",
      "hi\n",
      "reward is 0.225 output_prime is [1.370953]\n",
      "trial #378\n",
      "reward is -1 output_prime is [-0.42420352]\n",
      "reward is 0.30625 output_prime is [1.4815878]\n",
      "reward is 0.4166666666666667 output_prime is [-0.03382009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.2 output_prime is [0.50851995]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.0597634]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.0501814]\n",
      "trial #379\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [0.6423536]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [0.69624925]\n",
      "reward is 0.2 output_prime is [1.1037506]\n",
      "reward is 0.3125 output_prime is [1.1744698]\n",
      "reward is 0.05 output_prime is [0.25997317]\n",
      "reward is 0.20833333333333334 output_prime is [0.84226763]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.4375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.4375\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.4375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.4375\n",
      "accuracy is  0.8354166666666667\n",
      "trial #380\n",
      "reward is -1 output_prime is [-1.6896269]\n",
      "reward is 0.20833333333333334 output_prime is [1.4343834]\n",
      "reward is 0.05 output_prime is [1.040611]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.34926355]\n",
      "reward is 0.45 output_prime is [1.1246271]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [1.423156]\n",
      "trial #381\n",
      "reward is 0.2 output_prime is [0.6469353]\n",
      "reward is 0.3 output_prime is [0.67463046]\n",
      "reward is 0.528125 output_prime is [1.1047845]\n",
      "reward is 0.20833333333333334 output_prime is [0.7062796]\n",
      "reward is 0.703125 output_prime is [1.3745563]\n",
      "reward is 0.253125 output_prime is [1.154707]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #382\n",
      "reward is 0.45 output_prime is [-0.245588]\n",
      "reward is 0.378125 output_prime is [-0.31779015]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.26666666666666666 output_prime is [1.467945]\n",
      "reward is 0.253125 output_prime is [0.8847385]\n",
      "reward is -1 output_prime is [-1.6985815]\n",
      "reward is 0.2 output_prime is [0.70352507]\n",
      "trial #383\n",
      "reward is 0.6125 output_prime is [1.1517062]\n",
      "reward is 0.6125 output_prime is [1.6181269]\n",
      "reward is -1 output_prime is [-0.61457944]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.3560418]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.7015665]\n",
      "trial #384\n",
      "reward is -0.5 output_prime is [-1.1991704]\n",
      "reward is 0.3375 output_prime is [1.4423137]\n",
      "reward is 0.05 output_prime is [1.4084302]\n",
      "reward is 0.26666666666666666 output_prime is [0.89568615]\n",
      "reward is -1 output_prime is [-0.23130465]\n",
      "reward is 0.3 output_prime is [1.6508858]\n",
      "reward is -1 output_prime is [-0.16727555]\n",
      "reward is 0.2 output_prime is [1.25213]\n",
      "trial #385\n",
      "reward is 0.20833333333333334 output_prime is [1.7187562]\n",
      "reward is 0.2 output_prime is [1.2501215]\n",
      "reward is 0.05 output_prime is [0.8626591]\n",
      "reward is 0.20833333333333334 output_prime is [1.0529423]\n",
      "reward is -1 output_prime is [0.35468745]\n",
      "reward is 0.378125 output_prime is [1.2327898]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.60965884]\n",
      "trial #386\n",
      "reward is -1 output_prime is [-0.3360687]\n",
      "reward is 0.703125 output_prime is [1.0451581]\n",
      "reward is 0.05 output_prime is [0.8413922]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.2594264]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.3017458]\n",
      "reward is 0.05 output_prime is [0.43145144]\n",
      "trial #387\n",
      "reward is 0.20833333333333334 output_prime is [1.4374505]\n",
      "reward is 0.05 output_prime is [0.9063842]\n",
      "reward is 0.2 output_prime is [1.4475421]\n",
      "reward is 0.05 output_prime is [1.3049586]\n",
      "reward is 0.3125 output_prime is [1.3013934]\n",
      "reward is 0.703125 output_prime is [1.3881996]\n",
      "reward is 0.3125 output_prime is [0.9709983]\n",
      "reward is -1 output_prime is -1\n",
      "trial #388\n",
      "reward is 0.253125 output_prime is [1.3856752]\n",
      "reward is 1 output_prime is 1\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.5667292]\n",
      "reward is 0.378125 output_prime is [-0.27741355]\n",
      "reward is 0.20833333333333334 output_prime is [1.6876897]\n",
      "reward is 0.1125 output_prime is [1.1387336]\n",
      "reward is 0.378125 output_prime is [1.0496044]\n",
      "trial #389\n",
      "reward is -1 output_prime is [-0.6539805]\n",
      "reward is 0.05 output_prime is [1.6340802]\n",
      "reward is 0.2 output_prime is [1.5751386]\n",
      "reward is 0.20416666666666666 output_prime is [-0.45746595]\n",
      "reward is -1 output_prime is [-1.6627414]\n",
      "reward is 0.1 output_prime is [0.96543884]\n",
      "hi\n",
      "reward is 0.3375 output_prime is [-0.3276358]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.90625\n",
      "trial #390\n",
      "reward is 0.2 output_prime is [1.5595962]\n",
      "reward is 0.2 output_prime is [1.4916177]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.4374386]\n",
      "reward is -0.5 output_prime is [-0.5949661]\n",
      "reward is 0.3125 output_prime is [1.372469]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.47851282]\n",
      "trial #391\n",
      "reward is -1 output_prime is [-1.6764013]\n",
      "reward is 0.253125 output_prime is [0.8771434]\n",
      "reward is 0.05 output_prime is [1.2773441]\n",
      "reward is 0.2 output_prime is [1.3936535]\n",
      "reward is -1 output_prime is [-0.94805765]\n",
      "reward is 0.225 output_prime is [1.5809402]\n",
      "hi\n",
      "reward is 0.528125 output_prime is [0.97272563]\n",
      "trial #392\n",
      "reward is -1 output_prime is [-1.1103417]\n",
      "reward is 0.3 output_prime is [0.80632895]\n",
      "reward is 0.2 output_prime is [1.4691277]\n",
      "reward is 0.2 output_prime is [1.607652]\n",
      "reward is -1 output_prime is [-0.33294123]\n",
      "reward is -1 output_prime is [0.60469794]\n",
      "reward is 0.3375 output_prime is [1.1170554]\n",
      "reward is 0.378125 output_prime is [1.293621]\n",
      "trial #393\n",
      "reward is 0.05 output_prime is [1.0465851]\n",
      "reward is 0.20833333333333334 output_prime is [1.368503]\n",
      "reward is 0.3125 output_prime is [-0.36974126]\n",
      "reward is 0.05 output_prime is [0.6053964]\n",
      "reward is 0.05 output_prime is [0.9263601]\n",
      "reward is 0.703125 output_prime is [1.1729461]\n",
      "reward is -1 output_prime is [-0.5831244]\n",
      "reward is 0.20833333333333334 output_prime is [1.7015883]\n",
      "trial #394\n",
      "reward is 0.05 output_prime is [1.2299773]\n",
      "reward is -1 output_prime is [0.17223632]\n",
      "reward is -1 output_prime is [-1.6687062]\n",
      "reward is 0.20833333333333334 output_prime is [1.5453447]\n",
      "reward is 0.2 output_prime is [1.3847461]\n",
      "reward is -0.5 output_prime is [0.08743101]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [1.693663]\n",
      "trial #395\n",
      "reward is 0.6125 output_prime is [1.4015572]\n",
      "reward is -0.5 output_prime is [0.8821937]\n",
      "reward is 0.4 output_prime is [1.5123453]\n",
      "reward is 0.3125 output_prime is [1.0137117]\n",
      "reward is 0.05 output_prime is [1.1182032]\n",
      "reward is 0.05 output_prime is [1.0547919]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [0.7538663]\n",
      "trial #396\n",
      "reward is 0.225 output_prime is [1.5951895]\n",
      "reward is -1 output_prime is [-0.24518627]\n",
      "reward is 0.4 output_prime is [1.5035892]\n",
      "reward is -1 output_prime is [-0.64556456]\n",
      "reward is 0.20833333333333334 output_prime is [1.1856166]\n",
      "reward is 0.2 output_prime is [1.2231714]\n",
      "reward is 0.05 output_prime is [1.210478]\n",
      "reward is -1 output_prime is -1\n",
      "trial #397\n",
      "reward is -1 output_prime is [-1.655534]\n",
      "reward is -1 output_prime is [-0.28026408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.05 output_prime is [0.8301991]\n",
      "reward is 0.3125 output_prime is [-0.34402198]\n",
      "reward is 0.20833333333333334 output_prime is [1.5480257]\n",
      "reward is -1 output_prime is [-1.6574969]\n",
      "reward is 0.05 output_prime is [0.9274095]\n",
      "reward is -1 output_prime is [0.61091673]\n",
      "trial #398\n",
      "reward is 0.1125 output_prime is [1.1223295]\n",
      "reward is 0.2 output_prime is [1.0226417]\n",
      "reward is 0.2 output_prime is [1.7922597]\n",
      "reward is -0.5 output_prime is [0.8448149]\n",
      "reward is -1 output_prime is [-0.29546392]\n",
      "reward is 0.15 output_prime is [1.0205712]\n",
      "reward is 0.05 output_prime is [-0.27715564]\n",
      "reward is 0.1 output_prime is [1.2364258]\n",
      "trial #399\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.2 output_prime is [1.7973007]\n",
      "reward is 0.05 output_prime is [0.5213426]\n",
      "reward is 0.05 output_prime is [0.73484683]\n",
      "reward is 0.2 output_prime is [0.3572688]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.2105206]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.5\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.8895833333333335\n",
      "trial #400\n",
      "reward is 0.2 output_prime is [1.428253]\n",
      "reward is -1 output_prime is [0.22877789]\n",
      "reward is 0.703125 output_prime is [0.7001482]\n",
      "reward is 0.05 output_prime is [1.2075615]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [0.9538566]\n",
      "reward is 0.05 output_prime is [1.0496483]\n",
      "reward is -1 output_prime is [-1.6334856]\n",
      "trial #401\n",
      "reward is 0.05 output_prime is [1.3218918]\n",
      "reward is 0.2 output_prime is [1.816286]\n",
      "reward is -1 output_prime is [0.09021068]\n",
      "reward is 0.3375 output_prime is [0.69736516]\n",
      "reward is 0.2 output_prime is [1.8148755]\n",
      "reward is 0.3125 output_prime is [-0.31674325]\n",
      "hi\n",
      "reward is 0.4 output_prime is [0.98057115]\n",
      "trial #402\n",
      "reward is 0.3375 output_prime is [-0.2910122]\n",
      "reward is 0.2 output_prime is [1.3620926]\n",
      "reward is -1 output_prime is [-1.6284575]\n",
      "reward is 0.20833333333333334 output_prime is [1.6001616]\n",
      "reward is -1 output_prime is [-1.6290213]\n",
      "reward is 0.2 output_prime is [1.676771]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [1.5755275]\n",
      "trial #403\n",
      "reward is -0.5 output_prime is [-1.1308017]\n",
      "reward is 0.4 output_prime is [1.4576617]\n",
      "reward is -1 output_prime is [-0.2664485]\n",
      "reward is 0.3375 output_prime is [0.7512418]\n",
      "reward is -1 output_prime is [-1.4536382]\n",
      "reward is 0.3375 output_prime is [1.2065544]\n",
      "hi\n",
      "reward is 0.703125 output_prime is [0.20804486]\n",
      "trial #404\n",
      "reward is 0.2 output_prime is [1.8456075]\n",
      "reward is 0.5041666666666667 output_prime is [1.0821204]\n",
      "reward is 0.3375 output_prime is [1.5528619]\n",
      "reward is -0.5 output_prime is [-0.04785392]\n",
      "reward is 0.3375 output_prime is [1.166604]\n",
      "reward is 0.05 output_prime is [-0.0294163]\n",
      "hi\n",
      "reward is 0.45 output_prime is [-0.19469047]\n",
      "trial #405\n",
      "reward is 0.27222222222222225 output_prime is [1.1101179]\n",
      "reward is -1 output_prime is [-1.6483263]\n",
      "reward is 0.05 output_prime is [0.9894203]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.1 output_prime is [0.06861207]\n",
      "reward is -1 output_prime is [-1.6581968]\n",
      "reward is 0.05 output_prime is [0.52360684]\n",
      "reward is -0.5 output_prime is [-0.5159607]\n",
      "trial #406\n",
      "reward is 0.4166666666666667 output_prime is [0.9375243]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.6658454]\n",
      "reward is 0.2 output_prime is [1.7357844]\n",
      "reward is 0.3375 output_prime is [1.1638031]\n",
      "reward is 0.05 output_prime is [-0.63275415]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.034051]\n",
      "trial #407\n",
      "reward is 0.05 output_prime is [1.7410599]\n",
      "reward is 0.4 output_prime is [1.4148278]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.05 output_prime is [1.4575645]\n",
      "reward is 0.05 output_prime is [1.3417829]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is 0.378125 output_prime is [1.2072699]\n",
      "trial #408\n",
      "reward is 0.3125 output_prime is [0.76990134]\n",
      "reward is 0.378125 output_prime is [1.2015239]\n",
      "reward is 0.378125 output_prime is [-0.3128863]\n",
      "reward is -1 output_prime is [-1.6905047]\n",
      "reward is 0.3375 output_prime is [-0.35241517]\n",
      "reward is -1 output_prime is [0.6795002]\n",
      "hi\n",
      "reward is 1 output_prime is 1\n",
      "trial #409\n",
      "reward is 0.2 output_prime is [1.142259]\n",
      "reward is -1 output_prime is [-1.6861178]\n",
      "reward is 0.225 output_prime is [1.5835286]\n",
      "reward is -1 output_prime is [-0.5839447]\n",
      "reward is 0.2 output_prime is [0.7483206]\n",
      "reward is 0.378125 output_prime is [1.4390433]\n",
      "reward is 0.3125 output_prime is [-0.36807084]\n",
      "reward is 0.3125 output_prime is [1.438459]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9708333333333332\n",
      "trial #410\n",
      "reward is -1 output_prime is [-1.6785967]\n",
      "reward is 0.3375 output_prime is [0.47566426]\n",
      "reward is -1 output_prime is [-1.6772585]\n",
      "reward is 0.05 output_prime is [1.6176267]\n",
      "reward is 0.2 output_prime is [1.6583312]\n",
      "reward is 0.45 output_prime is [1.0000284]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #411\n",
      "reward is 0.05 output_prime is [1.0050337]\n",
      "reward is 0.05 output_prime is [1.3305308]\n",
      "reward is 0.225 output_prime is [0.44458842]\n",
      "reward is 0.378125 output_prime is [1.0811214]\n",
      "reward is 0.378125 output_prime is [0.80442613]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is 0.45 output_prime is [-0.21034837]\n",
      "trial #412\n",
      "reward is 0.378125 output_prime is [1.3772478]\n",
      "reward is 0.3125 output_prime is [1.2538207]\n",
      "reward is -1 output_prime is [-0.04113919]\n",
      "reward is 0.3 output_prime is [0.62499887]\n",
      "reward is 0.2 output_prime is [1.4065433]\n",
      "reward is -1 output_prime is [-0.18611324]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #413\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [0.7670145]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.6485317]\n",
      "reward is -1 output_prime is [-0.1364901]\n",
      "reward is -0.5 output_prime is [-1.1477757]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.14791769]\n",
      "trial #414\n",
      "reward is -0.5 output_prime is [-0.78367686]\n",
      "reward is 0.2 output_prime is [1.065568]\n",
      "reward is 0.6125 output_prime is [1.2433302]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.6490912]\n",
      "reward is 0.4166666666666667 output_prime is [1.0390401]\n",
      "hi\n",
      "reward is -0.5 output_prime is [-1.14978]\n",
      "trial #415\n",
      "reward is -0.5 output_prime is [0.12826931]\n",
      "reward is -1 output_prime is [-0.495381]\n",
      "reward is 0.20833333333333334 output_prime is [1.0300487]\n",
      "reward is -1 output_prime is [-1.6501443]\n",
      "reward is 0.05 output_prime is [1.1761323]\n",
      "reward is 0.30625 output_prime is [1.4744462]\n",
      "hi\n",
      "reward is -1 output_prime is [0.6701782]\n",
      "trial #416\n",
      "reward is 0.4166666666666667 output_prime is [1.0410678]\n",
      "reward is 0.378125 output_prime is [1.1869972]\n",
      "reward is 0.05 output_prime is [1.3423415]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.45 output_prime is [1.0103319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.2 output_prime is [1.486764]\n",
      "reward is -1 output_prime is [0.29212165]\n",
      "reward is 0.3125 output_prime is [0.529245]\n",
      "trial #417\n",
      "reward is 0.45 output_prime is [-0.19927406]\n",
      "reward is -1 output_prime is [-0.41011256]\n",
      "reward is 0.05 output_prime is [1.5984722]\n",
      "reward is -1 output_prime is [0.4184506]\n",
      "reward is 0.3125 output_prime is [0.76406145]\n",
      "reward is 0.2 output_prime is [1.820713]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.4183296]\n",
      "trial #418\n",
      "reward is -1 output_prime is [-0.3760308]\n",
      "reward is -1 output_prime is [-0.10776305]\n",
      "reward is -0.5 output_prime is [1.0462482]\n",
      "reward is 0.1 output_prime is [0.97034293]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [-0.27507538]\n",
      "hi\n",
      "reward is -0.5 output_prime is [0.69056916]\n",
      "trial #419\n",
      "reward is 0.20833333333333334 output_prime is [1.5601653]\n",
      "reward is -1 output_prime is [-1.652189]\n",
      "reward is 0.05 output_prime is [1.702207]\n",
      "reward is 0.2 output_prime is [1.1223438]\n",
      "reward is 0.4 output_prime is [1.3460433]\n",
      "reward is 0.27222222222222225 output_prime is [-0.37846798]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.2385697]\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.625\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.8354166666666668\n",
      "trial #420\n",
      "reward is 0.45 output_prime is [0.9606401]\n",
      "reward is 0.2 output_prime is [1.4839476]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.703125 output_prime is [0.5267164]\n",
      "reward is 0.20833333333333334 output_prime is [1.613447]\n",
      "reward is -0.5 output_prime is [-1.1479335]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.2080863]\n",
      "trial #421\n",
      "reward is 0.378125 output_prime is [1.3126547]\n",
      "reward is 0.05 output_prime is [0.89001334]\n",
      "reward is 0.30625 output_prime is [1.5037314]\n",
      "reward is 0.528125 output_prime is [1.5020788]\n",
      "reward is 0.05 output_prime is [1.3288412]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.528125 output_prime is [1.7091577]\n",
      "reward is -1 output_prime is [-1.6428056]\n",
      "trial #422\n",
      "reward is -1 output_prime is [-1.5436559]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.6125 output_prime is [0.5580681]\n",
      "reward is 0.225 output_prime is [0.40778345]\n",
      "reward is 0.2 output_prime is [0.9712356]\n",
      "reward is 0.3125 output_prime is [-0.32850802]\n",
      "reward is 0.703125 output_prime is [1.5113416]\n",
      "reward is 0.20833333333333334 output_prime is [1.8208545]\n",
      "trial #423\n",
      "reward is 0.20833333333333334 output_prime is [1.4829811]\n",
      "reward is -1 output_prime is [-1.6425169]\n",
      "reward is -0.5 output_prime is [0.9692794]\n",
      "reward is 0.2 output_prime is [1.4930958]\n",
      "reward is -1 output_prime is [-1.6450886]\n",
      "reward is 0.253125 output_prime is [1.4617414]\n",
      "hi\n",
      "reward is 0.4166666666666667 output_prime is [-0.23016194]\n",
      "trial #424\n",
      "reward is -1 output_prime is [-0.35466266]\n",
      "reward is 0.20833333333333334 output_prime is [1.7879345]\n",
      "reward is 0.05 output_prime is [1.2663127]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [0.8725877]\n",
      "reward is 0.05 output_prime is [1.1658517]\n",
      "hi\n",
      "reward is -0.5 output_prime is [-0.37402517]\n",
      "trial #425\n",
      "reward is -0.5 output_prime is [0.8949164]\n",
      "reward is 0.4166666666666667 output_prime is [1.1276163]\n",
      "reward is 0.3375 output_prime is [1.1785412]\n",
      "reward is 0.05 output_prime is [1.1914196]\n",
      "reward is 0.703125 output_prime is [1.0880909]\n",
      "reward is 0.05 output_prime is [1.3713176]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.7683997]\n",
      "trial #426\n",
      "reward is 0.05 output_prime is [1.5692587]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.1938909]\n",
      "reward is 0.2 output_prime is [1.3271654]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.05 output_prime is [1.3398407]\n",
      "hi\n",
      "reward is 0.2 output_prime is [0.6108454]\n",
      "trial #427\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.5962938]\n",
      "reward is -0.5 output_prime is [-1.0797393]\n",
      "reward is 0.1125 output_prime is [0.9044482]\n",
      "reward is 0.05 output_prime is [0.3180356]\n",
      "reward is 0.20833333333333334 output_prime is [1.8154681]\n",
      "hi\n",
      "reward is 0.4166666666666667 output_prime is [0.8079256]\n",
      "trial #428\n",
      "reward is 0.703125 output_prime is [1.2859943]\n",
      "reward is 0.05 output_prime is [0.9582849]\n",
      "reward is 0.27222222222222225 output_prime is [0.51267844]\n",
      "reward is 0.378125 output_prime is [1.4773073]\n",
      "reward is 0.4166666666666667 output_prime is [0.8391347]\n",
      "reward is -1 output_prime is [0.01971948]\n",
      "hi\n",
      "reward is 0.2 output_prime is [1.2717395]\n",
      "trial #429\n",
      "reward is 0.26666666666666666 output_prime is [1.9438275]\n",
      "reward is 0.225 output_prime is [1.7308671]\n",
      "reward is 0.4166666666666667 output_prime is [0.6260008]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [1.9482946]\n",
      "reward is -1 output_prime is [-0.02940309]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.01433277]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9458333333333332\n",
      "trial #430\n",
      "reward is -1 output_prime is [-1.4400452]\n",
      "reward is -1 output_prime is [-1.4328791]\n",
      "reward is 0.3125 output_prime is [-0.11126736]\n",
      "reward is -1 output_prime is [-0.7214172]\n",
      "reward is 0.6 output_prime is [0.180132]\n",
      "reward is -1 output_prime is [0.13927591]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.4224285]\n",
      "trial #431\n",
      "reward is 0.4 output_prime is [1.4200416]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [0.78558934]\n",
      "reward is 0.1125 output_prime is [1.2756879]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is 0.3375 output_prime is [1.7164642]\n",
      "trial #432\n",
      "reward is 0.378125 output_prime is [1.0206416]\n",
      "reward is -1 output_prime is [-1.4380238]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.4429388]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.253125 output_prime is [1.9303253]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.5438172]\n",
      "trial #433\n",
      "reward is 0.20833333333333334 output_prime is [1.6941713]\n",
      "reward is 0.45 output_prime is [-0.0102123]\n",
      "reward is -1 output_prime is [-1.4654763]\n",
      "reward is 0.05 output_prime is [1.2262692]\n",
      "reward is 0.05 output_prime is [1.1566192]\n",
      "reward is -1 output_prime is [0.37721598]\n",
      "hi\n",
      "reward is 0.225 output_prime is [1.4602304]\n",
      "trial #434\n",
      "reward is 0.45 output_prime is [-0.03607398]\n",
      "reward is 0.3125 output_prime is [1.5961385]\n",
      "reward is -0.5 output_prime is [-0.98908633]\n",
      "reward is 0.05 output_prime is [-0.4406965]\n",
      "reward is 0.1 output_prime is [0.39550683]\n",
      "reward is -1 output_prime is [-1.4940473]\n",
      "reward is -1 output_prime is [-0.21682787]\n",
      "reward is 0.3 output_prime is [1.7825253]\n",
      "trial #435\n",
      "reward is 0.225 output_prime is [1.7874767]\n",
      "reward is 0.1 output_prime is [1.5700243]\n",
      "reward is 0.225 output_prime is [0.6620516]\n",
      "reward is 0.05 output_prime is [1.1607621]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.814808]\n",
      "hi\n",
      "reward is 0.26666666666666666 output_prime is [1.9371809]\n",
      "trial #436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is -1 output_prime is [-1.5107884]\n",
      "reward is -1 output_prime is [0.870785]\n",
      "reward is 0.30625 output_prime is [0.97544134]\n",
      "reward is 0.05 output_prime is [1.3776886]\n",
      "reward is -1 output_prime is [-0.44784606]\n",
      "reward is -1 output_prime is [-0.3419547]\n",
      "hi\n",
      "reward is 0.3375 output_prime is [1.7811935]\n",
      "trial #437\n",
      "reward is 0.20833333333333334 output_prime is [1.7652612]\n",
      "reward is 0.4166666666666667 output_prime is [0.83449954]\n",
      "reward is 0.253125 output_prime is [1.7260985]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.20833333333333334 output_prime is [1.2392722]\n",
      "reward is 0.1 output_prime is [1.3187279]\n",
      "hi\n",
      "reward is 0.05 output_prime is [0.5614548]\n",
      "trial #438\n",
      "reward is -1 output_prime is [0.8612883]\n",
      "reward is -0.5 output_prime is [-0.43161884]\n",
      "reward is -1 output_prime is [0.7959372]\n",
      "reward is 0.703125 output_prime is [1.3891339]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [1.8411481]\n",
      "reward is 0.20833333333333334 output_prime is [-0.33221465]\n",
      "reward is 0.6125 output_prime is [1.2724032]\n",
      "trial #439\n",
      "reward is 0.703125 output_prime is [0.9041841]\n",
      "reward is 0.2 output_prime is [1.629074]\n",
      "reward is 0.45 output_prime is [0.37874305]\n",
      "reward is 0.2 output_prime is [0.32308674]\n",
      "reward is 0.378125 output_prime is [1.5475492]\n",
      "reward is -1 output_prime is [-0.7937272]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "accuracy is  0.9333333333333333\n",
      "trial #440\n",
      "reward is -1 output_prime is [-0.15024143]\n",
      "reward is 0.05 output_prime is [1.7234728]\n",
      "reward is 0.528125 output_prime is [1.8288629]\n",
      "reward is 0.2 output_prime is [1.6514894]\n",
      "reward is -1 output_prime is [-0.51104975]\n",
      "reward is 0.3375 output_prime is [0.81241906]\n",
      "reward is 0.45 output_prime is [-0.11278468]\n",
      "reward is 0.20833333333333334 output_prime is [1.9701283]\n",
      "trial #441\n",
      "reward is 0.20833333333333334 output_prime is [2.0058985]\n",
      "reward is 0.20416666666666666 output_prime is [0.8664213]\n",
      "reward is 0.2 output_prime is [1.8922577]\n",
      "reward is 0.1 output_prime is [1.5590162]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.14733368]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3375 output_prime is [1.3341885]\n",
      "trial #442\n",
      "reward is 0.20833333333333334 output_prime is [0.21345331]\n",
      "reward is -1 output_prime is [0.20199215]\n",
      "reward is 0.3375 output_prime is [-0.24365428]\n",
      "reward is 0.05 output_prime is [1.4382701]\n",
      "reward is 0.3 output_prime is [0.7400279]\n",
      "reward is -1 output_prime is [-0.26222724]\n",
      "hi\n",
      "reward is -1 output_prime is [0.13523877]\n",
      "trial #443\n",
      "reward is 0.05 output_prime is [1.6545459]\n",
      "reward is -1 output_prime is [-0.4039864]\n",
      "reward is 0.05 output_prime is [0.8371235]\n",
      "reward is 0.20833333333333334 output_prime is [1.9681348]\n",
      "reward is -1 output_prime is [-0.12515974]\n",
      "reward is 0.05 output_prime is [1.0825688]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.4270194]\n",
      "trial #444\n",
      "reward is 0.45 output_prime is [-0.14789182]\n",
      "reward is 0.05 output_prime is [1.9244329]\n",
      "reward is 0.3375 output_prime is [0.765164]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.4 output_prime is [1.6085162]\n",
      "reward is 0.3125 output_prime is [0.9011085]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.6059186]\n",
      "trial #445\n",
      "reward is 0.05 output_prime is [1.8749348]\n",
      "reward is 0.378125 output_prime is [-0.23048252]\n",
      "reward is -1 output_prime is [-1.6099706]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [1.7482855]\n",
      "reward is 0.6125 output_prime is [1.8308616]\n",
      "hi\n",
      "reward is 1 output_prime is 1\n",
      "trial #446\n",
      "reward is 0.378125 output_prime is [-0.23905963]\n",
      "reward is -1 output_prime is [-1.618735]\n",
      "reward is 0.05 output_prime is [1.4598308]\n",
      "reward is 0.3 output_prime is [1.7807074]\n",
      "reward is 0.20833333333333334 output_prime is [-0.4153195]\n",
      "reward is 0.3 output_prime is [1.7788873]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [0.8729477]\n",
      "trial #447\n",
      "reward is 0.5041666666666667 output_prime is [-0.12442213]\n",
      "reward is -1 output_prime is [-1.5893011]\n",
      "reward is 0.528125 output_prime is [1.8132746]\n",
      "reward is -1 output_prime is [0.4466406]\n",
      "reward is -0.5 output_prime is [-1.1351924]\n",
      "reward is 0.26666666666666666 output_prime is [2.0456982]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #448\n",
      "reward is 0.05 output_prime is [-0.0899765]\n",
      "reward is 0.1125 output_prime is [1.395114]\n",
      "reward is 0.225 output_prime is [1.2557638]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [1.9004842]\n",
      "reward is -1 output_prime is [-1.6458523]\n",
      "reward is 0.20833333333333334 output_prime is [2.0458705]\n",
      "reward is 0.3125 output_prime is [0.81387484]\n",
      "trial #449\n",
      "reward is 0.20833333333333334 output_prime is [2.0504642]\n",
      "reward is 0.45 output_prime is [1.2389524]\n",
      "reward is -1 output_prime is [-1.6175385]\n",
      "reward is 0.2 output_prime is [2.0507014]\n",
      "reward is 0.2 output_prime is [1.5170877]\n",
      "reward is 0.05 output_prime is [1.8945817]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.6540844]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.375\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9291666666666665\n",
      "trial #450\n",
      "reward is 0.2 output_prime is [1.5202483]\n",
      "reward is -1 output_prime is [-1.4218574]\n",
      "reward is 0.378125 output_prime is [0.8278666]\n",
      "reward is 0.3375 output_prime is [1.076319]\n",
      "reward is 0.05 output_prime is [1.2353486]\n",
      "reward is 0.20833333333333334 output_prime is [1.9551758]\n",
      "hi\n",
      "reward is 0.253125 output_prime is [0.65639246]\n",
      "trial #451\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.05 output_prime is [0.7132372]\n",
      "reward is 0.6125 output_prime is [1.3635316]\n",
      "reward is -0.5 output_prime is [-1.16331]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.703125 output_prime is [1.5212529]\n",
      "reward is -1 output_prime is [-1.6658436]\n",
      "reward is -1 output_prime is -1\n",
      "trial #452\n",
      "reward is -1 output_prime is [0.94749904]\n",
      "reward is -0.5 output_prime is [-0.7619627]\n",
      "reward is 0.4166666666666667 output_prime is [1.1972681]\n",
      "reward is -1 output_prime is [-0.7101109]\n",
      "reward is 0.05 output_prime is [2.0123463]\n",
      "reward is 0.2 output_prime is [2.1186328]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.8897722]\n",
      "trial #453\n",
      "reward is 0.3125 output_prime is [1.8889904]\n",
      "reward is -1 output_prime is [-0.19371027]\n",
      "reward is 0.2 output_prime is [0.6600519]\n",
      "reward is 0.05 output_prime is [1.4757645]\n",
      "reward is 0.1 output_prime is [1.610063]\n",
      "reward is 0.3 output_prime is [1.8735535]\n",
      "hi\n",
      "reward is 0.4 output_prime is [1.6957037]\n",
      "trial #454\n",
      "reward is 1 output_prime is 1\n",
      "reward is 1 output_prime is 1\n",
      "reward is -1 output_prime is [-1.674252]\n",
      "reward is 1 output_prime is 1\n",
      "reward is -1 output_prime is [0.74789727]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #455\n",
      "reward is 0.05 output_prime is [1.1388501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.26666666666666666 output_prime is [2.121765]\n",
      "reward is 0.2 output_prime is [2.0848265]\n",
      "reward is 0.20833333333333334 output_prime is [-0.46936345]\n",
      "reward is -1 output_prime is [-0.0700537]\n",
      "reward is 0.703125 output_prime is [1.1350238]\n",
      "reward is 0.20833333333333334 output_prime is [2.1275673]\n",
      "reward is 0.2 output_prime is [2.053466]\n",
      "trial #456\n",
      "reward is 0.05 output_prime is [1.2116421]\n",
      "reward is -0.5 output_prime is [1.3848063]\n",
      "reward is 1 output_prime is 1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.20075065]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is -1 output_prime is [-1.6803207]\n",
      "trial #457\n",
      "reward is 0.703125 output_prime is [1.1227167]\n",
      "reward is 0.703125 output_prime is [1.3427212]\n",
      "reward is -1 output_prime is [-0.14919025]\n",
      "reward is 0.20416666666666666 output_prime is [0.31601992]\n",
      "reward is 0.20833333333333334 output_prime is [0.50922793]\n",
      "reward is 0.20416666666666666 output_prime is [0.5765658]\n",
      "hi\n",
      "reward is 0.4166666666666667 output_prime is [1.1197067]\n",
      "trial #458\n",
      "reward is 0.2 output_prime is [1.3614469]\n",
      "reward is 0.05 output_prime is [1.5838976]\n",
      "reward is -0.5 output_prime is [0.66568303]\n",
      "reward is -1 output_prime is [-1.6796174]\n",
      "reward is 0.703125 output_prime is [0.67192996]\n",
      "reward is -1 output_prime is [0.9457985]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [0.27664065]\n",
      "trial #459\n",
      "reward is 0.3375 output_prime is [1.1299607]\n",
      "reward is 0.05 output_prime is [1.494768]\n",
      "reward is -1 output_prime is [-1.6806719]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [1.9572936]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9666666666666667\n",
      "trial #460\n",
      "reward is 0.26666666666666666 output_prime is [2.1662571]\n",
      "reward is 0.1 output_prime is [0.9675241]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.0858731]\n",
      "reward is 0.2 output_prime is [1.407854]\n",
      "reward is -1 output_prime is [-1.6837232]\n",
      "hi\n",
      "reward is 0.27222222222222225 output_prime is [0.4157371]\n",
      "trial #461\n",
      "reward is 0.2 output_prime is [2.1986337]\n",
      "reward is 0.3125 output_prime is [-0.3722496]\n",
      "reward is 0.2 output_prime is [2.1674538]\n",
      "reward is 0.3125 output_prime is [1.8227304]\n",
      "reward is 0.4 output_prime is [1.619682]\n",
      "reward is 0.05 output_prime is [-0.6356624]\n",
      "reward is 0.20833333333333334 output_prime is [2.1783948]\n",
      "reward is 0.05 output_prime is [1.981785]\n",
      "trial #462\n",
      "reward is 0.20833333333333334 output_prime is [1.8632941]\n",
      "reward is 0.2 output_prime is [2.2474923]\n",
      "reward is -1 output_prime is [-0.40734595]\n",
      "reward is 0.6125 output_prime is [1.222134]\n",
      "reward is 0.253125 output_prime is [2.0791035]\n",
      "reward is 0.3375 output_prime is [0.8485087]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [1.8186419]\n",
      "trial #463\n",
      "reward is 0.703125 output_prime is [1.2519882]\n",
      "reward is -1 output_prime is [-1.6870999]\n",
      "reward is 0.378125 output_prime is [-0.30902284]\n",
      "reward is 0.4 output_prime is [1.0394796]\n",
      "reward is 0.05 output_prime is [0.9869044]\n",
      "reward is -1 output_prime is [-1.6872399]\n",
      "hi\n",
      "reward is 0.26666666666666666 output_prime is [1.3721055]\n",
      "trial #464\n",
      "reward is 0.3375 output_prime is [-0.34966788]\n",
      "reward is -1 output_prime is [-0.42841202]\n",
      "reward is -1 output_prime is [-0.75698525]\n",
      "reward is -1 output_prime is [-0.7541303]\n",
      "reward is 0.3 output_prime is [1.1831532]\n",
      "reward is -1 output_prime is [-1.6866394]\n",
      "hi\n",
      "reward is 0.225 output_prime is [1.5026376]\n",
      "trial #465\n",
      "reward is 0.703125 output_prime is [1.47689]\n",
      "reward is -0.5 output_prime is [0.1451565]\n",
      "reward is 0.05 output_prime is [1.6029514]\n",
      "reward is 0.378125 output_prime is [0.7991442]\n",
      "reward is 0.26666666666666666 output_prime is [2.1466637]\n",
      "reward is -1 output_prime is [-0.22547859]\n",
      "reward is -1 output_prime is [-1.6879802]\n",
      "reward is -1 output_prime is [-1.3082757]\n",
      "trial #466\n",
      "reward is 0.2 output_prime is [1.9312414]\n",
      "reward is -1 output_prime is [-0.44173956]\n",
      "reward is 0.15 output_prime is [-0.53995895]\n",
      "reward is 0.703125 output_prime is [1.0542]\n",
      "reward is 0.05 output_prime is [1.5603961]\n",
      "reward is 0.3125 output_prime is [1.7012683]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.6927221]\n",
      "trial #467\n",
      "reward is 0.05 output_prime is [0.8405263]\n",
      "reward is -0.5 output_prime is [-1.1906674]\n",
      "reward is 0.05 output_prime is [1.5507895]\n",
      "reward is 0.45 output_prime is [-0.24548012]\n",
      "reward is 0.2 output_prime is [0.5040449]\n",
      "reward is 0.225 output_prime is [2.0658665]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #468\n",
      "reward is 0.3375 output_prime is [1.7176841]\n",
      "reward is -1 output_prime is [-1.697509]\n",
      "reward is 0.05 output_prime is [0.289822]\n",
      "reward is 0.4 output_prime is [0.6410985]\n",
      "reward is 0.45 output_prime is [1.126166]\n",
      "reward is 0.05 output_prime is [2.0867007]\n",
      "reward is 0.2 output_prime is [1.9471289]\n",
      "reward is 0.2 output_prime is [1.3206568]\n",
      "trial #469\n",
      "reward is -1 output_prime is [-1.7030606]\n",
      "reward is 0.2 output_prime is [1.2606775]\n",
      "reward is -1 output_prime is [0.31186485]\n",
      "reward is 0.3 output_prime is [0.6623446]\n",
      "reward is 0.20833333333333334 output_prime is [1.9385464]\n",
      "reward is -0.5 output_prime is [-0.09920052]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [1.7142837]\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.6875\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "accuracy is  0.8812500000000001\n",
      "trial #470\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.2 output_prime is [1.3078624]\n",
      "reward is 0.1 output_prime is [1.7819011]\n",
      "reward is 0.2 output_prime is [1.7643788]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.4 output_prime is [-0.3128809]\n",
      "hi\n",
      "reward is 0.378125 output_prime is [1.0681279]\n",
      "trial #471\n",
      "reward is 0.3 output_prime is [1.6761591]\n",
      "reward is 0.2 output_prime is [2.1947956]\n",
      "reward is 0.378125 output_prime is [1.0112832]\n",
      "reward is -0.5 output_prime is [-1.216854]\n",
      "reward is 0.2 output_prime is [1.8993113]\n",
      "reward is -0.5 output_prime is [-1.2185508]\n",
      "hi\n",
      "reward is 0.2 output_prime is [2.2986188]\n",
      "trial #472\n",
      "reward is 0.20833333333333334 output_prime is [0.74553907]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.7957383]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.2 output_prime is [0.94307524]\n",
      "reward is 0.05 output_prime is [1.4874933]\n",
      "reward is 0.05 output_prime is [1.9106236]\n",
      "reward is 1 output_prime is 1\n",
      "trial #473\n",
      "reward is 0.3125 output_prime is [1.6464065]\n",
      "reward is 0.3375 output_prime is [0.98252153]\n",
      "reward is -1 output_prime is [0.84863806]\n",
      "reward is 0.05 output_prime is [0.8533049]\n",
      "reward is 0.6125 output_prime is [1.3592603]\n",
      "reward is 0.3125 output_prime is [0.71030045]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 1 output_prime is 1\n",
      "trial #474\n",
      "reward is -1 output_prime is [-1.7305162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.20833333333333334 output_prime is [2.058594]\n",
      "reward is -0.5 output_prime is [0.58914435]\n",
      "reward is -1 output_prime is [-1.7314863]\n",
      "reward is 0.05 output_prime is [0.4346357]\n",
      "reward is 0.05 output_prime is [-0.6820209]\n",
      "hi\n",
      "reward is -1 output_prime is [-0.4457457]\n",
      "trial #475\n",
      "reward is -0.5 output_prime is [-0.5340596]\n",
      "reward is 0.26666666666666666 output_prime is [0.38347214]\n",
      "reward is 0.05 output_prime is [1.5747145]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.225 output_prime is [1.6113317]\n",
      "reward is 0.20833333333333334 output_prime is [0.8340812]\n",
      "hi\n",
      "reward is 0.05 output_prime is [1.2962794]\n",
      "trial #476\n",
      "reward is 0.26666666666666666 output_prime is [0.37123996]\n",
      "reward is 0.45 output_prime is [-0.2830385]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [-0.35507226]\n",
      "reward is -1 output_prime is [-1.5342853]\n",
      "reward is -1 output_prime is [-0.85376567]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.7337271]\n",
      "trial #477\n",
      "reward is 0.528125 output_prime is [2.158537]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.7785417]\n",
      "reward is -1 output_prime is [-0.17240363]\n",
      "reward is 0.225 output_prime is [1.9077402]\n",
      "reward is 0.1 output_prime is [1.1234939]\n",
      "hi\n",
      "reward is -1 output_prime is -1\n",
      "trial #478\n",
      "reward is 0.05 output_prime is [1.2562202]\n",
      "reward is -1 output_prime is [-0.2822879]\n",
      "reward is -0.5 output_prime is [-1.2356973]\n",
      "reward is 0.2 output_prime is [1.9857545]\n",
      "reward is -1 output_prime is [0.08009636]\n",
      "reward is -1 output_prime is [0.03285146]\n",
      "reward is 0.26666666666666666 output_prime is [2.0230827]\n",
      "reward is 0.2 output_prime is [1.160064]\n",
      "trial #479\n",
      "reward is 0.4166666666666667 output_prime is [1.3125914]\n",
      "reward is -0.5 output_prime is [0.47134262]\n",
      "reward is 0.20833333333333334 output_prime is [-0.03832771]\n",
      "reward is 0.20833333333333334 output_prime is [1.0524967]\n",
      "reward is 0.225 output_prime is [2.0875874]\n",
      "reward is 0.4166666666666667 output_prime is [-0.3194956]\n",
      "hi\n",
      "reward is 0.2 output_prime is [1.8385966]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9916666666666666\n",
      "trial #480\n",
      "reward is 0.20833333333333334 output_prime is [0.90982527]\n",
      "reward is -1 output_prime is [-0.70931983]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.4166666666666667 output_prime is [1.5694488]\n",
      "reward is 0.20416666666666666 output_prime is [-0.5321631]\n",
      "reward is -1 output_prime is [0.90056896]\n",
      "hi\n",
      "reward is 0.253125 output_prime is [1.6511381]\n",
      "trial #481\n",
      "reward is 0.20833333333333334 output_prime is [1.1083598]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.2 output_prime is [2.4451687]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.703125 output_prime is [1.1604726]\n",
      "reward is 0.20833333333333334 output_prime is [1.8588967]\n",
      "hi\n",
      "reward is 0.225 output_prime is [1.9153234]\n",
      "trial #482\n",
      "reward is 0.1 output_prime is [0.3807252]\n",
      "reward is 0.2 output_prime is [2.0404935]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-1.7368649]\n",
      "reward is 0.253125 output_prime is [1.916883]\n",
      "reward is -0.5 output_prime is [-0.09503207]\n",
      "reward is 0.20833333333333334 output_prime is [-0.5289161]\n",
      "trial #483\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.800629]\n",
      "reward is 0.3125 output_prime is [0.7046105]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.253125 output_prime is [2.025688]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is -1 output_prime is [-1.7053397]\n",
      "trial #484\n",
      "reward is 0.4 output_prime is [0.86608285]\n",
      "reward is 0.3125 output_prime is [1.9626917]\n",
      "reward is 0.05 output_prime is [0.6068128]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.378125 output_prime is [-0.3592993]\n",
      "reward is 0.2 output_prime is [0.51902586]\n",
      "hi\n",
      "reward is 1 output_prime is 1\n",
      "trial #485\n",
      "reward is -0.5 output_prime is [-1.2366197]\n",
      "reward is 0.3125 output_prime is [1.6711007]\n",
      "reward is 0.3125 output_prime is [1.6712594]\n",
      "reward is -0.5 output_prime is [0.4748683]\n",
      "reward is 0.3125 output_prime is [1.6695381]\n",
      "reward is 0.20833333333333334 output_prime is [1.837791]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -0.5 output_prime is [-1.2335256]\n",
      "trial #486\n",
      "reward is 0.1125 output_prime is [1.7354503]\n",
      "reward is 0.2 output_prime is [1.3823142]\n",
      "reward is 0.05 output_prime is [1.4110909]\n",
      "reward is 0.3375 output_prime is [1.9813434]\n",
      "reward is 0.2 output_prime is [1.3644115]\n",
      "reward is -1 output_prime is -1\n",
      "hi\n",
      "reward is -1 output_prime is [-0.23737001]\n",
      "trial #487\n",
      "reward is 0.05 output_prime is [1.9879138]\n",
      "reward is -1 output_prime is [1.2328959]\n",
      "reward is 0.2 output_prime is [1.6935295]\n",
      "reward is 0.20833333333333334 output_prime is [1.324302]\n",
      "reward is -1 output_prime is [-0.7257322]\n",
      "reward is 0.528125 output_prime is [1.871953]\n",
      "hi\n",
      "reward is 0.3375 output_prime is [1.0067052]\n",
      "trial #488\n",
      "reward is 0.703125 output_prime is [1.3338578]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [1.6736933]\n",
      "reward is 0.05 output_prime is [1.5794115]\n",
      "reward is 0.3125 output_prime is [-0.41158628]\n",
      "reward is 0.05 output_prime is [1.2616215]\n",
      "reward is 0.378125 output_prime is [1.6716487]\n",
      "reward is 0.378125 output_prime is [0.9126674]\n",
      "trial #489\n",
      "reward is 0.2 output_prime is [0.7434627]\n",
      "reward is -1 output_prime is [0.22282958]\n",
      "reward is 0.378125 output_prime is [1.3574848]\n",
      "reward is 0.20833333333333334 output_prime is [1.7476318]\n",
      "reward is -1 output_prime is [0.43926978]\n",
      "reward is -1 output_prime is [-0.36402035]\n",
      "hi\n",
      "reward is 0.45 output_prime is [1.2027186]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.6875\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9729166666666665\n",
      "trial #490\n",
      "reward is 0.6125 output_prime is [1.3958026]\n",
      "reward is 0.5041666666666667 output_prime is [-0.21383202]\n",
      "reward is 0.20833333333333334 output_prime is [2.1587172]\n",
      "reward is 0.225 output_prime is [1.250252]\n",
      "reward is 0.05 output_prime is [0.8998147]\n",
      "reward is -1 output_prime is [-1.0178257]\n",
      "hi\n",
      "reward is 0.3125 output_prime is [1.6335484]\n",
      "trial #491\n",
      "reward is 0.378125 output_prime is [-0.3366869]\n",
      "reward is 0.378125 output_prime is [1.4816382]\n",
      "reward is -1 output_prime is [-1.7133975]\n",
      "reward is 0.05 output_prime is [1.2836823]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.1125 output_prime is [0.1552021]\n",
      "reward is 0.3375 output_prime is [1.1322176]\n",
      "reward is 1 output_prime is 1\n",
      "trial #492\n",
      "reward is 0.225 output_prime is [1.819876]\n",
      "reward is -1 output_prime is [-1.7081022]\n",
      "reward is 0.703125 output_prime is [1.3908787]\n",
      "reward is 0.225 output_prime is [1.9101856]\n",
      "reward is 0.1 output_prime is [1.6960909]\n",
      "reward is 0.05 output_prime is [1.9592342]\n",
      "hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward is 0.3 output_prime is [1.924536]\n",
      "trial #493\n",
      "reward is 0.05 output_prime is [0.6638566]\n",
      "reward is 0.05 output_prime is [1.0712707]\n",
      "reward is 1 output_prime is 1\n",
      "reward is -1 output_prime is [-1.7013876]\n",
      "reward is 0.378125 output_prime is [-0.3225813]\n",
      "reward is 0.4166666666666667 output_prime is [1.3426024]\n",
      "hi\n",
      "reward is -1 output_prime is [-1.699502]\n",
      "trial #494\n",
      "reward is 0.05 output_prime is [1.540051]\n",
      "reward is 0.20833333333333334 output_prime is [2.089244]\n",
      "reward is -1 output_prime is -1\n",
      "reward is -1 output_prime is [-0.82938457]\n",
      "reward is 0.20833333333333334 output_prime is [1.77033]\n",
      "reward is 0.45 output_prime is [1.2262042]\n",
      "hi\n",
      "reward is -0.5 output_prime is [-1.1958723]\n",
      "trial #495\n",
      "reward is 0.378125 output_prime is [-0.31730467]\n",
      "reward is 0.05 output_prime is [2.2238905]\n",
      "reward is -1 output_prime is [1.2157667]\n",
      "reward is -1 output_prime is [-0.26642233]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.20833333333333334 output_prime is [2.09356]\n",
      "hi\n",
      "reward is 0.225 output_prime is [2.066912]\n",
      "trial #496\n",
      "reward is 0.225 output_prime is [1.369616]\n",
      "reward is 0.20833333333333334 output_prime is [1.3966639]\n",
      "reward is -0.5 output_prime is [0.07292742]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.3125 output_prime is [1.6338254]\n",
      "reward is 0.45 output_prime is [-0.22008622]\n",
      "reward is -1 output_prime is -1\n",
      "reward is 0.05 output_prime is [0.7820437]\n",
      "trial #497\n",
      "reward is 0.3375 output_prime is [2.0917935]\n",
      "reward is 1 output_prime is 1\n",
      "reward is 0.05 output_prime is [1.4965959]\n",
      "reward is 0.2 output_prime is [2.4018285]\n",
      "reward is 0.703125 output_prime is [1.3691504]\n",
      "reward is -0.5 output_prime is [-0.17782074]\n",
      "hi\n",
      "reward is 1 output_prime is 1\n",
      "trial #498\n",
      "reward is 0.4 output_prime is [1.63491]\n",
      "reward is 0.253125 output_prime is [2.0812817]\n",
      "reward is 0.225 output_prime is [1.4080741]\n",
      "reward is 0.05 output_prime is [1.3002663]\n",
      "reward is 0.225 output_prime is [2.060818]\n",
      "reward is 0.225 output_prime is [1.8294777]\n",
      "hi\n",
      "reward is 0.20833333333333334 output_prime is [0.9245036]\n",
      "trial #499\n",
      "reward is -1 output_prime is [0.00877357]\n",
      "reward is 0.703125 output_prime is [1.3327603]\n",
      "reward is -1 output_prime is [-1.6771979]\n",
      "reward is 0.20416666666666666 output_prime is [0.6945905]\n",
      "reward is 0.378125 output_prime is [1.6273577]\n",
      "reward is -1 output_prime is [-0.162862]\n",
      "hi\n",
      "reward is 0.45 output_prime is [-0.2261337]\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "sub accuracy is 0.75\n",
      "hi\n",
      "It's over\n",
      "sub accuracy is 1.0\n",
      "accuracy is  0.9583333333333333\n",
      "trial #500\n"
     ]
    }
   ],
   "source": [
    "env, agent, accuracies3 = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5875,\n",
       " 0.5687500000000001,\n",
       " 0.5270833333333333,\n",
       " 0.38958333333333345,\n",
       " 0.40416666666666673,\n",
       " 0.4520833333333334,\n",
       " 0.5020833333333334,\n",
       " 0.5541666666666667,\n",
       " 0.48541666666666666,\n",
       " 0.5687500000000002,\n",
       " 0.5875000000000001,\n",
       " 0.5333333333333333,\n",
       " 0.38541666666666674,\n",
       " 0.6833333333333332,\n",
       " 0.7625000000000002,\n",
       " 0.7395833333333335,\n",
       " 0.6520833333333332,\n",
       " 0.5854166666666667,\n",
       " 0.6375000000000001,\n",
       " 0.8812500000000001,\n",
       " 0.8187500000000001,\n",
       " 0.7916666666666667,\n",
       " 0.7916666666666667,\n",
       " 0.8354166666666668,\n",
       " 0.8208333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.9104166666666668,\n",
       " 0.7104166666666667,\n",
       " 0.8333333333333336,\n",
       " 0.7979166666666668,\n",
       " 0.9062500000000001,\n",
       " 0.7833333333333335,\n",
       " 0.8583333333333334,\n",
       " 0.9,\n",
       " 0.8458333333333334,\n",
       " 0.9458333333333333,\n",
       " 0.9749999999999999,\n",
       " 0.8708333333333333,\n",
       " 0.8708333333333333,\n",
       " 0.9270833333333334,\n",
       " 0.9375,\n",
       " 0.9124999999999999,\n",
       " 0.9562499999999999,\n",
       " 0.9583333333333334,\n",
       " 0.9500000000000001,\n",
       " 0.6833333333333332,\n",
       " 0.9333333333333332,\n",
       " 0.9854166666666665,\n",
       " 0.9833333333333333,\n",
       " 0.9624999999999999]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6916666666666668,\n",
       " 0.675,\n",
       " 0.9999999999999999,\n",
       " 0.9666666666666666,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9729166666666665,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9833333333333333,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.8333333333333335,\n",
       " 0.8312499999999999,\n",
       " 0.9833333333333333,\n",
       " 0.9999999999999999,\n",
       " 0.9833333333333333,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9500000000000001,\n",
       " 0.9208333333333332,\n",
       " 0.9812499999999998,\n",
       " 0.9916666666666666]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7125000000000001,\n",
       " 0.7562500000000001,\n",
       " 0.8729166666666666,\n",
       " 0.9666666666666666,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9499999999999998,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.8166666666666668,\n",
       " 0.9999999999999999,\n",
       " 0.9562499999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.98125,\n",
       " 0.9999999999999999,\n",
       " 0.8708333333333335,\n",
       " 0.9729166666666667,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9916666666666666,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9749999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9916666666666666,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.9999999999999999,\n",
       " 0.975,\n",
       " 0.9729166666666667,\n",
       " 0.9166666666666666,\n",
       " 0.9999999999999999,\n",
       " 0.91875]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracies2, label=\"trial 1\")\n",
    "plt.plot(accuracies3, label=\"trial 2\")\n",
    "plt.ylabel(\"Packing Accuracy\")\n",
    "plt.xlabel(\"Iterations (x10)\")\n",
    "plt.title(\"Hierarchical Model Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracies, label=\"trial 1\")\n",
    "plt.plot(accuracies1, label=\"trial 2\")\n",
    "plt.ylabel(\"Packing Accuracy\")\n",
    "plt.xlabel(\"Iterations (x100)\")\n",
    "plt.title(\"Hierarchical Model Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.2\n",
      "7\n",
      "0.20833333333333334\n",
      "8\n",
      "0.3375\n",
      "6\n",
      "0.4166666666666667\n",
      "3\n",
      "0.378125\n",
      "0\n",
      "0.703125\n",
      "2\n",
      "hi\n",
      "1\n",
      "10\n",
      "It's over\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_state = x.reset()\n",
    "for i in range(8):\n",
    "    action = y.trained_act(new_state)\n",
    "    print(action)\n",
    "    new_state, reward, done, _ = x.step(action)\n",
    "    print(reward)\n",
    "    x.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-57-66edbb7f4113>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-66edbb7f4113>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x = <__main__.PackEnv2 at 0x1379da210>\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x = <__main__.PackEnv2 at 0x1379da210>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
